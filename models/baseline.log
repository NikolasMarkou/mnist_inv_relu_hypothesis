I0503 16:50:44.626602 10699 caffe.cpp:217] Using GPUs 0
I0503 16:50:44.635373 10699 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
I0503 16:50:45.093385 10699 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 5000
base_lr: 0.01
display: 1000
max_iter: 500000
lr_policy: "step"
gamma: 0.5
momentum: 0.75
weight_decay: 0.0002
stepsize: 10000
snapshot: 100000
snapshot_prefix: "mnist"
solver_mode: GPU
device_id: 0
net: "train_val_inv_0.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
average_loss: 40
I0503 16:50:45.093654 10699 solver.cpp:91] Creating training net from net file: train_val_inv_0.prototxt
I0503 16:50:45.094430 10699 net.cpp:338] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0503 16:50:45.094478 10699 net.cpp:338] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_dual
I0503 16:50:45.094504 10699 net.cpp:338] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_single
I0503 16:50:45.094797 10699 net.cpp:74] Initializing net from parameters: 
name: "MNIST_NET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  image_data_param {
    source: "train.txt"
    batch_size: 300
    crop_size: 27
    shuffle: true
    is_color: false
  }
}
layer {
  name: "data_scaling"
  type: "Power"
  bottom: "data"
  top: "data"
  power_param {
    power: 1
    scale: 0.0078125
    shift: -1
  }
}
layer {
  name: "conv1_dual"
  type: "Convolution"
  bottom: "data"
  top: "conv1_dual"
  param {
    name: "conv1_w_dual"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b_dual"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv1_dual"
  type: "ReLU"
  bottom: "conv1_dual"
  top: "relu/conv1_dual"
}
layer {
  name: "conv1_minus_dual"
  type: "Power"
  bottom: "conv1_dual"
  top: "conv1_minus_dual"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "relu/conv1_minus_dual"
  type: "ReLU"
  bottom: "conv1_minus_dual"
  top: "relu/conv1_minus_dual"
}
layer {
  name: "conv2_lhs_dual"
  type: "Convolution"
  bottom: "relu/conv1_minus_dual"
  top: "conv2_lhs_dual"
  param {
    name: "conv2_w_dual"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b_dual"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv2_lhs_dual"
  type: "ReLU"
  bottom: "conv2_lhs_dual"
  top: "conv2_lhs_dual"
}
layer {
  name: "conv2_rhs_dual"
  type: "Convolution"
  bottom: "relu/conv1_dual"
  top: "conv2_rhs_dual"
  param {
    name: "conv2_w_dual"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b_dual"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv2_rhs_dual"
  type: "ReLU"
  bottom: "conv2_rhs_dual"
  top: "conv2_rhs_dual"
}
layer {
  name: "fc_10_lhs_dual"
  type: "InnerProduct"
  bottom: "conv2_lhs_dual"
  top: "fc_10_lhs_dual"
  param {
    name: "fc_10_w_dual"
    lr_mult: 5
    decay_mult: 1
  }
  param {
    name: "fc_10_b_dual"
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc_10_rhs_dual"
  type: "InnerProduct"
  bottom: "conv2_rhs_dual"
  top: "fc_10_rhs_dual"
  param {
    name: "fc_10_w_dual"
    lr_mult: 5
    decay_mult: 1
  }
  param {
    name: "fc_10_b_dual"
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc_10_dual"
  type: "Eltwise"
  bottom: "fc_10_rhs_dual"
  bottom: "fc_10_lhs_dual"
  top: "fc_10_dual"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "loss_dual"
  type: "SoftmaxWithLoss"
  bottom: "fc_10_dual"
  bottom: "label"
  top: "loss_dual"
  include {
    phase: TRAIN
  }
}
layer {
  name: "conv1_single"
  type: "Convolution"
  bottom: "data"
  top: "conv1_single"
  param {
    name: "conv1_w_single"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b_single"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv1_single"
  type: "ReLU"
  bottom: "conv1_single"
  top: "relu/conv1_single"
}
layer {
  name: "conv2_single"
  type: "Convolution"
  bottom: "relu/conv1_single"
  top: "conv2_single"
  param {
    name: "conv2_w_single"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b_single"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv2_single"
  type: "ReLU"
  bottom: "conv2_single"
  top: "conv2_single"
}
layer {
  name: "fc_10_single"
  type: "InnerProduct"
  bottom: "conv2_single"
  top: "fc_10_single"
  param {
    name: "fc_10_w_single"
    lr_mult: 5
    decay_mult: 1
  }
  param {
    name: "fc_10_b_single"
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_single"
  type: "SoftmaxWithLoss"
  bottom: "fc_10_single"
  bottom: "label"
  top: "loss_single"
  include {
    phase: TRAIN
  }
}
I0503 16:50:45.096228 10699 layer_factory.hpp:77] Creating layer data
I0503 16:50:45.096284 10699 net.cpp:116] Creating Layer data
I0503 16:50:45.096309 10699 net.cpp:424] data -> data
I0503 16:50:45.096348 10699 net.cpp:424] data -> label
I0503 16:50:45.096384 10699 image_data_layer.cpp:38] Opening file train.txt
I0503 16:50:45.111384 10699 image_data_layer.cpp:53] Shuffling data
I0503 16:50:45.116597 10699 image_data_layer.cpp:58] A total of 60000 images.
I0503 16:50:45.126904 10699 image_data_layer.cpp:85] output data size: 300,1,28,28
I0503 16:50:45.129535 10699 net.cpp:166] Setting up data
I0503 16:50:45.129559 10699 net.cpp:173] Top shape: 300 1 28 28 (235200)
I0503 16:50:45.129562 10699 net.cpp:173] Top shape: 300 (300)
I0503 16:50:45.129565 10699 net.cpp:181] Memory required for data: 942000
I0503 16:50:45.129571 10699 layer_factory.hpp:77] Creating layer label_data_1_split
I0503 16:50:45.129582 10699 net.cpp:116] Creating Layer label_data_1_split
I0503 16:50:45.129586 10699 net.cpp:450] label_data_1_split <- label
I0503 16:50:45.129595 10699 net.cpp:424] label_data_1_split -> label_data_1_split_0
I0503 16:50:45.129604 10699 net.cpp:424] label_data_1_split -> label_data_1_split_1
I0503 16:50:45.129665 10699 net.cpp:166] Setting up label_data_1_split
I0503 16:50:45.129673 10699 net.cpp:173] Top shape: 300 (300)
I0503 16:50:45.129675 10699 net.cpp:173] Top shape: 300 (300)
I0503 16:50:45.129678 10699 net.cpp:181] Memory required for data: 944400
I0503 16:50:45.129679 10699 layer_factory.hpp:77] Creating layer data_scaling
I0503 16:50:45.129685 10699 net.cpp:116] Creating Layer data_scaling
I0503 16:50:45.129688 10699 net.cpp:450] data_scaling <- data
I0503 16:50:45.129693 10699 net.cpp:411] data_scaling -> data (in-place)
I0503 16:50:45.129699 10699 net.cpp:166] Setting up data_scaling
I0503 16:50:45.129703 10699 net.cpp:173] Top shape: 300 1 28 28 (235200)
I0503 16:50:45.129705 10699 net.cpp:181] Memory required for data: 1885200
I0503 16:50:45.129707 10699 layer_factory.hpp:77] Creating layer data_data_scaling_0_split
I0503 16:50:45.129725 10699 net.cpp:116] Creating Layer data_data_scaling_0_split
I0503 16:50:45.129729 10699 net.cpp:450] data_data_scaling_0_split <- data
I0503 16:50:45.129731 10699 net.cpp:424] data_data_scaling_0_split -> data_data_scaling_0_split_0
I0503 16:50:45.129747 10699 net.cpp:424] data_data_scaling_0_split -> data_data_scaling_0_split_1
I0503 16:50:45.129777 10699 net.cpp:166] Setting up data_data_scaling_0_split
I0503 16:50:45.129781 10699 net.cpp:173] Top shape: 300 1 28 28 (235200)
I0503 16:50:45.129784 10699 net.cpp:173] Top shape: 300 1 28 28 (235200)
I0503 16:50:45.129786 10699 net.cpp:181] Memory required for data: 3766800
I0503 16:50:45.129788 10699 layer_factory.hpp:77] Creating layer conv1_dual
I0503 16:50:45.129802 10699 net.cpp:116] Creating Layer conv1_dual
I0503 16:50:45.129806 10699 net.cpp:450] conv1_dual <- data_data_scaling_0_split_0
I0503 16:50:45.129811 10699 net.cpp:424] conv1_dual -> conv1_dual
I0503 16:50:45.390305 10699 net.cpp:166] Setting up conv1_dual
I0503 16:50:45.390328 10699 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0503 16:50:45.390331 10699 net.cpp:181] Memory required for data: 11067600
I0503 16:50:45.390346 10699 layer_factory.hpp:77] Creating layer conv1_dual_conv1_dual_0_split
I0503 16:50:45.390355 10699 net.cpp:116] Creating Layer conv1_dual_conv1_dual_0_split
I0503 16:50:45.390358 10699 net.cpp:450] conv1_dual_conv1_dual_0_split <- conv1_dual
I0503 16:50:45.390363 10699 net.cpp:424] conv1_dual_conv1_dual_0_split -> conv1_dual_conv1_dual_0_split_0
I0503 16:50:45.390370 10699 net.cpp:424] conv1_dual_conv1_dual_0_split -> conv1_dual_conv1_dual_0_split_1
I0503 16:50:45.390406 10699 net.cpp:166] Setting up conv1_dual_conv1_dual_0_split
I0503 16:50:45.390413 10699 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0503 16:50:45.390416 10699 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0503 16:50:45.390419 10699 net.cpp:181] Memory required for data: 25669200
I0503 16:50:45.390420 10699 layer_factory.hpp:77] Creating layer relu/conv1_dual
I0503 16:50:45.390425 10699 net.cpp:116] Creating Layer relu/conv1_dual
I0503 16:50:45.390429 10699 net.cpp:450] relu/conv1_dual <- conv1_dual_conv1_dual_0_split_0
I0503 16:50:45.390432 10699 net.cpp:424] relu/conv1_dual -> relu/conv1_dual
I0503 16:50:45.390772 10699 net.cpp:166] Setting up relu/conv1_dual
I0503 16:50:45.390784 10699 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0503 16:50:45.390786 10699 net.cpp:181] Memory required for data: 32970000
I0503 16:50:45.390789 10699 layer_factory.hpp:77] Creating layer conv1_minus_dual
I0503 16:50:45.390794 10699 net.cpp:116] Creating Layer conv1_minus_dual
I0503 16:50:45.390796 10699 net.cpp:450] conv1_minus_dual <- conv1_dual_conv1_dual_0_split_1
I0503 16:50:45.390801 10699 net.cpp:424] conv1_minus_dual -> conv1_minus_dual
I0503 16:50:45.390821 10699 net.cpp:166] Setting up conv1_minus_dual
I0503 16:50:45.390826 10699 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0503 16:50:45.390828 10699 net.cpp:181] Memory required for data: 40270800
I0503 16:50:45.390831 10699 layer_factory.hpp:77] Creating layer relu/conv1_minus_dual
I0503 16:50:45.390836 10699 net.cpp:116] Creating Layer relu/conv1_minus_dual
I0503 16:50:45.390838 10699 net.cpp:450] relu/conv1_minus_dual <- conv1_minus_dual
I0503 16:50:45.390841 10699 net.cpp:424] relu/conv1_minus_dual -> relu/conv1_minus_dual
I0503 16:50:45.390991 10699 net.cpp:166] Setting up relu/conv1_minus_dual
I0503 16:50:45.391000 10699 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0503 16:50:45.391003 10699 net.cpp:181] Memory required for data: 47571600
I0503 16:50:45.391005 10699 layer_factory.hpp:77] Creating layer conv2_lhs_dual
I0503 16:50:45.391016 10699 net.cpp:116] Creating Layer conv2_lhs_dual
I0503 16:50:45.391022 10699 net.cpp:450] conv2_lhs_dual <- relu/conv1_minus_dual
I0503 16:50:45.391028 10699 net.cpp:424] conv2_lhs_dual -> conv2_lhs_dual
I0503 16:50:45.392592 10699 net.cpp:166] Setting up conv2_lhs_dual
I0503 16:50:45.392604 10699 net.cpp:173] Top shape: 300 36 6 6 (388800)
I0503 16:50:45.392621 10699 net.cpp:181] Memory required for data: 49126800
I0503 16:50:45.392629 10699 layer_factory.hpp:77] Creating layer relu/conv2_lhs_dual
I0503 16:50:45.392634 10699 net.cpp:116] Creating Layer relu/conv2_lhs_dual
I0503 16:50:45.392637 10699 net.cpp:450] relu/conv2_lhs_dual <- conv2_lhs_dual
I0503 16:50:45.392642 10699 net.cpp:411] relu/conv2_lhs_dual -> conv2_lhs_dual (in-place)
I0503 16:50:45.392969 10699 net.cpp:166] Setting up relu/conv2_lhs_dual
I0503 16:50:45.392980 10699 net.cpp:173] Top shape: 300 36 6 6 (388800)
I0503 16:50:45.392982 10699 net.cpp:181] Memory required for data: 50682000
I0503 16:50:45.392985 10699 layer_factory.hpp:77] Creating layer conv2_rhs_dual
I0503 16:50:45.392994 10699 net.cpp:116] Creating Layer conv2_rhs_dual
I0503 16:50:45.392997 10699 net.cpp:450] conv2_rhs_dual <- relu/conv1_dual
I0503 16:50:45.393003 10699 net.cpp:424] conv2_rhs_dual -> conv2_rhs_dual
I0503 16:50:45.394034 10699 net.cpp:166] Setting up conv2_rhs_dual
I0503 16:50:45.394047 10699 net.cpp:173] Top shape: 300 36 6 6 (388800)
I0503 16:50:45.394049 10699 net.cpp:181] Memory required for data: 52237200
I0503 16:50:45.394053 10699 net.cpp:509] Sharing parameters 'conv2_w_dual' owned by layer 'conv2_lhs_dual', param index 0
I0503 16:50:45.394057 10699 net.cpp:509] Sharing parameters 'conv2_b_dual' owned by layer 'conv2_lhs_dual', param index 1
I0503 16:50:45.394059 10699 layer_factory.hpp:77] Creating layer relu/conv2_rhs_dual
I0503 16:50:45.394067 10699 net.cpp:116] Creating Layer relu/conv2_rhs_dual
I0503 16:50:45.394068 10699 net.cpp:450] relu/conv2_rhs_dual <- conv2_rhs_dual
I0503 16:50:45.394073 10699 net.cpp:411] relu/conv2_rhs_dual -> conv2_rhs_dual (in-place)
I0503 16:50:45.394214 10699 net.cpp:166] Setting up relu/conv2_rhs_dual
I0503 16:50:45.394222 10699 net.cpp:173] Top shape: 300 36 6 6 (388800)
I0503 16:50:45.394225 10699 net.cpp:181] Memory required for data: 53792400
I0503 16:50:45.394228 10699 layer_factory.hpp:77] Creating layer fc_10_lhs_dual
I0503 16:50:45.394234 10699 net.cpp:116] Creating Layer fc_10_lhs_dual
I0503 16:50:45.394237 10699 net.cpp:450] fc_10_lhs_dual <- conv2_lhs_dual
I0503 16:50:45.394243 10699 net.cpp:424] fc_10_lhs_dual -> fc_10_lhs_dual
I0503 16:50:45.394399 10699 net.cpp:166] Setting up fc_10_lhs_dual
I0503 16:50:45.394407 10699 net.cpp:173] Top shape: 300 10 (3000)
I0503 16:50:45.394409 10699 net.cpp:181] Memory required for data: 53804400
I0503 16:50:45.394413 10699 layer_factory.hpp:77] Creating layer fc_10_rhs_dual
I0503 16:50:45.394419 10699 net.cpp:116] Creating Layer fc_10_rhs_dual
I0503 16:50:45.394423 10699 net.cpp:450] fc_10_rhs_dual <- conv2_rhs_dual
I0503 16:50:45.394426 10699 net.cpp:424] fc_10_rhs_dual -> fc_10_rhs_dual
I0503 16:50:45.394564 10699 net.cpp:166] Setting up fc_10_rhs_dual
I0503 16:50:45.394570 10699 net.cpp:173] Top shape: 300 10 (3000)
I0503 16:50:45.394572 10699 net.cpp:181] Memory required for data: 53816400
I0503 16:50:45.394577 10699 net.cpp:509] Sharing parameters 'fc_10_w_dual' owned by layer 'fc_10_lhs_dual', param index 0
I0503 16:50:45.394579 10699 net.cpp:509] Sharing parameters 'fc_10_b_dual' owned by layer 'fc_10_lhs_dual', param index 1
I0503 16:50:45.394582 10699 layer_factory.hpp:77] Creating layer fc_10_dual
I0503 16:50:45.394587 10699 net.cpp:116] Creating Layer fc_10_dual
I0503 16:50:45.394589 10699 net.cpp:450] fc_10_dual <- fc_10_rhs_dual
I0503 16:50:45.394593 10699 net.cpp:450] fc_10_dual <- fc_10_lhs_dual
I0503 16:50:45.394596 10699 net.cpp:424] fc_10_dual -> fc_10_dual
I0503 16:50:45.394618 10699 net.cpp:166] Setting up fc_10_dual
I0503 16:50:45.394624 10699 net.cpp:173] Top shape: 300 10 (3000)
I0503 16:50:45.394626 10699 net.cpp:181] Memory required for data: 53828400
I0503 16:50:45.394629 10699 layer_factory.hpp:77] Creating layer loss_dual
I0503 16:50:45.394634 10699 net.cpp:116] Creating Layer loss_dual
I0503 16:50:45.394637 10699 net.cpp:450] loss_dual <- fc_10_dual
I0503 16:50:45.394640 10699 net.cpp:450] loss_dual <- label_data_1_split_0
I0503 16:50:45.394644 10699 net.cpp:424] loss_dual -> loss_dual
I0503 16:50:45.394662 10699 layer_factory.hpp:77] Creating layer loss_dual
I0503 16:50:45.395419 10699 net.cpp:166] Setting up loss_dual
I0503 16:50:45.395429 10699 net.cpp:173] Top shape: (1)
I0503 16:50:45.395432 10699 net.cpp:176]     with loss weight 1
I0503 16:50:45.395447 10699 net.cpp:181] Memory required for data: 53828404
I0503 16:50:45.395449 10699 layer_factory.hpp:77] Creating layer conv1_single
I0503 16:50:45.395459 10699 net.cpp:116] Creating Layer conv1_single
I0503 16:50:45.395462 10699 net.cpp:450] conv1_single <- data_data_scaling_0_split_1
I0503 16:50:45.395468 10699 net.cpp:424] conv1_single -> conv1_single
I0503 16:50:45.396301 10699 net.cpp:166] Setting up conv1_single
I0503 16:50:45.396312 10699 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0503 16:50:45.396314 10699 net.cpp:181] Memory required for data: 61129204
I0503 16:50:45.396319 10699 layer_factory.hpp:77] Creating layer relu/conv1_single
I0503 16:50:45.396324 10699 net.cpp:116] Creating Layer relu/conv1_single
I0503 16:50:45.396327 10699 net.cpp:450] relu/conv1_single <- conv1_single
I0503 16:50:45.396332 10699 net.cpp:424] relu/conv1_single -> relu/conv1_single
I0503 16:50:45.396667 10699 net.cpp:166] Setting up relu/conv1_single
I0503 16:50:45.396677 10699 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0503 16:50:45.396680 10699 net.cpp:181] Memory required for data: 68430004
I0503 16:50:45.396682 10699 layer_factory.hpp:77] Creating layer conv2_single
I0503 16:50:45.396692 10699 net.cpp:116] Creating Layer conv2_single
I0503 16:50:45.396693 10699 net.cpp:450] conv2_single <- relu/conv1_single
I0503 16:50:45.396700 10699 net.cpp:424] conv2_single -> conv2_single
I0503 16:50:45.397738 10699 net.cpp:166] Setting up conv2_single
I0503 16:50:45.397752 10699 net.cpp:173] Top shape: 300 36 6 6 (388800)
I0503 16:50:45.397753 10699 net.cpp:181] Memory required for data: 69985204
I0503 16:50:45.397759 10699 layer_factory.hpp:77] Creating layer relu/conv2_single
I0503 16:50:45.397764 10699 net.cpp:116] Creating Layer relu/conv2_single
I0503 16:50:45.397768 10699 net.cpp:450] relu/conv2_single <- conv2_single
I0503 16:50:45.397770 10699 net.cpp:411] relu/conv2_single -> conv2_single (in-place)
I0503 16:50:45.397917 10699 net.cpp:166] Setting up relu/conv2_single
I0503 16:50:45.397924 10699 net.cpp:173] Top shape: 300 36 6 6 (388800)
I0503 16:50:45.397927 10699 net.cpp:181] Memory required for data: 71540404
I0503 16:50:45.397929 10699 layer_factory.hpp:77] Creating layer fc_10_single
I0503 16:50:45.397935 10699 net.cpp:116] Creating Layer fc_10_single
I0503 16:50:45.397938 10699 net.cpp:450] fc_10_single <- conv2_single
I0503 16:50:45.397943 10699 net.cpp:424] fc_10_single -> fc_10_single
I0503 16:50:45.398099 10699 net.cpp:166] Setting up fc_10_single
I0503 16:50:45.398106 10699 net.cpp:173] Top shape: 300 10 (3000)
I0503 16:50:45.398108 10699 net.cpp:181] Memory required for data: 71552404
I0503 16:50:45.398113 10699 layer_factory.hpp:77] Creating layer loss_single
I0503 16:50:45.398118 10699 net.cpp:116] Creating Layer loss_single
I0503 16:50:45.398120 10699 net.cpp:450] loss_single <- fc_10_single
I0503 16:50:45.398123 10699 net.cpp:450] loss_single <- label_data_1_split_1
I0503 16:50:45.398128 10699 net.cpp:424] loss_single -> loss_single
I0503 16:50:45.398133 10699 layer_factory.hpp:77] Creating layer loss_single
I0503 16:50:45.398535 10699 net.cpp:166] Setting up loss_single
I0503 16:50:45.398545 10699 net.cpp:173] Top shape: (1)
I0503 16:50:45.398546 10699 net.cpp:176]     with loss weight 1
I0503 16:50:45.398553 10699 net.cpp:181] Memory required for data: 71552408
I0503 16:50:45.398556 10699 net.cpp:242] loss_single needs backward computation.
I0503 16:50:45.398560 10699 net.cpp:242] fc_10_single needs backward computation.
I0503 16:50:45.398561 10699 net.cpp:242] relu/conv2_single needs backward computation.
I0503 16:50:45.398563 10699 net.cpp:242] conv2_single needs backward computation.
I0503 16:50:45.398566 10699 net.cpp:242] relu/conv1_single needs backward computation.
I0503 16:50:45.398567 10699 net.cpp:242] conv1_single needs backward computation.
I0503 16:50:45.398579 10699 net.cpp:242] loss_dual needs backward computation.
I0503 16:50:45.398582 10699 net.cpp:242] fc_10_dual needs backward computation.
I0503 16:50:45.398586 10699 net.cpp:242] fc_10_rhs_dual needs backward computation.
I0503 16:50:45.398587 10699 net.cpp:242] fc_10_lhs_dual needs backward computation.
I0503 16:50:45.398591 10699 net.cpp:242] relu/conv2_rhs_dual needs backward computation.
I0503 16:50:45.398592 10699 net.cpp:242] conv2_rhs_dual needs backward computation.
I0503 16:50:45.398594 10699 net.cpp:242] relu/conv2_lhs_dual needs backward computation.
I0503 16:50:45.398597 10699 net.cpp:242] conv2_lhs_dual needs backward computation.
I0503 16:50:45.398599 10699 net.cpp:242] relu/conv1_minus_dual needs backward computation.
I0503 16:50:45.398602 10699 net.cpp:242] conv1_minus_dual needs backward computation.
I0503 16:50:45.398604 10699 net.cpp:242] relu/conv1_dual needs backward computation.
I0503 16:50:45.398607 10699 net.cpp:242] conv1_dual_conv1_dual_0_split needs backward computation.
I0503 16:50:45.398609 10699 net.cpp:242] conv1_dual needs backward computation.
I0503 16:50:45.398612 10699 net.cpp:244] data_data_scaling_0_split does not need backward computation.
I0503 16:50:45.398615 10699 net.cpp:244] data_scaling does not need backward computation.
I0503 16:50:45.398617 10699 net.cpp:244] label_data_1_split does not need backward computation.
I0503 16:50:45.398620 10699 net.cpp:244] data does not need backward computation.
I0503 16:50:45.398622 10699 net.cpp:286] This network produces output loss_dual
I0503 16:50:45.398625 10699 net.cpp:286] This network produces output loss_single
I0503 16:50:45.398694 10699 net.cpp:299] Network initialization done.
I0503 16:50:45.399164 10699 solver.cpp:181] Creating test net (#0) specified by net file: train_val_inv_0.prototxt
I0503 16:50:45.399197 10699 net.cpp:338] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0503 16:50:45.399210 10699 net.cpp:338] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss_dual
I0503 16:50:45.399217 10699 net.cpp:338] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss_single
I0503 16:50:45.399389 10699 net.cpp:74] Initializing net from parameters: 
name: "MNIST_NET"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  image_data_param {
    source: "test.txt"
    batch_size: 100
    crop_size: 27
    shuffle: true
    is_color: false
  }
}
layer {
  name: "data_scaling"
  type: "Power"
  bottom: "data"
  top: "data"
  power_param {
    power: 1
    scale: 0.0078125
    shift: -1
  }
}
layer {
  name: "conv1_dual"
  type: "Convolution"
  bottom: "data"
  top: "conv1_dual"
  param {
    name: "conv1_w_dual"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b_dual"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv1_dual"
  type: "ReLU"
  bottom: "conv1_dual"
  top: "relu/conv1_dual"
}
layer {
  name: "conv1_minus_dual"
  type: "Power"
  bottom: "conv1_dual"
  top: "conv1_minus_dual"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "relu/conv1_minus_dual"
  type: "ReLU"
  bottom: "conv1_minus_dual"
  top: "relu/conv1_minus_dual"
}
layer {
  name: "conv2_lhs_dual"
  type: "Convolution"
  bottom: "relu/conv1_minus_dual"
  top: "conv2_lhs_dual"
  param {
    name: "conv2_w_dual"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b_dual"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv2_lhs_dual"
  type: "ReLU"
  bottom: "conv2_lhs_dual"
  top: "conv2_lhs_dual"
}
layer {
  name: "conv2_rhs_dual"
  type: "Convolution"
  bottom: "relu/conv1_dual"
  top: "conv2_rhs_dual"
  param {
    name: "conv2_w_dual"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b_dual"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv2_rhs_dual"
  type: "ReLU"
  bottom: "conv2_rhs_dual"
  top: "conv2_rhs_dual"
}
layer {
  name: "fc_10_lhs_dual"
  type: "InnerProduct"
  bottom: "conv2_lhs_dual"
  top: "fc_10_lhs_dual"
  param {
    name: "fc_10_w_dual"
    lr_mult: 5
    decay_mult: 1
  }
  param {
    name: "fc_10_b_dual"
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc_10_rhs_dual"
  type: "InnerProduct"
  bottom: "conv2_rhs_dual"
  top: "fc_10_rhs_dual"
  param {
    name: "fc_10_w_dual"
    lr_mult: 5
    decay_mult: 1
  }
  param {
    name: "fc_10_b_dual"
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc_10_dual"
  type: "Eltwise"
  bottom: "fc_10_rhs_dual"
  bottom: "fc_10_lhs_dual"
  top: "fc_10_dual"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "accuracy_dual"
  type: "Accuracy"
  bottom: "fc_10_dual"
  bottom: "label"
  top: "accuracy_dual"
  include {
    phase: TEST
  }
}
layer {
  name: "conv1_single"
  type: "Convolution"
  bottom: "data"
  top: "conv1_single"
  param {
    name: "conv1_w_single"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_b_single"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv1_single"
  type: "ReLU"
  bottom: "conv1_single"
  top: "relu/conv1_single"
}
layer {
  name: "conv2_single"
  type: "Convolution"
  bottom: "relu/conv1_single"
  top: "conv2_single"
  param {
    name: "conv2_w_single"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b_single"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu/conv2_single"
  type: "ReLU"
  bottom: "conv2_single"
  top: "conv2_single"
}
layer {
  name: "fc_10_single"
  type: "InnerProduct"
  bottom: "conv2_single"
  top: "fc_10_single"
  param {
    name: "fc_10_w_single"
    lr_mult: 5
    decay_mult: 1
  }
  param {
    name: "fc_10_b_single"
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy_single"
  type: "Accuracy"
  bottom: "fc_10_single"
  bottom: "label"
  top: "accuracy_single"
  include {
    phase: TEST
  }
}
I0503 16:50:45.399484 10699 layer_factory.hpp:77] Creating layer data
I0503 16:50:45.399495 10699 net.cpp:116] Creating Layer data
I0503 16:50:45.399499 10699 net.cpp:424] data -> data
I0503 16:50:45.399507 10699 net.cpp:424] data -> label
I0503 16:50:45.399513 10699 image_data_layer.cpp:38] Opening file test.txt
I0503 16:50:45.401643 10699 image_data_layer.cpp:53] Shuffling data
I0503 16:50:45.402448 10699 image_data_layer.cpp:58] A total of 10000 images.
I0503 16:50:45.402645 10699 image_data_layer.cpp:85] output data size: 100,1,28,28
I0503 16:50:45.409204 10699 net.cpp:166] Setting up data
I0503 16:50:45.409216 10699 net.cpp:173] Top shape: 100 1 28 28 (78400)
I0503 16:50:45.409220 10699 net.cpp:173] Top shape: 100 (100)
I0503 16:50:45.409222 10699 net.cpp:181] Memory required for data: 314000
I0503 16:50:45.409237 10699 layer_factory.hpp:77] Creating layer label_data_1_split
I0503 16:50:45.409245 10699 net.cpp:116] Creating Layer label_data_1_split
I0503 16:50:45.409248 10699 net.cpp:450] label_data_1_split <- label
I0503 16:50:45.409252 10699 net.cpp:424] label_data_1_split -> label_data_1_split_0
I0503 16:50:45.409258 10699 net.cpp:424] label_data_1_split -> label_data_1_split_1
I0503 16:50:45.409348 10699 net.cpp:166] Setting up label_data_1_split
I0503 16:50:45.409356 10699 net.cpp:173] Top shape: 100 (100)
I0503 16:50:45.409358 10699 net.cpp:173] Top shape: 100 (100)
I0503 16:50:45.409360 10699 net.cpp:181] Memory required for data: 314800
I0503 16:50:45.409363 10699 layer_factory.hpp:77] Creating layer data_scaling
I0503 16:50:45.409368 10699 net.cpp:116] Creating Layer data_scaling
I0503 16:50:45.409371 10699 net.cpp:450] data_scaling <- data
I0503 16:50:45.409374 10699 net.cpp:411] data_scaling -> data (in-place)
I0503 16:50:45.409379 10699 net.cpp:166] Setting up data_scaling
I0503 16:50:45.409382 10699 net.cpp:173] Top shape: 100 1 28 28 (78400)
I0503 16:50:45.409384 10699 net.cpp:181] Memory required for data: 628400
I0503 16:50:45.409386 10699 layer_factory.hpp:77] Creating layer data_data_scaling_0_split
I0503 16:50:45.409390 10699 net.cpp:116] Creating Layer data_data_scaling_0_split
I0503 16:50:45.409392 10699 net.cpp:450] data_data_scaling_0_split <- data
I0503 16:50:45.409395 10699 net.cpp:424] data_data_scaling_0_split -> data_data_scaling_0_split_0
I0503 16:50:45.409399 10699 net.cpp:424] data_data_scaling_0_split -> data_data_scaling_0_split_1
I0503 16:50:45.409430 10699 net.cpp:166] Setting up data_data_scaling_0_split
I0503 16:50:45.409433 10699 net.cpp:173] Top shape: 100 1 28 28 (78400)
I0503 16:50:45.409436 10699 net.cpp:173] Top shape: 100 1 28 28 (78400)
I0503 16:50:45.409438 10699 net.cpp:181] Memory required for data: 1255600
I0503 16:50:45.409440 10699 layer_factory.hpp:77] Creating layer conv1_dual
I0503 16:50:45.409453 10699 net.cpp:116] Creating Layer conv1_dual
I0503 16:50:45.409456 10699 net.cpp:450] conv1_dual <- data_data_scaling_0_split_0
I0503 16:50:45.409459 10699 net.cpp:424] conv1_dual -> conv1_dual
I0503 16:50:45.414036 10699 net.cpp:166] Setting up conv1_dual
I0503 16:50:45.414048 10699 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0503 16:50:45.414053 10699 net.cpp:181] Memory required for data: 3689200
I0503 16:50:45.414062 10699 layer_factory.hpp:77] Creating layer conv1_dual_conv1_dual_0_split
I0503 16:50:45.414067 10699 net.cpp:116] Creating Layer conv1_dual_conv1_dual_0_split
I0503 16:50:45.414068 10699 net.cpp:450] conv1_dual_conv1_dual_0_split <- conv1_dual
I0503 16:50:45.414079 10699 net.cpp:424] conv1_dual_conv1_dual_0_split -> conv1_dual_conv1_dual_0_split_0
I0503 16:50:45.414084 10699 net.cpp:424] conv1_dual_conv1_dual_0_split -> conv1_dual_conv1_dual_0_split_1
I0503 16:50:45.414129 10699 net.cpp:166] Setting up conv1_dual_conv1_dual_0_split
I0503 16:50:45.414134 10699 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0503 16:50:45.414137 10699 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0503 16:50:45.414139 10699 net.cpp:181] Memory required for data: 8556400
I0503 16:50:45.414141 10699 layer_factory.hpp:77] Creating layer relu/conv1_dual
I0503 16:50:45.414147 10699 net.cpp:116] Creating Layer relu/conv1_dual
I0503 16:50:45.414150 10699 net.cpp:450] relu/conv1_dual <- conv1_dual_conv1_dual_0_split_0
I0503 16:50:45.414153 10699 net.cpp:424] relu/conv1_dual -> relu/conv1_dual
I0503 16:50:45.414749 10699 net.cpp:166] Setting up relu/conv1_dual
I0503 16:50:45.414760 10699 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0503 16:50:45.414763 10699 net.cpp:181] Memory required for data: 10990000
I0503 16:50:45.414765 10699 layer_factory.hpp:77] Creating layer conv1_minus_dual
I0503 16:50:45.414770 10699 net.cpp:116] Creating Layer conv1_minus_dual
I0503 16:50:45.414773 10699 net.cpp:450] conv1_minus_dual <- conv1_dual_conv1_dual_0_split_1
I0503 16:50:45.414777 10699 net.cpp:424] conv1_minus_dual -> conv1_minus_dual
I0503 16:50:45.414810 10699 net.cpp:166] Setting up conv1_minus_dual
I0503 16:50:45.414814 10699 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0503 16:50:45.414816 10699 net.cpp:181] Memory required for data: 13423600
I0503 16:50:45.414819 10699 layer_factory.hpp:77] Creating layer relu/conv1_minus_dual
I0503 16:50:45.414826 10699 net.cpp:116] Creating Layer relu/conv1_minus_dual
I0503 16:50:45.414829 10699 net.cpp:450] relu/conv1_minus_dual <- conv1_minus_dual
I0503 16:50:45.414832 10699 net.cpp:424] relu/conv1_minus_dual -> relu/conv1_minus_dual
I0503 16:50:45.415940 10699 net.cpp:166] Setting up relu/conv1_minus_dual
I0503 16:50:45.415953 10699 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0503 16:50:45.415956 10699 net.cpp:181] Memory required for data: 15857200
I0503 16:50:45.415959 10699 layer_factory.hpp:77] Creating layer conv2_lhs_dual
I0503 16:50:45.415968 10699 net.cpp:116] Creating Layer conv2_lhs_dual
I0503 16:50:45.415971 10699 net.cpp:450] conv2_lhs_dual <- relu/conv1_minus_dual
I0503 16:50:45.415978 10699 net.cpp:424] conv2_lhs_dual -> conv2_lhs_dual
I0503 16:50:45.420126 10699 net.cpp:166] Setting up conv2_lhs_dual
I0503 16:50:45.420140 10699 net.cpp:173] Top shape: 100 36 6 6 (129600)
I0503 16:50:45.420142 10699 net.cpp:181] Memory required for data: 16375600
I0503 16:50:45.420150 10699 layer_factory.hpp:77] Creating layer relu/conv2_lhs_dual
I0503 16:50:45.420156 10699 net.cpp:116] Creating Layer relu/conv2_lhs_dual
I0503 16:50:45.420157 10699 net.cpp:450] relu/conv2_lhs_dual <- conv2_lhs_dual
I0503 16:50:45.420161 10699 net.cpp:411] relu/conv2_lhs_dual -> conv2_lhs_dual (in-place)
I0503 16:50:45.420655 10699 net.cpp:166] Setting up relu/conv2_lhs_dual
I0503 16:50:45.420665 10699 net.cpp:173] Top shape: 100 36 6 6 (129600)
I0503 16:50:45.420668 10699 net.cpp:181] Memory required for data: 16894000
I0503 16:50:45.420670 10699 layer_factory.hpp:77] Creating layer conv2_rhs_dual
I0503 16:50:45.420680 10699 net.cpp:116] Creating Layer conv2_rhs_dual
I0503 16:50:45.420682 10699 net.cpp:450] conv2_rhs_dual <- relu/conv1_dual
I0503 16:50:45.420687 10699 net.cpp:424] conv2_rhs_dual -> conv2_rhs_dual
I0503 16:50:45.425432 10699 net.cpp:166] Setting up conv2_rhs_dual
I0503 16:50:45.425446 10699 net.cpp:173] Top shape: 100 36 6 6 (129600)
I0503 16:50:45.425447 10699 net.cpp:181] Memory required for data: 17412400
I0503 16:50:45.425452 10699 net.cpp:509] Sharing parameters 'conv2_w_dual' owned by layer 'conv2_lhs_dual', param index 0
I0503 16:50:45.425457 10699 net.cpp:509] Sharing parameters 'conv2_b_dual' owned by layer 'conv2_lhs_dual', param index 1
I0503 16:50:45.425458 10699 layer_factory.hpp:77] Creating layer relu/conv2_rhs_dual
I0503 16:50:45.425463 10699 net.cpp:116] Creating Layer relu/conv2_rhs_dual
I0503 16:50:45.425467 10699 net.cpp:450] relu/conv2_rhs_dual <- conv2_rhs_dual
I0503 16:50:45.425472 10699 net.cpp:411] relu/conv2_rhs_dual -> conv2_rhs_dual (in-place)
I0503 16:50:45.425629 10699 net.cpp:166] Setting up relu/conv2_rhs_dual
I0503 16:50:45.425638 10699 net.cpp:173] Top shape: 100 36 6 6 (129600)
I0503 16:50:45.425640 10699 net.cpp:181] Memory required for data: 17930800
I0503 16:50:45.425642 10699 layer_factory.hpp:77] Creating layer fc_10_lhs_dual
I0503 16:50:45.425650 10699 net.cpp:116] Creating Layer fc_10_lhs_dual
I0503 16:50:45.425653 10699 net.cpp:450] fc_10_lhs_dual <- conv2_lhs_dual
I0503 16:50:45.425658 10699 net.cpp:424] fc_10_lhs_dual -> fc_10_lhs_dual
I0503 16:50:45.425825 10699 net.cpp:166] Setting up fc_10_lhs_dual
I0503 16:50:45.425834 10699 net.cpp:173] Top shape: 100 10 (1000)
I0503 16:50:45.425837 10699 net.cpp:181] Memory required for data: 17934800
I0503 16:50:45.425843 10699 layer_factory.hpp:77] Creating layer fc_10_rhs_dual
I0503 16:50:45.425848 10699 net.cpp:116] Creating Layer fc_10_rhs_dual
I0503 16:50:45.425851 10699 net.cpp:450] fc_10_rhs_dual <- conv2_rhs_dual
I0503 16:50:45.425856 10699 net.cpp:424] fc_10_rhs_dual -> fc_10_rhs_dual
I0503 16:50:45.425997 10699 net.cpp:166] Setting up fc_10_rhs_dual
I0503 16:50:45.426005 10699 net.cpp:173] Top shape: 100 10 (1000)
I0503 16:50:45.426018 10699 net.cpp:181] Memory required for data: 17938800
I0503 16:50:45.426023 10699 net.cpp:509] Sharing parameters 'fc_10_w_dual' owned by layer 'fc_10_lhs_dual', param index 0
I0503 16:50:45.426026 10699 net.cpp:509] Sharing parameters 'fc_10_b_dual' owned by layer 'fc_10_lhs_dual', param index 1
I0503 16:50:45.426028 10699 layer_factory.hpp:77] Creating layer fc_10_dual
I0503 16:50:45.426034 10699 net.cpp:116] Creating Layer fc_10_dual
I0503 16:50:45.426036 10699 net.cpp:450] fc_10_dual <- fc_10_rhs_dual
I0503 16:50:45.426039 10699 net.cpp:450] fc_10_dual <- fc_10_lhs_dual
I0503 16:50:45.426043 10699 net.cpp:424] fc_10_dual -> fc_10_dual
I0503 16:50:45.426067 10699 net.cpp:166] Setting up fc_10_dual
I0503 16:50:45.426072 10699 net.cpp:173] Top shape: 100 10 (1000)
I0503 16:50:45.426074 10699 net.cpp:181] Memory required for data: 17942800
I0503 16:50:45.426076 10699 layer_factory.hpp:77] Creating layer accuracy_dual
I0503 16:50:45.426084 10699 net.cpp:116] Creating Layer accuracy_dual
I0503 16:50:45.426085 10699 net.cpp:450] accuracy_dual <- fc_10_dual
I0503 16:50:45.426090 10699 net.cpp:450] accuracy_dual <- label_data_1_split_0
I0503 16:50:45.426092 10699 net.cpp:424] accuracy_dual -> accuracy_dual
I0503 16:50:45.426098 10699 net.cpp:166] Setting up accuracy_dual
I0503 16:50:45.426101 10699 net.cpp:173] Top shape: (1)
I0503 16:50:45.426103 10699 net.cpp:181] Memory required for data: 17942804
I0503 16:50:45.426105 10699 layer_factory.hpp:77] Creating layer conv1_single
I0503 16:50:45.426115 10699 net.cpp:116] Creating Layer conv1_single
I0503 16:50:45.426117 10699 net.cpp:450] conv1_single <- data_data_scaling_0_split_1
I0503 16:50:45.426121 10699 net.cpp:424] conv1_single -> conv1_single
I0503 16:50:45.428851 10699 net.cpp:166] Setting up conv1_single
I0503 16:50:45.428864 10699 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0503 16:50:45.428866 10699 net.cpp:181] Memory required for data: 20376404
I0503 16:50:45.428872 10699 layer_factory.hpp:77] Creating layer relu/conv1_single
I0503 16:50:45.428876 10699 net.cpp:116] Creating Layer relu/conv1_single
I0503 16:50:45.428879 10699 net.cpp:450] relu/conv1_single <- conv1_single
I0503 16:50:45.428884 10699 net.cpp:424] relu/conv1_single -> relu/conv1_single
I0503 16:50:45.429884 10699 net.cpp:166] Setting up relu/conv1_single
I0503 16:50:45.429896 10699 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0503 16:50:45.429899 10699 net.cpp:181] Memory required for data: 22810004
I0503 16:50:45.429901 10699 layer_factory.hpp:77] Creating layer conv2_single
I0503 16:50:45.429910 10699 net.cpp:116] Creating Layer conv2_single
I0503 16:50:45.429913 10699 net.cpp:450] conv2_single <- relu/conv1_single
I0503 16:50:45.429918 10699 net.cpp:424] conv2_single -> conv2_single
I0503 16:50:45.435194 10699 net.cpp:166] Setting up conv2_single
I0503 16:50:45.435205 10699 net.cpp:173] Top shape: 100 36 6 6 (129600)
I0503 16:50:45.435207 10699 net.cpp:181] Memory required for data: 23328404
I0503 16:50:45.435214 10699 layer_factory.hpp:77] Creating layer relu/conv2_single
I0503 16:50:45.435219 10699 net.cpp:116] Creating Layer relu/conv2_single
I0503 16:50:45.435221 10699 net.cpp:450] relu/conv2_single <- conv2_single
I0503 16:50:45.435225 10699 net.cpp:411] relu/conv2_single -> conv2_single (in-place)
I0503 16:50:45.436127 10699 net.cpp:166] Setting up relu/conv2_single
I0503 16:50:45.436136 10699 net.cpp:173] Top shape: 100 36 6 6 (129600)
I0503 16:50:45.436137 10699 net.cpp:181] Memory required for data: 23846804
I0503 16:50:45.436141 10699 layer_factory.hpp:77] Creating layer fc_10_single
I0503 16:50:45.436146 10699 net.cpp:116] Creating Layer fc_10_single
I0503 16:50:45.436149 10699 net.cpp:450] fc_10_single <- conv2_single
I0503 16:50:45.436153 10699 net.cpp:424] fc_10_single -> fc_10_single
I0503 16:50:45.436307 10699 net.cpp:166] Setting up fc_10_single
I0503 16:50:45.436314 10699 net.cpp:173] Top shape: 100 10 (1000)
I0503 16:50:45.436316 10699 net.cpp:181] Memory required for data: 23850804
I0503 16:50:45.436321 10699 layer_factory.hpp:77] Creating layer accuracy_single
I0503 16:50:45.436338 10699 net.cpp:116] Creating Layer accuracy_single
I0503 16:50:45.436342 10699 net.cpp:450] accuracy_single <- fc_10_single
I0503 16:50:45.436344 10699 net.cpp:450] accuracy_single <- label_data_1_split_1
I0503 16:50:45.436348 10699 net.cpp:424] accuracy_single -> accuracy_single
I0503 16:50:45.436354 10699 net.cpp:166] Setting up accuracy_single
I0503 16:50:45.436357 10699 net.cpp:173] Top shape: (1)
I0503 16:50:45.436360 10699 net.cpp:181] Memory required for data: 23850808
I0503 16:50:45.436364 10699 net.cpp:244] accuracy_single does not need backward computation.
I0503 16:50:45.436367 10699 net.cpp:244] fc_10_single does not need backward computation.
I0503 16:50:45.436368 10699 net.cpp:244] relu/conv2_single does not need backward computation.
I0503 16:50:45.436370 10699 net.cpp:244] conv2_single does not need backward computation.
I0503 16:50:45.436373 10699 net.cpp:244] relu/conv1_single does not need backward computation.
I0503 16:50:45.436375 10699 net.cpp:244] conv1_single does not need backward computation.
I0503 16:50:45.436378 10699 net.cpp:244] accuracy_dual does not need backward computation.
I0503 16:50:45.436380 10699 net.cpp:244] fc_10_dual does not need backward computation.
I0503 16:50:45.436383 10699 net.cpp:244] fc_10_rhs_dual does not need backward computation.
I0503 16:50:45.436385 10699 net.cpp:244] fc_10_lhs_dual does not need backward computation.
I0503 16:50:45.436388 10699 net.cpp:244] relu/conv2_rhs_dual does not need backward computation.
I0503 16:50:45.436394 10699 net.cpp:244] conv2_rhs_dual does not need backward computation.
I0503 16:50:45.436398 10699 net.cpp:244] relu/conv2_lhs_dual does not need backward computation.
I0503 16:50:45.436399 10699 net.cpp:244] conv2_lhs_dual does not need backward computation.
I0503 16:50:45.436401 10699 net.cpp:244] relu/conv1_minus_dual does not need backward computation.
I0503 16:50:45.436404 10699 net.cpp:244] conv1_minus_dual does not need backward computation.
I0503 16:50:45.436406 10699 net.cpp:244] relu/conv1_dual does not need backward computation.
I0503 16:50:45.436409 10699 net.cpp:244] conv1_dual_conv1_dual_0_split does not need backward computation.
I0503 16:50:45.436411 10699 net.cpp:244] conv1_dual does not need backward computation.
I0503 16:50:45.436414 10699 net.cpp:244] data_data_scaling_0_split does not need backward computation.
I0503 16:50:45.436416 10699 net.cpp:244] data_scaling does not need backward computation.
I0503 16:50:45.436419 10699 net.cpp:244] label_data_1_split does not need backward computation.
I0503 16:50:45.436420 10699 net.cpp:244] data does not need backward computation.
I0503 16:50:45.436422 10699 net.cpp:286] This network produces output accuracy_dual
I0503 16:50:45.436425 10699 net.cpp:286] This network produces output accuracy_single
I0503 16:50:45.438061 10699 net.cpp:299] Network initialization done.
I0503 16:50:45.438144 10699 solver.cpp:60] Solver scaffolding done.
I0503 16:50:45.438508 10699 caffe.cpp:251] Starting Optimization
I0503 16:50:45.438519 10699 solver.cpp:279] Solving MNIST_NET
I0503 16:50:45.438520 10699 solver.cpp:280] Learning Rate Policy: step
I0503 16:50:45.438735 10699 solver.cpp:337] Iteration 0, Testing net (#0)
I0503 16:50:45.439144 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 16:50:45.439204 10699 net.cpp:709] Ignoring source layer loss_single
I0503 16:50:45.500780 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:50:46.045600 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.0753
I0503 16:50:46.045637 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.0818
I0503 16:50:46.053336 10699 solver.cpp:228] Iteration 0, loss = 4.82858
I0503 16:50:46.053372 10699 solver.cpp:244]     Train net output #0: loss_dual = 2.40207 (* 1 = 2.40207 loss)
I0503 16:50:46.053381 10699 solver.cpp:244]     Train net output #1: loss_single = 2.42651 (* 1 = 2.42651 loss)
I0503 16:50:46.053393 10699 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0503 16:50:59.450516 10699 solver.cpp:228] Iteration 1000, loss = 0.147439
I0503 16:50:59.450582 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.08183 (* 1 = 0.08183 loss)
I0503 16:50:59.450590 10699 solver.cpp:244]     Train net output #1: loss_single = 0.11269 (* 1 = 0.11269 loss)
I0503 16:50:59.450598 10699 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0503 16:51:12.602059 10699 solver.cpp:228] Iteration 2000, loss = 0.0938835
I0503 16:51:12.602151 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0366773 (* 1 = 0.0366773 loss)
I0503 16:51:12.602175 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0471619 (* 1 = 0.0471619 loss)
I0503 16:51:12.602195 10699 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0503 16:51:17.169875 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:51:25.581058 10699 solver.cpp:228] Iteration 3000, loss = 0.0792094
I0503 16:51:25.581087 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0484104 (* 1 = 0.0484104 loss)
I0503 16:51:25.581094 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0631509 (* 1 = 0.0631509 loss)
I0503 16:51:25.581099 10699 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0503 16:51:38.506117 10699 solver.cpp:228] Iteration 4000, loss = 0.0633621
I0503 16:51:38.506147 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0240997 (* 1 = 0.0240997 loss)
I0503 16:51:38.506153 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0433048 (* 1 = 0.0433048 loss)
I0503 16:51:38.506157 10699 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0503 16:51:49.922400 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:51:51.570793 10699 solver.cpp:337] Iteration 5000, Testing net (#0)
I0503 16:51:51.570822 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 16:51:51.570829 10699 net.cpp:709] Ignoring source layer loss_single
I0503 16:51:52.016373 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9848
I0503 16:51:52.016402 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9842
I0503 16:51:52.018684 10699 solver.cpp:228] Iteration 5000, loss = 0.0623896
I0503 16:51:52.018704 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0196587 (* 1 = 0.0196587 loss)
I0503 16:51:52.018709 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0188603 (* 1 = 0.0188603 loss)
I0503 16:51:52.018718 10699 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0503 16:52:05.107822 10699 solver.cpp:228] Iteration 6000, loss = 0.0595118
I0503 16:52:05.107856 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.018028 (* 1 = 0.018028 loss)
I0503 16:52:05.107861 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0199509 (* 1 = 0.0199509 loss)
I0503 16:52:05.107867 10699 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0503 16:52:18.396546 10699 solver.cpp:228] Iteration 7000, loss = 0.0529925
I0503 16:52:18.396580 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0149497 (* 1 = 0.0149497 loss)
I0503 16:52:18.396589 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0167253 (* 1 = 0.0167253 loss)
I0503 16:52:18.396596 10699 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0503 16:52:21.533324 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:52:31.508631 10699 solver.cpp:228] Iteration 8000, loss = 0.0402055
I0503 16:52:31.508662 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0180289 (* 1 = 0.0180289 loss)
I0503 16:52:31.508669 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0283 (* 1 = 0.0283 loss)
I0503 16:52:31.508673 10699 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0503 16:52:44.719449 10699 solver.cpp:228] Iteration 9000, loss = 0.0349815
I0503 16:52:44.719483 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0116274 (* 1 = 0.0116274 loss)
I0503 16:52:44.719490 10699 solver.cpp:244]     Train net output #1: loss_single = 0.013711 (* 1 = 0.013711 loss)
I0503 16:52:44.719494 10699 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0503 16:52:54.203670 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:52:57.591809 10699 solver.cpp:337] Iteration 10000, Testing net (#0)
I0503 16:52:57.591833 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 16:52:57.591838 10699 net.cpp:709] Ignoring source layer loss_single
I0503 16:52:58.107328 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9848
I0503 16:52:58.107357 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9853
I0503 16:52:58.109577 10699 solver.cpp:228] Iteration 10000, loss = 0.0363653
I0503 16:52:58.109598 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00842115 (* 1 = 0.00842115 loss)
I0503 16:52:58.109603 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0150575 (* 1 = 0.0150575 loss)
I0503 16:52:58.109609 10699 sgd_solver.cpp:106] Iteration 10000, lr = 0.005
I0503 16:53:11.254489 10699 solver.cpp:228] Iteration 11000, loss = 0.0252336
I0503 16:53:11.254529 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00658246 (* 1 = 0.00658246 loss)
I0503 16:53:11.254539 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0108749 (* 1 = 0.0108749 loss)
I0503 16:53:11.254547 10699 sgd_solver.cpp:106] Iteration 11000, lr = 0.005
I0503 16:53:24.208006 10699 solver.cpp:228] Iteration 12000, loss = 0.0211762
I0503 16:53:24.214848 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0106459 (* 1 = 0.0106459 loss)
I0503 16:53:24.216874 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0175558 (* 1 = 0.0175558 loss)
I0503 16:53:24.216925 10699 sgd_solver.cpp:106] Iteration 12000, lr = 0.005
I0503 16:53:25.731289 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:53:37.275333 10699 solver.cpp:228] Iteration 13000, loss = 0.0213293
I0503 16:53:37.275358 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0052148 (* 1 = 0.0052148 loss)
I0503 16:53:37.275363 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00981148 (* 1 = 0.00981148 loss)
I0503 16:53:37.275367 10699 sgd_solver.cpp:106] Iteration 13000, lr = 0.005
I0503 16:53:50.180009 10699 solver.cpp:228] Iteration 14000, loss = 0.0241974
I0503 16:53:50.180040 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0111149 (* 1 = 0.0111149 loss)
I0503 16:53:50.180047 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0170511 (* 1 = 0.0170511 loss)
I0503 16:53:50.180050 10699 sgd_solver.cpp:106] Iteration 14000, lr = 0.005
I0503 16:53:58.701395 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:54:03.521508 10699 solver.cpp:337] Iteration 15000, Testing net (#0)
I0503 16:54:03.521533 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 16:54:03.521538 10699 net.cpp:709] Ignoring source layer loss_single
I0503 16:54:04.141556 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9856
I0503 16:54:04.141579 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9856
I0503 16:54:04.152654 10699 solver.cpp:228] Iteration 15000, loss = 0.0223446
I0503 16:54:04.152721 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00691152 (* 1 = 0.00691152 loss)
I0503 16:54:04.152747 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0181719 (* 1 = 0.0181719 loss)
I0503 16:54:04.152771 10699 sgd_solver.cpp:106] Iteration 15000, lr = 0.005
I0503 16:54:17.075309 10699 solver.cpp:228] Iteration 16000, loss = 0.0202258
I0503 16:54:17.075346 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00771641 (* 1 = 0.00771641 loss)
I0503 16:54:17.075356 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0102655 (* 1 = 0.0102655 loss)
I0503 16:54:17.075363 10699 sgd_solver.cpp:106] Iteration 16000, lr = 0.005
I0503 16:54:30.156007 10699 solver.cpp:228] Iteration 17000, loss = 0.0186988
I0503 16:54:30.156316 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00531798 (* 1 = 0.00531798 loss)
I0503 16:54:30.156453 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00655696 (* 1 = 0.00655696 loss)
I0503 16:54:30.156582 10699 sgd_solver.cpp:106] Iteration 17000, lr = 0.005
I0503 16:54:31.333603 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:54:42.940332 10699 solver.cpp:228] Iteration 18000, loss = 0.0195207
I0503 16:54:42.940374 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0133727 (* 1 = 0.0133727 loss)
I0503 16:54:42.940385 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0286475 (* 1 = 0.0286475 loss)
I0503 16:54:42.940392 10699 sgd_solver.cpp:106] Iteration 18000, lr = 0.005
I0503 16:54:55.570201 10699 solver.cpp:228] Iteration 19000, loss = 0.0177512
I0503 16:54:55.570235 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00559592 (* 1 = 0.00559592 loss)
I0503 16:54:55.570245 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00829993 (* 1 = 0.00829993 loss)
I0503 16:54:55.570250 10699 sgd_solver.cpp:106] Iteration 19000, lr = 0.005
I0503 16:55:03.485991 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:55:08.753613 10699 solver.cpp:337] Iteration 20000, Testing net (#0)
I0503 16:55:08.753644 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 16:55:08.753651 10699 net.cpp:709] Ignoring source layer loss_single
I0503 16:55:09.308985 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9857
I0503 16:55:09.309010 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9855
I0503 16:55:09.311632 10699 solver.cpp:228] Iteration 20000, loss = 0.0176261
I0503 16:55:09.311658 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00418223 (* 1 = 0.00418223 loss)
I0503 16:55:09.311668 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0042214 (* 1 = 0.0042214 loss)
I0503 16:55:09.311676 10699 sgd_solver.cpp:106] Iteration 20000, lr = 0.0025
I0503 16:55:22.148916 10699 solver.cpp:228] Iteration 21000, loss = 0.0176753
I0503 16:55:22.148962 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00773608 (* 1 = 0.00773608 loss)
I0503 16:55:22.148972 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00731083 (* 1 = 0.00731083 loss)
I0503 16:55:22.148979 10699 sgd_solver.cpp:106] Iteration 21000, lr = 0.0025
I0503 16:55:35.151965 10699 solver.cpp:228] Iteration 22000, loss = 0.0166356
I0503 16:55:35.152074 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00475694 (* 1 = 0.00475694 loss)
I0503 16:55:35.152081 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00613813 (* 1 = 0.00613813 loss)
I0503 16:55:35.152086 10699 sgd_solver.cpp:106] Iteration 22000, lr = 0.0025
I0503 16:55:35.372691 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:55:48.210197 10699 solver.cpp:228] Iteration 23000, loss = 0.0156595
I0503 16:55:48.210229 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00641989 (* 1 = 0.00641989 loss)
I0503 16:55:48.210234 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0070905 (* 1 = 0.0070905 loss)
I0503 16:55:48.210238 10699 sgd_solver.cpp:106] Iteration 23000, lr = 0.0025
I0503 16:56:01.122926 10699 solver.cpp:228] Iteration 24000, loss = 0.0155967
I0503 16:56:01.122953 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00915071 (* 1 = 0.00915071 loss)
I0503 16:56:01.122959 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0117782 (* 1 = 0.0117782 loss)
I0503 16:56:01.122963 10699 sgd_solver.cpp:106] Iteration 24000, lr = 0.0025
I0503 16:56:06.871181 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:56:13.824005 10699 solver.cpp:337] Iteration 25000, Testing net (#0)
I0503 16:56:13.824093 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 16:56:13.824117 10699 net.cpp:709] Ignoring source layer loss_single
I0503 16:56:14.323868 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9856
I0503 16:56:14.323891 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9853
I0503 16:56:14.344935 10699 solver.cpp:228] Iteration 25000, loss = 0.0145774
I0503 16:56:14.344964 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00408575 (* 1 = 0.00408575 loss)
I0503 16:56:14.344971 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00664768 (* 1 = 0.00664768 loss)
I0503 16:56:14.344979 10699 sgd_solver.cpp:106] Iteration 25000, lr = 0.0025
I0503 16:56:27.266199 10699 solver.cpp:228] Iteration 26000, loss = 0.0150864
I0503 16:56:27.266299 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00518665 (* 1 = 0.00518665 loss)
I0503 16:56:27.266335 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00729795 (* 1 = 0.00729795 loss)
I0503 16:56:27.266361 10699 sgd_solver.cpp:106] Iteration 26000, lr = 0.0025
I0503 16:56:36.684012 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:56:39.963475 10699 solver.cpp:228] Iteration 27000, loss = 0.0140002
I0503 16:56:39.963604 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00688656 (* 1 = 0.00688656 loss)
I0503 16:56:39.963613 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00829939 (* 1 = 0.00829939 loss)
I0503 16:56:39.963616 10699 sgd_solver.cpp:106] Iteration 27000, lr = 0.0025
I0503 16:56:52.702060 10699 solver.cpp:228] Iteration 28000, loss = 0.0130721
I0503 16:56:52.702091 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00476357 (* 1 = 0.00476357 loss)
I0503 16:56:52.702097 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00882383 (* 1 = 0.00882383 loss)
I0503 16:56:52.702101 10699 sgd_solver.cpp:106] Iteration 28000, lr = 0.0025
I0503 16:57:05.582723 10699 solver.cpp:228] Iteration 29000, loss = 0.0128193
I0503 16:57:05.582752 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00685811 (* 1 = 0.00685811 loss)
I0503 16:57:05.582758 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0090902 (* 1 = 0.0090902 loss)
I0503 16:57:05.582763 10699 sgd_solver.cpp:106] Iteration 29000, lr = 0.0025
I0503 16:57:07.969838 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:57:18.527950 10699 solver.cpp:337] Iteration 30000, Testing net (#0)
I0503 16:57:18.528060 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 16:57:18.528069 10699 net.cpp:709] Ignoring source layer loss_single
I0503 16:57:19.125988 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9857
I0503 16:57:19.126013 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9856
I0503 16:57:19.143414 10699 solver.cpp:228] Iteration 30000, loss = 0.0122714
I0503 16:57:19.143441 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00673678 (* 1 = 0.00673678 loss)
I0503 16:57:19.143447 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00927935 (* 1 = 0.00927935 loss)
I0503 16:57:19.143453 10699 sgd_solver.cpp:106] Iteration 30000, lr = 0.00125
I0503 16:57:32.000011 10699 solver.cpp:228] Iteration 31000, loss = 0.0130316
I0503 16:57:32.000044 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00776227 (* 1 = 0.00776227 loss)
I0503 16:57:32.000051 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0140978 (* 1 = 0.0140978 loss)
I0503 16:57:32.000056 10699 sgd_solver.cpp:106] Iteration 31000, lr = 0.00125
I0503 16:57:38.554575 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:57:44.692528 10699 solver.cpp:228] Iteration 32000, loss = 0.0115584
I0503 16:57:44.692564 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00425674 (* 1 = 0.00425674 loss)
I0503 16:57:44.692572 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00683069 (* 1 = 0.00683069 loss)
I0503 16:57:44.692580 10699 sgd_solver.cpp:106] Iteration 32000, lr = 0.00125
I0503 16:57:57.369516 10699 solver.cpp:228] Iteration 33000, loss = 0.0133772
I0503 16:57:57.369597 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00396527 (* 1 = 0.00396527 loss)
I0503 16:57:57.369609 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00638202 (* 1 = 0.00638202 loss)
I0503 16:57:57.369618 10699 sgd_solver.cpp:106] Iteration 33000, lr = 0.00125
I0503 16:58:09.867012 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:58:10.294538 10699 solver.cpp:228] Iteration 34000, loss = 0.0126535
I0503 16:58:10.294657 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00627622 (* 1 = 0.00627622 loss)
I0503 16:58:10.294687 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00742944 (* 1 = 0.00742944 loss)
I0503 16:58:10.294720 10699 sgd_solver.cpp:106] Iteration 34000, lr = 0.00125
I0503 16:58:23.229537 10699 solver.cpp:337] Iteration 35000, Testing net (#0)
I0503 16:58:23.229562 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 16:58:23.229568 10699 net.cpp:709] Ignoring source layer loss_single
I0503 16:58:23.827154 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 16:58:23.827188 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9855
I0503 16:58:23.829821 10699 solver.cpp:228] Iteration 35000, loss = 0.0130019
I0503 16:58:23.829844 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00483043 (* 1 = 0.00483043 loss)
I0503 16:58:23.829850 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00611583 (* 1 = 0.00611583 loss)
I0503 16:58:23.829856 10699 sgd_solver.cpp:106] Iteration 35000, lr = 0.00125
I0503 16:58:36.651948 10699 solver.cpp:228] Iteration 36000, loss = 0.0121789
I0503 16:58:36.652072 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00300339 (* 1 = 0.00300339 loss)
I0503 16:58:36.652081 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00322994 (* 1 = 0.00322994 loss)
I0503 16:58:36.652087 10699 sgd_solver.cpp:106] Iteration 36000, lr = 0.00125
I0503 16:58:40.906013 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:58:49.536782 10699 solver.cpp:228] Iteration 37000, loss = 0.0118419
I0503 16:58:49.536941 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00680744 (* 1 = 0.00680744 loss)
I0503 16:58:49.536988 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00789286 (* 1 = 0.00789286 loss)
I0503 16:58:49.537030 10699 sgd_solver.cpp:106] Iteration 37000, lr = 0.00125
I0503 16:59:02.376369 10699 solver.cpp:228] Iteration 38000, loss = 0.0123523
I0503 16:59:02.376467 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0034766 (* 1 = 0.0034766 loss)
I0503 16:59:02.376497 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00690526 (* 1 = 0.00690526 loss)
I0503 16:59:02.376520 10699 sgd_solver.cpp:106] Iteration 38000, lr = 0.00125
I0503 16:59:12.611766 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:59:15.528391 10699 solver.cpp:228] Iteration 39000, loss = 0.0116935
I0503 16:59:15.528436 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0048497 (* 1 = 0.0048497 loss)
I0503 16:59:15.528445 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00980515 (* 1 = 0.00980515 loss)
I0503 16:59:15.528455 10699 sgd_solver.cpp:106] Iteration 39000, lr = 0.00125
I0503 16:59:26.418411 10699 solver.cpp:337] Iteration 40000, Testing net (#0)
I0503 16:59:26.418496 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 16:59:26.418524 10699 net.cpp:709] Ignoring source layer loss_single
I0503 16:59:26.894418 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9859
I0503 16:59:26.894446 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9854
I0503 16:59:26.896752 10699 solver.cpp:228] Iteration 40000, loss = 0.0132323
I0503 16:59:26.896773 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00391165 (* 1 = 0.00391165 loss)
I0503 16:59:26.896780 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00442905 (* 1 = 0.00442905 loss)
I0503 16:59:26.896787 10699 sgd_solver.cpp:106] Iteration 40000, lr = 0.000625
I0503 16:59:34.664237 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:59:37.598628 10699 solver.cpp:228] Iteration 41000, loss = 0.011365
I0503 16:59:37.598659 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00309178 (* 1 = 0.00309178 loss)
I0503 16:59:37.598665 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00525249 (* 1 = 0.00525249 loss)
I0503 16:59:37.598670 10699 sgd_solver.cpp:106] Iteration 41000, lr = 0.000625
I0503 16:59:48.192025 10699 solver.cpp:228] Iteration 42000, loss = 0.0116213
I0503 16:59:48.192198 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00417059 (* 1 = 0.00417059 loss)
I0503 16:59:48.192232 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00770548 (* 1 = 0.00770548 loss)
I0503 16:59:48.192267 10699 sgd_solver.cpp:106] Iteration 42000, lr = 0.000625
I0503 16:59:55.089432 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 16:59:58.860741 10699 solver.cpp:228] Iteration 43000, loss = 0.011521
I0503 16:59:58.860774 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00637957 (* 1 = 0.00637957 loss)
I0503 16:59:58.860779 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00934748 (* 1 = 0.00934748 loss)
I0503 16:59:58.860785 10699 sgd_solver.cpp:106] Iteration 43000, lr = 0.000625
I0503 17:00:09.105032 10699 solver.cpp:228] Iteration 44000, loss = 0.0118386
I0503 17:00:09.105070 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00758844 (* 1 = 0.00758844 loss)
I0503 17:00:09.105082 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0110993 (* 1 = 0.0110993 loss)
I0503 17:00:09.105090 10699 sgd_solver.cpp:106] Iteration 44000, lr = 0.000625
I0503 17:00:15.878494 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:00:19.660688 10699 solver.cpp:337] Iteration 45000, Testing net (#0)
I0503 17:00:19.660821 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:00:19.660909 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:00:20.028599 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9859
I0503 17:00:20.028625 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.985301
I0503 17:00:20.030890 10699 solver.cpp:228] Iteration 45000, loss = 0.0119124
I0503 17:00:20.030907 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0242851 (* 1 = 0.0242851 loss)
I0503 17:00:20.030912 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0276332 (* 1 = 0.0276332 loss)
I0503 17:00:20.030920 10699 sgd_solver.cpp:106] Iteration 45000, lr = 0.000625
I0503 17:00:30.679908 10699 solver.cpp:228] Iteration 46000, loss = 0.0112097
I0503 17:00:30.679941 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00316092 (* 1 = 0.00316092 loss)
I0503 17:00:30.679949 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00579878 (* 1 = 0.00579878 loss)
I0503 17:00:30.679953 10699 sgd_solver.cpp:106] Iteration 46000, lr = 0.000625
I0503 17:00:36.046355 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:00:41.151477 10699 solver.cpp:228] Iteration 47000, loss = 0.011112
I0503 17:00:41.151509 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00489536 (* 1 = 0.00489536 loss)
I0503 17:00:41.151515 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00639914 (* 1 = 0.00639914 loss)
I0503 17:00:41.151518 10699 sgd_solver.cpp:106] Iteration 47000, lr = 0.000625
I0503 17:00:51.903993 10699 solver.cpp:228] Iteration 48000, loss = 0.0121493
I0503 17:00:51.904119 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00431622 (* 1 = 0.00431622 loss)
I0503 17:00:51.904145 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00627409 (* 1 = 0.00627409 loss)
I0503 17:00:51.904165 10699 sgd_solver.cpp:106] Iteration 48000, lr = 0.000625
I0503 17:00:56.967064 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:01:01.897145 10699 solver.cpp:228] Iteration 49000, loss = 0.0111763
I0503 17:01:01.897187 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00235607 (* 1 = 0.00235607 loss)
I0503 17:01:01.897197 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00337596 (* 1 = 0.00337596 loss)
I0503 17:01:01.897204 10699 sgd_solver.cpp:106] Iteration 49000, lr = 0.000625
I0503 17:01:12.206984 10699 solver.cpp:337] Iteration 50000, Testing net (#0)
I0503 17:01:12.207008 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:01:12.207013 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:01:12.729851 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:01:12.729928 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9856
I0503 17:01:12.732430 10699 solver.cpp:228] Iteration 50000, loss = 0.0111266
I0503 17:01:12.732488 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0100067 (* 1 = 0.0100067 loss)
I0503 17:01:12.732524 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00813853 (* 1 = 0.00813853 loss)
I0503 17:01:12.732555 10699 sgd_solver.cpp:106] Iteration 50000, lr = 0.0003125
I0503 17:01:20.460500 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:01:25.584194 10699 solver.cpp:228] Iteration 51000, loss = 0.0112645
I0503 17:01:25.584303 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00328363 (* 1 = 0.00328363 loss)
I0503 17:01:25.584316 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00411122 (* 1 = 0.00411122 loss)
I0503 17:01:25.584323 10699 sgd_solver.cpp:106] Iteration 51000, lr = 0.0003125
I0503 17:01:38.727566 10699 solver.cpp:228] Iteration 52000, loss = 0.0113997
I0503 17:01:38.727604 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00652301 (* 1 = 0.00652301 loss)
I0503 17:01:38.727612 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00763836 (* 1 = 0.00763836 loss)
I0503 17:01:38.727622 10699 sgd_solver.cpp:106] Iteration 52000, lr = 0.0003125
I0503 17:01:51.705504 10699 solver.cpp:228] Iteration 53000, loss = 0.0113903
I0503 17:01:51.705539 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00910948 (* 1 = 0.00910948 loss)
I0503 17:01:51.705549 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0116013 (* 1 = 0.0116013 loss)
I0503 17:01:51.705556 10699 sgd_solver.cpp:106] Iteration 53000, lr = 0.0003125
I0503 17:01:53.645592 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:02:04.544049 10699 solver.cpp:228] Iteration 54000, loss = 0.0112472
I0503 17:02:04.544193 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00626957 (* 1 = 0.00626957 loss)
I0503 17:02:04.544224 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00761167 (* 1 = 0.00761167 loss)
I0503 17:02:04.544250 10699 sgd_solver.cpp:106] Iteration 54000, lr = 0.0003125
I0503 17:02:17.768448 10699 solver.cpp:337] Iteration 55000, Testing net (#0)
I0503 17:02:17.768471 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:02:17.768476 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:02:18.385895 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9859
I0503 17:02:18.385977 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9858
I0503 17:02:18.388437 10699 solver.cpp:228] Iteration 55000, loss = 0.0110186
I0503 17:02:18.388487 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00474334 (* 1 = 0.00474334 loss)
I0503 17:02:18.388521 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00459267 (* 1 = 0.00459267 loss)
I0503 17:02:18.388547 10699 sgd_solver.cpp:106] Iteration 55000, lr = 0.0003125
I0503 17:02:24.966527 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:02:31.288308 10699 solver.cpp:228] Iteration 56000, loss = 0.0108655
I0503 17:02:31.288341 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00505296 (* 1 = 0.00505296 loss)
I0503 17:02:31.288347 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00673425 (* 1 = 0.00673425 loss)
I0503 17:02:31.288352 10699 sgd_solver.cpp:106] Iteration 56000, lr = 0.0003125
I0503 17:02:44.309633 10699 solver.cpp:228] Iteration 57000, loss = 0.0112599
I0503 17:02:44.309753 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00231188 (* 1 = 0.00231188 loss)
I0503 17:02:44.309764 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00371932 (* 1 = 0.00371932 loss)
I0503 17:02:44.309773 10699 sgd_solver.cpp:106] Iteration 57000, lr = 0.0003125
I0503 17:02:56.971946 10699 solver.cpp:228] Iteration 58000, loss = 0.00994524
I0503 17:02:56.971981 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00382903 (* 1 = 0.00382903 loss)
I0503 17:02:56.971988 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00500259 (* 1 = 0.00500259 loss)
I0503 17:02:56.971993 10699 sgd_solver.cpp:106] Iteration 58000, lr = 0.0003125
I0503 17:02:57.378167 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:03:09.829612 10699 solver.cpp:228] Iteration 59000, loss = 0.0122499
I0503 17:03:09.829776 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00326424 (* 1 = 0.00326424 loss)
I0503 17:03:09.829826 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00572174 (* 1 = 0.00572174 loss)
I0503 17:03:09.829869 10699 sgd_solver.cpp:106] Iteration 59000, lr = 0.0003125
I0503 17:03:23.032611 10699 solver.cpp:337] Iteration 60000, Testing net (#0)
I0503 17:03:23.032722 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:03:23.032730 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:03:23.560045 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9863
I0503 17:03:23.560129 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9856
I0503 17:03:23.562726 10699 solver.cpp:228] Iteration 60000, loss = 0.0113147
I0503 17:03:23.562782 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00594195 (* 1 = 0.00594195 loss)
I0503 17:03:23.562816 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0118158 (* 1 = 0.0118158 loss)
I0503 17:03:23.562845 10699 sgd_solver.cpp:106] Iteration 60000, lr = 0.00015625
I0503 17:03:28.016721 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:03:36.251478 10699 solver.cpp:228] Iteration 61000, loss = 0.0114452
I0503 17:03:36.251512 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0060957 (* 1 = 0.0060957 loss)
I0503 17:03:36.251518 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00704156 (* 1 = 0.00704156 loss)
I0503 17:03:36.251523 10699 sgd_solver.cpp:106] Iteration 61000, lr = 0.00015625
I0503 17:03:49.455916 10699 solver.cpp:228] Iteration 62000, loss = 0.0117907
I0503 17:03:49.455958 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00480285 (* 1 = 0.00480285 loss)
I0503 17:03:49.455968 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00684191 (* 1 = 0.00684191 loss)
I0503 17:03:49.455976 10699 sgd_solver.cpp:106] Iteration 62000, lr = 0.00015625
I0503 17:04:01.176434 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:04:02.344292 10699 solver.cpp:228] Iteration 63000, loss = 0.0110711
I0503 17:04:02.344323 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00523384 (* 1 = 0.00523384 loss)
I0503 17:04:02.344329 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0101949 (* 1 = 0.0101949 loss)
I0503 17:04:02.344334 10699 sgd_solver.cpp:106] Iteration 63000, lr = 0.00015625
I0503 17:04:15.669677 10699 solver.cpp:228] Iteration 64000, loss = 0.0119634
I0503 17:04:15.669775 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00321748 (* 1 = 0.00321748 loss)
I0503 17:04:15.669816 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00453732 (* 1 = 0.00453732 loss)
I0503 17:04:15.669837 10699 sgd_solver.cpp:106] Iteration 64000, lr = 0.00015625
I0503 17:04:28.746083 10699 solver.cpp:337] Iteration 65000, Testing net (#0)
I0503 17:04:28.746109 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:04:28.746116 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:04:29.259964 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:04:29.259989 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9858
I0503 17:04:29.277411 10699 solver.cpp:228] Iteration 65000, loss = 0.00987562
I0503 17:04:29.277432 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00232489 (* 1 = 0.00232489 loss)
I0503 17:04:29.277438 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00333195 (* 1 = 0.00333195 loss)
I0503 17:04:29.277444 10699 sgd_solver.cpp:106] Iteration 65000, lr = 0.00015625
I0503 17:04:32.669765 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:04:42.187925 10699 solver.cpp:228] Iteration 66000, loss = 0.0112765
I0503 17:04:42.188024 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00351916 (* 1 = 0.00351916 loss)
I0503 17:04:42.188051 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0053071 (* 1 = 0.0053071 loss)
I0503 17:04:42.188073 10699 sgd_solver.cpp:106] Iteration 66000, lr = 0.00015625
I0503 17:04:54.729676 10699 solver.cpp:228] Iteration 67000, loss = 0.0100274
I0503 17:04:54.729707 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00232405 (* 1 = 0.00232405 loss)
I0503 17:04:54.729713 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00451737 (* 1 = 0.00451737 loss)
I0503 17:04:54.729718 10699 sgd_solver.cpp:106] Iteration 67000, lr = 0.00015625
I0503 17:05:03.208083 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:05:07.881494 10699 solver.cpp:228] Iteration 68000, loss = 0.0107107
I0503 17:05:07.881539 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00345333 (* 1 = 0.00345333 loss)
I0503 17:05:07.881551 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00398678 (* 1 = 0.00398678 loss)
I0503 17:05:07.881561 10699 sgd_solver.cpp:106] Iteration 68000, lr = 0.00015625
I0503 17:05:20.963459 10699 solver.cpp:228] Iteration 69000, loss = 0.0103741
I0503 17:05:20.963542 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0023829 (* 1 = 0.0023829 loss)
I0503 17:05:20.963569 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00344822 (* 1 = 0.00344822 loss)
I0503 17:05:20.963590 10699 sgd_solver.cpp:106] Iteration 69000, lr = 0.00015625
I0503 17:05:33.985301 10699 solver.cpp:337] Iteration 70000, Testing net (#0)
I0503 17:05:33.985436 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:05:33.985460 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:05:34.434314 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:05:34.522426 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.9861
I0503 17:05:34.522450 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9856
I0503 17:05:34.539881 10699 solver.cpp:228] Iteration 70000, loss = 0.0118889
I0503 17:05:34.539902 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0201561 (* 1 = 0.0201561 loss)
I0503 17:05:34.539907 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0227961 (* 1 = 0.0227961 loss)
I0503 17:05:34.539913 10699 sgd_solver.cpp:106] Iteration 70000, lr = 7.8125e-05
I0503 17:05:47.325706 10699 solver.cpp:228] Iteration 71000, loss = 0.0109544
I0503 17:05:47.325752 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00491666 (* 1 = 0.00491666 loss)
I0503 17:05:47.325764 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00609981 (* 1 = 0.00609981 loss)
I0503 17:05:47.325773 10699 sgd_solver.cpp:106] Iteration 71000, lr = 7.8125e-05
I0503 17:06:00.114732 10699 solver.cpp:228] Iteration 72000, loss = 0.0124242
I0503 17:06:00.114768 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00590619 (* 1 = 0.00590619 loss)
I0503 17:06:00.114778 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00700892 (* 1 = 0.00700892 loss)
I0503 17:06:00.114784 10699 sgd_solver.cpp:106] Iteration 72000, lr = 7.8125e-05
I0503 17:06:06.184710 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:06:13.242204 10699 solver.cpp:228] Iteration 73000, loss = 0.0102069
I0503 17:06:13.242297 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00702453 (* 1 = 0.00702453 loss)
I0503 17:06:13.242326 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00983366 (* 1 = 0.00983366 loss)
I0503 17:06:13.242347 10699 sgd_solver.cpp:106] Iteration 73000, lr = 7.8125e-05
I0503 17:06:25.874337 10699 solver.cpp:228] Iteration 74000, loss = 0.0116131
I0503 17:06:25.874377 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.004571 (* 1 = 0.004571 loss)
I0503 17:06:25.874387 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00671124 (* 1 = 0.00671124 loss)
I0503 17:06:25.874393 10699 sgd_solver.cpp:106] Iteration 74000, lr = 7.8125e-05
I0503 17:06:38.841900 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:06:39.101128 10699 solver.cpp:337] Iteration 75000, Testing net (#0)
I0503 17:06:39.101153 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:06:39.101160 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:06:39.594233 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:06:39.594261 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:06:39.596539 10699 solver.cpp:228] Iteration 75000, loss = 0.0117425
I0503 17:06:39.596561 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00417632 (* 1 = 0.00417632 loss)
I0503 17:06:39.596571 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00568988 (* 1 = 0.00568988 loss)
I0503 17:06:39.596580 10699 sgd_solver.cpp:106] Iteration 75000, lr = 7.8125e-05
I0503 17:06:52.650075 10699 solver.cpp:228] Iteration 76000, loss = 0.0110744
I0503 17:06:52.650108 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00289848 (* 1 = 0.00289848 loss)
I0503 17:06:52.650115 10699 solver.cpp:244]     Train net output #1: loss_single = 0.003676 (* 1 = 0.003676 loss)
I0503 17:06:52.650120 10699 sgd_solver.cpp:106] Iteration 76000, lr = 7.8125e-05
I0503 17:07:05.563339 10699 solver.cpp:228] Iteration 77000, loss = 0.0107882
I0503 17:07:05.563511 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00215682 (* 1 = 0.00215682 loss)
I0503 17:07:05.563583 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00208523 (* 1 = 0.00208523 loss)
I0503 17:07:05.563639 10699 sgd_solver.cpp:106] Iteration 77000, lr = 7.8125e-05
I0503 17:07:08.476068 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:07:18.529666 10699 solver.cpp:228] Iteration 78000, loss = 0.0112083
I0503 17:07:18.531286 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00399455 (* 1 = 0.00399455 loss)
I0503 17:07:18.531297 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00513738 (* 1 = 0.00513738 loss)
I0503 17:07:18.531304 10699 sgd_solver.cpp:106] Iteration 78000, lr = 7.8125e-05
I0503 17:07:31.592564 10699 solver.cpp:228] Iteration 79000, loss = 0.0101353
I0503 17:07:31.592603 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00641793 (* 1 = 0.00641793 loss)
I0503 17:07:31.592612 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00710363 (* 1 = 0.00710363 loss)
I0503 17:07:31.592622 10699 sgd_solver.cpp:106] Iteration 79000, lr = 7.8125e-05
I0503 17:07:39.626364 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:07:43.957710 10699 solver.cpp:337] Iteration 80000, Testing net (#0)
I0503 17:07:43.957741 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:07:43.957748 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:07:44.557570 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986101
I0503 17:07:44.557595 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:07:44.585435 10699 solver.cpp:228] Iteration 80000, loss = 0.0110399
I0503 17:07:44.585476 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00456013 (* 1 = 0.00456013 loss)
I0503 17:07:44.585487 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00558575 (* 1 = 0.00558575 loss)
I0503 17:07:44.585497 10699 sgd_solver.cpp:106] Iteration 80000, lr = 3.90625e-05
I0503 17:07:57.512972 10699 solver.cpp:228] Iteration 81000, loss = 0.0116621
I0503 17:07:57.513056 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00390327 (* 1 = 0.00390327 loss)
I0503 17:07:57.513063 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00581687 (* 1 = 0.00581687 loss)
I0503 17:07:57.513068 10699 sgd_solver.cpp:106] Iteration 81000, lr = 3.90625e-05
I0503 17:08:10.433204 10699 solver.cpp:228] Iteration 82000, loss = 0.0117993
I0503 17:08:10.433305 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00406428 (* 1 = 0.00406428 loss)
I0503 17:08:10.433357 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00526354 (* 1 = 0.00526354 loss)
I0503 17:08:10.433392 10699 sgd_solver.cpp:106] Iteration 82000, lr = 3.90625e-05
I0503 17:08:10.722569 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:08:23.473022 10699 solver.cpp:228] Iteration 83000, loss = 0.011769
I0503 17:08:23.473057 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00336693 (* 1 = 0.00336693 loss)
I0503 17:08:23.473064 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00497773 (* 1 = 0.00497773 loss)
I0503 17:08:23.473068 10699 sgd_solver.cpp:106] Iteration 83000, lr = 3.90625e-05
I0503 17:08:36.489661 10699 solver.cpp:228] Iteration 84000, loss = 0.0100275
I0503 17:08:36.489794 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00362604 (* 1 = 0.00362604 loss)
I0503 17:08:36.490075 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00470867 (* 1 = 0.00470867 loss)
I0503 17:08:36.490120 10699 sgd_solver.cpp:106] Iteration 84000, lr = 3.90625e-05
I0503 17:08:43.247676 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:08:49.314616 10699 solver.cpp:337] Iteration 85000, Testing net (#0)
I0503 17:08:49.314698 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:08:49.314721 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:08:49.905498 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:08:49.905583 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9856
I0503 17:08:49.908133 10699 solver.cpp:228] Iteration 85000, loss = 0.0101116
I0503 17:08:49.908155 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00372271 (* 1 = 0.00372271 loss)
I0503 17:08:49.908164 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00395555 (* 1 = 0.00395555 loss)
I0503 17:08:49.908172 10699 sgd_solver.cpp:106] Iteration 85000, lr = 3.90625e-05
I0503 17:09:02.665752 10699 solver.cpp:228] Iteration 86000, loss = 0.0104202
I0503 17:09:02.665792 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00410995 (* 1 = 0.00410995 loss)
I0503 17:09:02.665802 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0052529 (* 1 = 0.0052529 loss)
I0503 17:09:02.665812 10699 sgd_solver.cpp:106] Iteration 86000, lr = 3.90625e-05
I0503 17:09:14.341307 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:09:15.891263 10699 solver.cpp:228] Iteration 87000, loss = 0.0114508
I0503 17:09:15.891300 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00360939 (* 1 = 0.00360939 loss)
I0503 17:09:15.891311 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00784537 (* 1 = 0.00784537 loss)
I0503 17:09:15.891320 10699 sgd_solver.cpp:106] Iteration 87000, lr = 3.90625e-05
I0503 17:09:28.683563 10699 solver.cpp:228] Iteration 88000, loss = 0.0120416
I0503 17:09:28.683590 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00341182 (* 1 = 0.00341182 loss)
I0503 17:09:28.683595 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00496325 (* 1 = 0.00496325 loss)
I0503 17:09:28.683599 10699 sgd_solver.cpp:106] Iteration 88000, lr = 3.90625e-05
I0503 17:09:41.461922 10699 solver.cpp:228] Iteration 89000, loss = 0.0102449
I0503 17:09:41.461957 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00642808 (* 1 = 0.00642808 loss)
I0503 17:09:41.461964 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00979395 (* 1 = 0.00979395 loss)
I0503 17:09:41.461971 10699 sgd_solver.cpp:106] Iteration 89000, lr = 3.90625e-05
I0503 17:09:46.398288 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:09:54.484941 10699 solver.cpp:337] Iteration 90000, Testing net (#0)
I0503 17:09:54.485026 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:09:54.485059 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:09:54.978124 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:09:54.978157 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9856
I0503 17:09:54.998150 10699 solver.cpp:228] Iteration 90000, loss = 0.0112435
I0503 17:09:54.998185 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00306744 (* 1 = 0.00306744 loss)
I0503 17:09:54.998193 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00514819 (* 1 = 0.00514819 loss)
I0503 17:09:54.998201 10699 sgd_solver.cpp:106] Iteration 90000, lr = 1.95312e-05
I0503 17:10:07.879065 10699 solver.cpp:228] Iteration 91000, loss = 0.00957314
I0503 17:10:07.879104 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.002892 (* 1 = 0.002892 loss)
I0503 17:10:07.879115 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00534052 (* 1 = 0.00534052 loss)
I0503 17:10:07.879123 10699 sgd_solver.cpp:106] Iteration 91000, lr = 1.95312e-05
I0503 17:10:16.897042 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:10:20.693179 10699 solver.cpp:228] Iteration 92000, loss = 0.0106199
I0503 17:10:20.693215 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00553239 (* 1 = 0.00553239 loss)
I0503 17:10:20.693223 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00815109 (* 1 = 0.00815109 loss)
I0503 17:10:20.693231 10699 sgd_solver.cpp:106] Iteration 92000, lr = 1.95312e-05
I0503 17:10:33.400229 10699 solver.cpp:228] Iteration 93000, loss = 0.0101248
I0503 17:10:33.400267 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00374919 (* 1 = 0.00374919 loss)
I0503 17:10:33.400276 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00572928 (* 1 = 0.00572928 loss)
I0503 17:10:33.400283 10699 sgd_solver.cpp:106] Iteration 93000, lr = 1.95312e-05
I0503 17:10:46.216620 10699 solver.cpp:228] Iteration 94000, loss = 0.0102319
I0503 17:10:46.216665 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00290544 (* 1 = 0.00290544 loss)
I0503 17:10:46.216680 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00419375 (* 1 = 0.00419375 loss)
I0503 17:10:46.216692 10699 sgd_solver.cpp:106] Iteration 94000, lr = 1.95312e-05
I0503 17:10:48.425611 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:10:59.209974 10699 solver.cpp:337] Iteration 95000, Testing net (#0)
I0503 17:10:59.210002 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:10:59.210008 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:10:59.741031 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:10:59.741055 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:10:59.748956 10699 solver.cpp:228] Iteration 95000, loss = 0.0107275
I0503 17:10:59.749020 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00579755 (* 1 = 0.00579755 loss)
I0503 17:10:59.749048 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0092986 (* 1 = 0.0092986 loss)
I0503 17:10:59.749073 10699 sgd_solver.cpp:106] Iteration 95000, lr = 1.95312e-05
I0503 17:11:12.900802 10699 solver.cpp:228] Iteration 96000, loss = 0.0103999
I0503 17:11:12.900907 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00402035 (* 1 = 0.00402035 loss)
I0503 17:11:12.900938 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00535887 (* 1 = 0.00535887 loss)
I0503 17:11:12.900970 10699 sgd_solver.cpp:106] Iteration 96000, lr = 1.95312e-05
I0503 17:11:19.646724 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:11:26.229929 10699 solver.cpp:228] Iteration 97000, loss = 0.0101615
I0503 17:11:26.230020 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00389292 (* 1 = 0.00389292 loss)
I0503 17:11:26.230052 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00566829 (* 1 = 0.00566829 loss)
I0503 17:11:26.230079 10699 sgd_solver.cpp:106] Iteration 97000, lr = 1.95312e-05
I0503 17:11:39.128773 10699 solver.cpp:228] Iteration 98000, loss = 0.011806
I0503 17:11:39.128808 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00528264 (* 1 = 0.00528264 loss)
I0503 17:11:39.128818 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00562015 (* 1 = 0.00562015 loss)
I0503 17:11:39.128826 10699 sgd_solver.cpp:106] Iteration 98000, lr = 1.95312e-05
I0503 17:11:51.173168 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:11:51.889384 10699 solver.cpp:228] Iteration 99000, loss = 0.011204
I0503 17:11:51.889422 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00215711 (* 1 = 0.00215711 loss)
I0503 17:11:51.889432 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00245655 (* 1 = 0.00245655 loss)
I0503 17:11:51.889439 10699 sgd_solver.cpp:106] Iteration 99000, lr = 1.95312e-05
I0503 17:12:04.952931 10699 solver.cpp:454] Snapshotting to binary proto file mnist_iter_100000.caffemodel
I0503 17:12:04.959498 10699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mnist_iter_100000.solverstate
I0503 17:12:04.960172 10699 solver.cpp:337] Iteration 100000, Testing net (#0)
I0503 17:12:04.960189 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:12:04.960196 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:12:05.539669 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:12:05.539698 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:12:05.555902 10699 solver.cpp:228] Iteration 100000, loss = 0.0103444
I0503 17:12:05.555932 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00463946 (* 1 = 0.00463946 loss)
I0503 17:12:05.555940 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00582152 (* 1 = 0.00582152 loss)
I0503 17:12:05.555949 10699 sgd_solver.cpp:106] Iteration 100000, lr = 9.76562e-06
I0503 17:12:18.493472 10699 solver.cpp:228] Iteration 101000, loss = 0.0103937
I0503 17:12:18.493515 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00254678 (* 1 = 0.00254678 loss)
I0503 17:12:18.493527 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00444835 (* 1 = 0.00444835 loss)
I0503 17:12:18.493535 10699 sgd_solver.cpp:106] Iteration 101000, lr = 9.76562e-06
I0503 17:12:21.975366 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:12:31.165071 10699 solver.cpp:228] Iteration 102000, loss = 0.0101055
I0503 17:12:31.165154 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00343021 (* 1 = 0.00343021 loss)
I0503 17:12:31.165197 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00643226 (* 1 = 0.00643226 loss)
I0503 17:12:31.165223 10699 sgd_solver.cpp:106] Iteration 102000, lr = 9.76562e-06
I0503 17:12:43.980936 10699 solver.cpp:228] Iteration 103000, loss = 0.00966319
I0503 17:12:43.980968 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00533965 (* 1 = 0.00533965 loss)
I0503 17:12:43.980978 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00742659 (* 1 = 0.00742659 loss)
I0503 17:12:43.980986 10699 sgd_solver.cpp:106] Iteration 103000, lr = 9.76562e-06
I0503 17:12:53.046061 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:12:56.671840 10699 solver.cpp:228] Iteration 104000, loss = 0.0121173
I0503 17:12:56.671869 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00307359 (* 1 = 0.00307359 loss)
I0503 17:12:56.671875 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00396421 (* 1 = 0.00396421 loss)
I0503 17:12:56.671881 10699 sgd_solver.cpp:106] Iteration 104000, lr = 9.76562e-06
I0503 17:13:09.202817 10699 solver.cpp:337] Iteration 105000, Testing net (#0)
I0503 17:13:09.202847 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:13:09.202853 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:13:09.715364 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:13:09.715440 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:13:09.718004 10699 solver.cpp:228] Iteration 105000, loss = 0.0102879
I0503 17:13:09.718062 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00396174 (* 1 = 0.00396174 loss)
I0503 17:13:09.718098 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00396782 (* 1 = 0.00396782 loss)
I0503 17:13:09.718148 10699 sgd_solver.cpp:106] Iteration 105000, lr = 9.76562e-06
I0503 17:13:21.590963 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:13:22.805745 10699 solver.cpp:228] Iteration 106000, loss = 0.012566
I0503 17:13:22.805775 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0105388 (* 1 = 0.0105388 loss)
I0503 17:13:22.805780 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0168995 (* 1 = 0.0168995 loss)
I0503 17:13:22.805785 10699 sgd_solver.cpp:106] Iteration 106000, lr = 9.76562e-06
I0503 17:13:35.635645 10699 solver.cpp:228] Iteration 107000, loss = 0.0105735
I0503 17:13:35.635746 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00523416 (* 1 = 0.00523416 loss)
I0503 17:13:35.635752 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00736051 (* 1 = 0.00736051 loss)
I0503 17:13:35.635759 10699 sgd_solver.cpp:106] Iteration 107000, lr = 9.76562e-06
I0503 17:13:48.170961 10699 solver.cpp:228] Iteration 108000, loss = 0.0101234
I0503 17:13:48.171001 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0058662 (* 1 = 0.0058662 loss)
I0503 17:13:48.171010 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00784263 (* 1 = 0.00784263 loss)
I0503 17:13:48.171017 10699 sgd_solver.cpp:106] Iteration 108000, lr = 9.76562e-06
I0503 17:13:50.832006 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:13:58.239967 10699 solver.cpp:228] Iteration 109000, loss = 0.0111029
I0503 17:13:58.240002 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00434502 (* 1 = 0.00434502 loss)
I0503 17:13:58.240010 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0068224 (* 1 = 0.0068224 loss)
I0503 17:13:58.240020 10699 sgd_solver.cpp:106] Iteration 109000, lr = 9.76562e-06
I0503 17:14:08.693825 10699 solver.cpp:337] Iteration 110000, Testing net (#0)
I0503 17:14:08.693953 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:14:08.693979 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:14:09.111543 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:14:09.111579 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:14:09.130586 10699 solver.cpp:228] Iteration 110000, loss = 0.0107222
I0503 17:14:09.130620 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00462864 (* 1 = 0.00462864 loss)
I0503 17:14:09.130630 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00475234 (* 1 = 0.00475234 loss)
I0503 17:14:09.130643 10699 sgd_solver.cpp:106] Iteration 110000, lr = 4.88281e-06
I0503 17:14:10.217118 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:14:19.810986 10699 solver.cpp:228] Iteration 111000, loss = 0.0111765
I0503 17:14:19.811018 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00543136 (* 1 = 0.00543136 loss)
I0503 17:14:19.811024 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00848132 (* 1 = 0.00848132 loss)
I0503 17:14:19.811031 10699 sgd_solver.cpp:106] Iteration 111000, lr = 4.88281e-06
I0503 17:14:30.265167 10699 solver.cpp:228] Iteration 112000, loss = 0.0116499
I0503 17:14:30.265261 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00624213 (* 1 = 0.00624213 loss)
I0503 17:14:30.265288 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00843904 (* 1 = 0.00843904 loss)
I0503 17:14:30.265310 10699 sgd_solver.cpp:106] Iteration 112000, lr = 4.88281e-06
I0503 17:14:30.692782 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:14:40.782110 10699 solver.cpp:228] Iteration 113000, loss = 0.0111213
I0503 17:14:40.782209 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00866085 (* 1 = 0.00866085 loss)
I0503 17:14:40.782217 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0111409 (* 1 = 0.0111409 loss)
I0503 17:14:40.782222 10699 sgd_solver.cpp:106] Iteration 113000, lr = 4.88281e-06
I0503 17:14:51.332607 10699 solver.cpp:228] Iteration 114000, loss = 0.0110293
I0503 17:14:51.332643 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00460409 (* 1 = 0.00460409 loss)
I0503 17:14:51.332651 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00499065 (* 1 = 0.00499065 loss)
I0503 17:14:51.332660 10699 sgd_solver.cpp:106] Iteration 114000, lr = 4.88281e-06
I0503 17:14:52.260876 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:15:02.083941 10699 solver.cpp:337] Iteration 115000, Testing net (#0)
I0503 17:15:02.084025 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:15:02.084053 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:15:02.541381 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:15:02.541406 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:15:02.545403 10699 solver.cpp:228] Iteration 115000, loss = 0.0106154
I0503 17:15:02.545469 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00247643 (* 1 = 0.00247643 loss)
I0503 17:15:02.545501 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00301344 (* 1 = 0.00301344 loss)
I0503 17:15:02.545529 10699 sgd_solver.cpp:106] Iteration 115000, lr = 4.88281e-06
I0503 17:15:11.680023 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:15:13.271114 10699 solver.cpp:228] Iteration 116000, loss = 0.0111442
I0503 17:15:13.271153 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00999302 (* 1 = 0.00999302 loss)
I0503 17:15:13.271164 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0144179 (* 1 = 0.0144179 loss)
I0503 17:15:13.271174 10699 sgd_solver.cpp:106] Iteration 116000, lr = 4.88281e-06
I0503 17:15:24.208103 10699 solver.cpp:228] Iteration 117000, loss = 0.0106305
I0503 17:15:24.208199 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00569478 (* 1 = 0.00569478 loss)
I0503 17:15:24.208225 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00951675 (* 1 = 0.00951675 loss)
I0503 17:15:24.208245 10699 sgd_solver.cpp:106] Iteration 117000, lr = 4.88281e-06
I0503 17:15:32.005798 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:15:34.519160 10699 solver.cpp:228] Iteration 118000, loss = 0.0105428
I0503 17:15:34.519192 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00482885 (* 1 = 0.00482885 loss)
I0503 17:15:34.519198 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0063936 (* 1 = 0.0063936 loss)
I0503 17:15:34.519204 10699 sgd_solver.cpp:106] Iteration 118000, lr = 4.88281e-06
I0503 17:15:46.766532 10699 solver.cpp:228] Iteration 119000, loss = 0.0107575
I0503 17:15:46.766607 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00483945 (* 1 = 0.00483945 loss)
I0503 17:15:46.766614 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00757038 (* 1 = 0.00757038 loss)
I0503 17:15:46.766620 10699 sgd_solver.cpp:106] Iteration 119000, lr = 4.88281e-06
I0503 17:15:59.685480 10699 solver.cpp:337] Iteration 120000, Testing net (#0)
I0503 17:15:59.685500 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:15:59.685505 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:15:59.847806 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:16:00.273118 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:16:00.273146 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:16:00.275992 10699 solver.cpp:228] Iteration 120000, loss = 0.0109967
I0503 17:16:00.276018 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00498462 (* 1 = 0.00498462 loss)
I0503 17:16:00.276211 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00963803 (* 1 = 0.00963803 loss)
I0503 17:16:00.276347 10699 sgd_solver.cpp:106] Iteration 120000, lr = 2.44141e-06
I0503 17:16:13.333024 10699 solver.cpp:228] Iteration 121000, loss = 0.0100461
I0503 17:16:13.333119 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00687184 (* 1 = 0.00687184 loss)
I0503 17:16:13.333174 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0107928 (* 1 = 0.0107928 loss)
I0503 17:16:13.333202 10699 sgd_solver.cpp:106] Iteration 121000, lr = 2.44141e-06
I0503 17:16:26.488842 10699 solver.cpp:228] Iteration 122000, loss = 0.0102088
I0503 17:16:26.489001 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00217206 (* 1 = 0.00217206 loss)
I0503 17:16:26.489029 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00314606 (* 1 = 0.00314606 loss)
I0503 17:16:26.489054 10699 sgd_solver.cpp:106] Iteration 122000, lr = 2.44141e-06
I0503 17:16:31.391510 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:16:39.313700 10699 solver.cpp:228] Iteration 123000, loss = 0.0108436
I0503 17:16:39.313802 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00371082 (* 1 = 0.00371082 loss)
I0503 17:16:39.313828 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0034789 (* 1 = 0.0034789 loss)
I0503 17:16:39.313849 10699 sgd_solver.cpp:106] Iteration 123000, lr = 2.44141e-06
I0503 17:16:52.154749 10699 solver.cpp:228] Iteration 124000, loss = 0.0109605
I0503 17:16:52.154780 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00421145 (* 1 = 0.00421145 loss)
I0503 17:16:52.154786 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00661964 (* 1 = 0.00661964 loss)
I0503 17:16:52.154793 10699 sgd_solver.cpp:106] Iteration 124000, lr = 2.44141e-06
I0503 17:17:03.782866 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:17:05.237514 10699 solver.cpp:337] Iteration 125000, Testing net (#0)
I0503 17:17:05.237609 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:17:05.237637 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:17:05.801671 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:17:05.801698 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:17:05.819784 10699 solver.cpp:228] Iteration 125000, loss = 0.0101963
I0503 17:17:05.819810 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00722281 (* 1 = 0.00722281 loss)
I0503 17:17:05.819816 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00996986 (* 1 = 0.00996986 loss)
I0503 17:17:05.819823 10699 sgd_solver.cpp:106] Iteration 125000, lr = 2.44141e-06
I0503 17:17:18.920552 10699 solver.cpp:228] Iteration 126000, loss = 0.0109588
I0503 17:17:18.920588 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00463656 (* 1 = 0.00463656 loss)
I0503 17:17:18.920596 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00726476 (* 1 = 0.00726476 loss)
I0503 17:17:18.920603 10699 sgd_solver.cpp:106] Iteration 126000, lr = 2.44141e-06
I0503 17:17:31.953327 10699 solver.cpp:228] Iteration 127000, loss = 0.00951967
I0503 17:17:31.953414 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00643155 (* 1 = 0.00643155 loss)
I0503 17:17:31.953440 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00666117 (* 1 = 0.00666117 loss)
I0503 17:17:31.953459 10699 sgd_solver.cpp:106] Iteration 127000, lr = 2.44141e-06
I0503 17:17:35.525961 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:17:44.724934 10699 solver.cpp:228] Iteration 128000, loss = 0.0114938
I0503 17:17:44.724967 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00627601 (* 1 = 0.00627601 loss)
I0503 17:17:44.724973 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0144742 (* 1 = 0.0144742 loss)
I0503 17:17:44.724979 10699 sgd_solver.cpp:106] Iteration 128000, lr = 2.44141e-06
I0503 17:17:57.553239 10699 solver.cpp:228] Iteration 129000, loss = 0.0111719
I0503 17:17:57.553274 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00529888 (* 1 = 0.00529888 loss)
I0503 17:17:57.553282 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00556166 (* 1 = 0.00556166 loss)
I0503 17:17:57.553287 10699 sgd_solver.cpp:106] Iteration 129000, lr = 2.44141e-06
I0503 17:18:07.723778 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:18:10.567955 10699 solver.cpp:337] Iteration 130000, Testing net (#0)
I0503 17:18:10.567983 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:18:10.567991 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:18:11.117861 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:18:11.117897 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:18:11.120422 10699 solver.cpp:228] Iteration 130000, loss = 0.0106338
I0503 17:18:11.120450 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00596501 (* 1 = 0.00596501 loss)
I0503 17:18:11.120461 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00691004 (* 1 = 0.00691004 loss)
I0503 17:18:11.120472 10699 sgd_solver.cpp:106] Iteration 130000, lr = 1.2207e-06
I0503 17:18:24.097463 10699 solver.cpp:228] Iteration 131000, loss = 0.0107444
I0503 17:18:24.097496 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00484907 (* 1 = 0.00484907 loss)
I0503 17:18:24.097501 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0061543 (* 1 = 0.0061543 loss)
I0503 17:18:24.097506 10699 sgd_solver.cpp:106] Iteration 131000, lr = 1.2207e-06
I0503 17:18:37.090174 10699 solver.cpp:228] Iteration 132000, loss = 0.0107541
I0503 17:18:37.090207 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00878207 (* 1 = 0.00878207 loss)
I0503 17:18:37.090216 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0197736 (* 1 = 0.0197736 loss)
I0503 17:18:37.090225 10699 sgd_solver.cpp:106] Iteration 132000, lr = 1.2207e-06
I0503 17:18:38.382863 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:18:50.048754 10699 solver.cpp:228] Iteration 133000, loss = 0.0100013
I0503 17:18:50.048786 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00231609 (* 1 = 0.00231609 loss)
I0503 17:18:50.048792 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00324351 (* 1 = 0.00324351 loss)
I0503 17:18:50.048797 10699 sgd_solver.cpp:106] Iteration 133000, lr = 1.2207e-06
I0503 17:19:03.274314 10699 solver.cpp:228] Iteration 134000, loss = 0.0102416
I0503 17:19:03.274422 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00283147 (* 1 = 0.00283147 loss)
I0503 17:19:03.274456 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00359782 (* 1 = 0.00359782 loss)
I0503 17:19:03.274484 10699 sgd_solver.cpp:106] Iteration 134000, lr = 1.2207e-06
I0503 17:19:10.747007 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:19:15.909615 10699 solver.cpp:337] Iteration 135000, Testing net (#0)
I0503 17:19:15.909637 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:19:15.909642 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:19:16.601986 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:19:16.602010 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:19:16.621229 10699 solver.cpp:228] Iteration 135000, loss = 0.0100697
I0503 17:19:16.621255 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00451871 (* 1 = 0.00451871 loss)
I0503 17:19:16.621261 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00540148 (* 1 = 0.00540148 loss)
I0503 17:19:16.621268 10699 sgd_solver.cpp:106] Iteration 135000, lr = 1.2207e-06
I0503 17:19:29.375576 10699 solver.cpp:228] Iteration 136000, loss = 0.011512
I0503 17:19:29.375617 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00470524 (* 1 = 0.00470524 loss)
I0503 17:19:29.375627 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00511563 (* 1 = 0.00511563 loss)
I0503 17:19:29.375635 10699 sgd_solver.cpp:106] Iteration 136000, lr = 1.2207e-06
I0503 17:19:40.570575 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:19:41.835593 10699 solver.cpp:228] Iteration 137000, loss = 0.0108211
I0503 17:19:41.835708 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00370342 (* 1 = 0.00370342 loss)
I0503 17:19:41.835718 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00525303 (* 1 = 0.00525303 loss)
I0503 17:19:41.835726 10699 sgd_solver.cpp:106] Iteration 137000, lr = 1.2207e-06
I0503 17:19:54.856302 10699 solver.cpp:228] Iteration 138000, loss = 0.0106143
I0503 17:19:54.856336 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0037484 (* 1 = 0.0037484 loss)
I0503 17:19:54.856343 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00399562 (* 1 = 0.00399562 loss)
I0503 17:19:54.856348 10699 sgd_solver.cpp:106] Iteration 138000, lr = 1.2207e-06
I0503 17:20:07.754643 10699 solver.cpp:228] Iteration 139000, loss = 0.01041
I0503 17:20:07.754683 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00779066 (* 1 = 0.00779066 loss)
I0503 17:20:07.754693 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00801752 (* 1 = 0.00801752 loss)
I0503 17:20:07.754700 10699 sgd_solver.cpp:106] Iteration 139000, lr = 1.2207e-06
I0503 17:20:13.435909 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:20:20.896626 10699 solver.cpp:337] Iteration 140000, Testing net (#0)
I0503 17:20:20.896647 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:20:20.896652 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:20:21.501957 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:20:21.501986 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:20:21.504245 10699 solver.cpp:228] Iteration 140000, loss = 0.0113794
I0503 17:20:21.504266 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00597329 (* 1 = 0.00597329 loss)
I0503 17:20:21.504277 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0110684 (* 1 = 0.0110684 loss)
I0503 17:20:21.504287 10699 sgd_solver.cpp:106] Iteration 140000, lr = 6.10352e-07
I0503 17:20:34.588835 10699 solver.cpp:228] Iteration 141000, loss = 0.0101668
I0503 17:20:34.588871 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00373856 (* 1 = 0.00373856 loss)
I0503 17:20:34.588879 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00652042 (* 1 = 0.00652042 loss)
I0503 17:20:34.588886 10699 sgd_solver.cpp:106] Iteration 141000, lr = 6.10352e-07
I0503 17:20:45.859174 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:20:47.115301 10699 solver.cpp:228] Iteration 142000, loss = 0.0116748
I0503 17:20:47.115334 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00696189 (* 1 = 0.00696189 loss)
I0503 17:20:47.115339 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00931831 (* 1 = 0.00931831 loss)
I0503 17:20:47.115345 10699 sgd_solver.cpp:106] Iteration 142000, lr = 6.10352e-07
I0503 17:20:59.739547 10699 solver.cpp:228] Iteration 143000, loss = 0.0107239
I0503 17:20:59.739578 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00404125 (* 1 = 0.00404125 loss)
I0503 17:20:59.739584 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00438956 (* 1 = 0.00438956 loss)
I0503 17:20:59.739588 10699 sgd_solver.cpp:106] Iteration 143000, lr = 6.10352e-07
I0503 17:21:12.620337 10699 solver.cpp:228] Iteration 144000, loss = 0.01133
I0503 17:21:12.620368 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00538826 (* 1 = 0.00538826 loss)
I0503 17:21:12.620374 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00748831 (* 1 = 0.00748831 loss)
I0503 17:21:12.620380 10699 sgd_solver.cpp:106] Iteration 144000, lr = 6.10352e-07
I0503 17:21:17.502805 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:21:25.615214 10699 solver.cpp:337] Iteration 145000, Testing net (#0)
I0503 17:21:25.615242 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:21:25.615248 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:21:26.150926 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:21:26.150959 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:21:26.153434 10699 solver.cpp:228] Iteration 145000, loss = 0.010618
I0503 17:21:26.153463 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00315577 (* 1 = 0.00315577 loss)
I0503 17:21:26.153473 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00553314 (* 1 = 0.00553314 loss)
I0503 17:21:26.153482 10699 sgd_solver.cpp:106] Iteration 145000, lr = 6.10352e-07
I0503 17:21:39.250749 10699 solver.cpp:228] Iteration 146000, loss = 0.0109614
I0503 17:21:39.250790 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00320813 (* 1 = 0.00320813 loss)
I0503 17:21:39.250802 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00511134 (* 1 = 0.00511134 loss)
I0503 17:21:39.250809 10699 sgd_solver.cpp:106] Iteration 146000, lr = 6.10352e-07
I0503 17:21:49.106315 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:21:52.147104 10699 solver.cpp:228] Iteration 147000, loss = 0.0112648
I0503 17:21:52.147145 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00289273 (* 1 = 0.00289273 loss)
I0503 17:21:52.147155 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00403637 (* 1 = 0.00403637 loss)
I0503 17:21:52.147162 10699 sgd_solver.cpp:106] Iteration 147000, lr = 6.10352e-07
I0503 17:22:04.938397 10699 solver.cpp:228] Iteration 148000, loss = 0.0117153
I0503 17:22:04.938433 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00419685 (* 1 = 0.00419685 loss)
I0503 17:22:04.938442 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00542248 (* 1 = 0.00542248 loss)
I0503 17:22:04.938452 10699 sgd_solver.cpp:106] Iteration 148000, lr = 6.10352e-07
I0503 17:22:18.079860 10699 solver.cpp:228] Iteration 149000, loss = 0.0113061
I0503 17:22:18.079903 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00476976 (* 1 = 0.00476976 loss)
I0503 17:22:18.079915 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00682977 (* 1 = 0.00682977 loss)
I0503 17:22:18.079921 10699 sgd_solver.cpp:106] Iteration 149000, lr = 6.10352e-07
I0503 17:22:21.115141 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:22:31.191303 10699 solver.cpp:337] Iteration 150000, Testing net (#0)
I0503 17:22:31.191334 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:22:31.191341 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:22:31.741605 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:22:31.741632 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:22:31.744253 10699 solver.cpp:228] Iteration 150000, loss = 0.0103386
I0503 17:22:31.744324 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00352233 (* 1 = 0.00352233 loss)
I0503 17:22:31.744355 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00430191 (* 1 = 0.00430191 loss)
I0503 17:22:31.744384 10699 sgd_solver.cpp:106] Iteration 150000, lr = 3.05176e-07
I0503 17:22:44.621093 10699 solver.cpp:228] Iteration 151000, loss = 0.0110965
I0503 17:22:44.621126 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00293266 (* 1 = 0.00293266 loss)
I0503 17:22:44.621132 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00297499 (* 1 = 0.00297499 loss)
I0503 17:22:44.621139 10699 sgd_solver.cpp:106] Iteration 151000, lr = 3.05176e-07
I0503 17:22:52.454974 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:22:57.495028 10699 solver.cpp:228] Iteration 152000, loss = 0.0111985
I0503 17:22:57.495062 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00900962 (* 1 = 0.00900962 loss)
I0503 17:22:57.495071 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0119468 (* 1 = 0.0119468 loss)
I0503 17:22:57.495080 10699 sgd_solver.cpp:106] Iteration 152000, lr = 3.05176e-07
I0503 17:23:10.078083 10699 solver.cpp:228] Iteration 153000, loss = 0.0107498
I0503 17:23:10.078125 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00383243 (* 1 = 0.00383243 loss)
I0503 17:23:10.078135 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0069242 (* 1 = 0.0069242 loss)
I0503 17:23:10.078143 10699 sgd_solver.cpp:106] Iteration 153000, lr = 3.05176e-07
I0503 17:23:23.086743 10699 solver.cpp:228] Iteration 154000, loss = 0.010814
I0503 17:23:23.086902 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00284773 (* 1 = 0.00284773 loss)
I0503 17:23:23.086928 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00655607 (* 1 = 0.00655607 loss)
I0503 17:23:23.086948 10699 sgd_solver.cpp:106] Iteration 154000, lr = 3.05176e-07
I0503 17:23:23.103611 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:23:35.874151 10699 solver.cpp:337] Iteration 155000, Testing net (#0)
I0503 17:23:35.874178 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:23:35.874186 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:23:36.490948 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:23:36.491031 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:23:36.500243 10699 solver.cpp:228] Iteration 155000, loss = 0.0101996
I0503 17:23:36.500283 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00222543 (* 1 = 0.00222543 loss)
I0503 17:23:36.500291 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00182217 (* 1 = 0.00182217 loss)
I0503 17:23:36.500299 10699 sgd_solver.cpp:106] Iteration 155000, lr = 3.05176e-07
I0503 17:23:49.268874 10699 solver.cpp:228] Iteration 156000, loss = 0.0104043
I0503 17:23:49.268978 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00642663 (* 1 = 0.00642663 loss)
I0503 17:23:49.269009 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0108436 (* 1 = 0.0108436 loss)
I0503 17:23:49.269021 10699 sgd_solver.cpp:106] Iteration 156000, lr = 3.05176e-07
I0503 17:23:53.366909 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:24:02.241699 10699 solver.cpp:228] Iteration 157000, loss = 0.00990114
I0503 17:24:02.241746 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00440217 (* 1 = 0.00440217 loss)
I0503 17:24:02.241758 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00604749 (* 1 = 0.00604749 loss)
I0503 17:24:02.241767 10699 sgd_solver.cpp:106] Iteration 157000, lr = 3.05176e-07
I0503 17:24:15.376248 10699 solver.cpp:228] Iteration 158000, loss = 0.0118089
I0503 17:24:15.376292 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00246783 (* 1 = 0.00246783 loss)
I0503 17:24:15.376304 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0036897 (* 1 = 0.0036897 loss)
I0503 17:24:15.376312 10699 sgd_solver.cpp:106] Iteration 158000, lr = 3.05176e-07
I0503 17:24:25.697221 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:24:28.363030 10699 solver.cpp:228] Iteration 159000, loss = 0.0110109
I0503 17:24:28.363060 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00683098 (* 1 = 0.00683098 loss)
I0503 17:24:28.363066 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00779671 (* 1 = 0.00779671 loss)
I0503 17:24:28.363071 10699 sgd_solver.cpp:106] Iteration 159000, lr = 3.05176e-07
I0503 17:24:41.610172 10699 solver.cpp:337] Iteration 160000, Testing net (#0)
I0503 17:24:41.610194 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:24:41.610200 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:24:42.150684 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:24:42.150708 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:24:42.171028 10699 solver.cpp:228] Iteration 160000, loss = 0.0101207
I0503 17:24:42.171047 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00494561 (* 1 = 0.00494561 loss)
I0503 17:24:42.171053 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00589052 (* 1 = 0.00589052 loss)
I0503 17:24:42.171058 10699 sgd_solver.cpp:106] Iteration 160000, lr = 1.52588e-07
I0503 17:24:55.192612 10699 solver.cpp:228] Iteration 161000, loss = 0.00949407
I0503 17:24:55.194109 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0041445 (* 1 = 0.0041445 loss)
I0503 17:24:55.195703 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00609675 (* 1 = 0.00609675 loss)
I0503 17:24:55.195767 10699 sgd_solver.cpp:106] Iteration 161000, lr = 1.52588e-07
I0503 17:24:56.780048 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:25:08.334100 10699 solver.cpp:228] Iteration 162000, loss = 0.0111362
I0503 17:25:08.334136 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00528231 (* 1 = 0.00528231 loss)
I0503 17:25:08.334146 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00839333 (* 1 = 0.00839333 loss)
I0503 17:25:08.334151 10699 sgd_solver.cpp:106] Iteration 162000, lr = 1.52588e-07
I0503 17:25:21.871495 10699 solver.cpp:228] Iteration 163000, loss = 0.0102076
I0503 17:25:21.871526 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00323757 (* 1 = 0.00323757 loss)
I0503 17:25:21.871531 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00656795 (* 1 = 0.00656795 loss)
I0503 17:25:21.871536 10699 sgd_solver.cpp:106] Iteration 163000, lr = 1.52588e-07
I0503 17:25:31.910562 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:25:35.071332 10699 solver.cpp:228] Iteration 164000, loss = 0.0103717
I0503 17:25:35.071363 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00378613 (* 1 = 0.00378613 loss)
I0503 17:25:35.071369 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00518746 (* 1 = 0.00518746 loss)
I0503 17:25:35.071374 10699 sgd_solver.cpp:106] Iteration 164000, lr = 1.52588e-07
I0503 17:25:47.904754 10699 solver.cpp:337] Iteration 165000, Testing net (#0)
I0503 17:25:47.904846 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:25:47.904888 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:25:48.451354 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:25:48.451383 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:25:48.453637 10699 solver.cpp:228] Iteration 165000, loss = 0.010479
I0503 17:25:48.453657 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00227507 (* 1 = 0.00227507 loss)
I0503 17:25:48.453663 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00341727 (* 1 = 0.00341727 loss)
I0503 17:25:48.453670 10699 sgd_solver.cpp:106] Iteration 165000, lr = 1.52588e-07
I0503 17:26:01.809624 10699 solver.cpp:228] Iteration 166000, loss = 0.010522
I0503 17:26:01.809655 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00540685 (* 1 = 0.00540685 loss)
I0503 17:26:01.809661 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00795428 (* 1 = 0.00795428 loss)
I0503 17:26:01.809665 10699 sgd_solver.cpp:106] Iteration 166000, lr = 1.52588e-07
I0503 17:26:03.637586 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:26:14.810003 10699 solver.cpp:228] Iteration 167000, loss = 0.0114838
I0503 17:26:14.810093 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00390432 (* 1 = 0.00390432 loss)
I0503 17:26:14.810122 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00610977 (* 1 = 0.00610977 loss)
I0503 17:26:14.810142 10699 sgd_solver.cpp:106] Iteration 167000, lr = 1.52588e-07
I0503 17:26:27.456360 10699 solver.cpp:228] Iteration 168000, loss = 0.0100184
I0503 17:26:27.456398 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00511218 (* 1 = 0.00511218 loss)
I0503 17:26:27.456408 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00529549 (* 1 = 0.00529549 loss)
I0503 17:26:27.456414 10699 sgd_solver.cpp:106] Iteration 168000, lr = 1.52588e-07
I0503 17:26:35.827860 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:26:40.085237 10699 solver.cpp:228] Iteration 169000, loss = 0.0104519
I0503 17:26:40.085266 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00650932 (* 1 = 0.00650932 loss)
I0503 17:26:40.085271 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00986378 (* 1 = 0.00986378 loss)
I0503 17:26:40.085275 10699 sgd_solver.cpp:106] Iteration 169000, lr = 1.52588e-07
I0503 17:26:53.181996 10699 solver.cpp:337] Iteration 170000, Testing net (#0)
I0503 17:26:53.182027 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:26:53.182035 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:26:53.632551 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:26:53.632586 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:26:53.635129 10699 solver.cpp:228] Iteration 170000, loss = 0.0109931
I0503 17:26:53.635155 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00466536 (* 1 = 0.00466536 loss)
I0503 17:26:53.635164 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00764054 (* 1 = 0.00764054 loss)
I0503 17:26:53.635174 10699 sgd_solver.cpp:106] Iteration 170000, lr = 7.62939e-08
I0503 17:27:06.738539 10699 solver.cpp:228] Iteration 171000, loss = 0.00997668
I0503 17:27:06.738662 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00459687 (* 1 = 0.00459687 loss)
I0503 17:27:06.738672 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00536474 (* 1 = 0.00536474 loss)
I0503 17:27:06.738680 10699 sgd_solver.cpp:106] Iteration 171000, lr = 7.62939e-08
I0503 17:27:06.758793 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:27:19.806277 10699 solver.cpp:228] Iteration 172000, loss = 0.010587
I0503 17:27:19.806311 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00574659 (* 1 = 0.00574659 loss)
I0503 17:27:19.806321 10699 solver.cpp:244]     Train net output #1: loss_single = 0.007673 (* 1 = 0.007673 loss)
I0503 17:27:19.806329 10699 sgd_solver.cpp:106] Iteration 172000, lr = 7.62939e-08
I0503 17:27:32.845793 10699 solver.cpp:228] Iteration 173000, loss = 0.00997008
I0503 17:27:32.845824 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00246025 (* 1 = 0.00246025 loss)
I0503 17:27:32.845830 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00439427 (* 1 = 0.00439427 loss)
I0503 17:27:32.845835 10699 sgd_solver.cpp:106] Iteration 173000, lr = 7.62939e-08
I0503 17:27:38.668427 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:27:45.722290 10699 solver.cpp:228] Iteration 174000, loss = 0.0100166
I0503 17:27:45.722323 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0033239 (* 1 = 0.0033239 loss)
I0503 17:27:45.722333 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00350244 (* 1 = 0.00350244 loss)
I0503 17:27:45.722342 10699 sgd_solver.cpp:106] Iteration 174000, lr = 7.62939e-08
I0503 17:27:58.734433 10699 solver.cpp:337] Iteration 175000, Testing net (#0)
I0503 17:27:58.734470 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:27:58.734479 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:27:59.282019 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:27:59.282050 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:27:59.284384 10699 solver.cpp:228] Iteration 175000, loss = 0.0120913
I0503 17:27:59.284407 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00584089 (* 1 = 0.00584089 loss)
I0503 17:27:59.284415 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00822468 (* 1 = 0.00822468 loss)
I0503 17:27:59.284421 10699 sgd_solver.cpp:106] Iteration 175000, lr = 7.62939e-08
I0503 17:28:08.910989 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:28:12.304395 10699 solver.cpp:228] Iteration 176000, loss = 0.0110557
I0503 17:28:12.304431 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00383607 (* 1 = 0.00383607 loss)
I0503 17:28:12.304438 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00492135 (* 1 = 0.00492135 loss)
I0503 17:28:12.304446 10699 sgd_solver.cpp:106] Iteration 176000, lr = 7.62939e-08
I0503 17:28:23.176004 10699 solver.cpp:228] Iteration 177000, loss = 0.011377
I0503 17:28:23.176038 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00871105 (* 1 = 0.00871105 loss)
I0503 17:28:23.176044 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0143475 (* 1 = 0.0143475 loss)
I0503 17:28:23.176049 10699 sgd_solver.cpp:106] Iteration 177000, lr = 7.62939e-08
I0503 17:28:30.476970 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:28:33.547956 10699 solver.cpp:228] Iteration 178000, loss = 0.0114076
I0503 17:28:33.547988 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00564335 (* 1 = 0.00564335 loss)
I0503 17:28:33.547994 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00699282 (* 1 = 0.00699282 loss)
I0503 17:28:33.548001 10699 sgd_solver.cpp:106] Iteration 178000, lr = 7.62939e-08
I0503 17:28:44.464881 10699 solver.cpp:228] Iteration 179000, loss = 0.0107606
I0503 17:28:44.465030 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00445263 (* 1 = 0.00445263 loss)
I0503 17:28:44.465059 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00530272 (* 1 = 0.00530272 loss)
I0503 17:28:44.465080 10699 sgd_solver.cpp:106] Iteration 179000, lr = 7.62939e-08
I0503 17:28:51.391041 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:28:54.975563 10699 solver.cpp:337] Iteration 180000, Testing net (#0)
I0503 17:28:54.975637 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:28:54.975659 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:28:55.412868 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:28:55.412899 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.985701
I0503 17:28:55.431529 10699 solver.cpp:228] Iteration 180000, loss = 0.0105458
I0503 17:28:55.431556 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00570372 (* 1 = 0.00570372 loss)
I0503 17:28:55.431565 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00909195 (* 1 = 0.00909195 loss)
I0503 17:28:55.431573 10699 sgd_solver.cpp:106] Iteration 180000, lr = 3.8147e-08
I0503 17:29:06.243167 10699 solver.cpp:228] Iteration 181000, loss = 0.0110476
I0503 17:29:06.243198 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00574296 (* 1 = 0.00574296 loss)
I0503 17:29:06.243204 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00748676 (* 1 = 0.00748676 loss)
I0503 17:29:06.243211 10699 sgd_solver.cpp:106] Iteration 181000, lr = 3.8147e-08
I0503 17:29:11.323668 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:29:17.047195 10699 solver.cpp:228] Iteration 182000, loss = 0.0110995
I0503 17:29:17.047269 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00695768 (* 1 = 0.00695768 loss)
I0503 17:29:17.047279 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00728736 (* 1 = 0.00728736 loss)
I0503 17:29:17.047286 10699 sgd_solver.cpp:106] Iteration 182000, lr = 3.8147e-08
I0503 17:29:27.671267 10699 solver.cpp:228] Iteration 183000, loss = 0.0103493
I0503 17:29:27.671308 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00590914 (* 1 = 0.00590914 loss)
I0503 17:29:27.671319 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00702921 (* 1 = 0.00702921 loss)
I0503 17:29:27.671327 10699 sgd_solver.cpp:106] Iteration 183000, lr = 3.8147e-08
I0503 17:29:32.330066 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:29:38.624665 10699 solver.cpp:228] Iteration 184000, loss = 0.0105557
I0503 17:29:38.624712 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00188627 (* 1 = 0.00188627 loss)
I0503 17:29:38.624723 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00337863 (* 1 = 0.00337863 loss)
I0503 17:29:38.624733 10699 sgd_solver.cpp:106] Iteration 184000, lr = 3.8147e-08
I0503 17:29:48.968408 10699 solver.cpp:337] Iteration 185000, Testing net (#0)
I0503 17:29:48.968509 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:29:48.968518 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:29:49.388221 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:29:49.388366 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:29:49.392679 10699 solver.cpp:228] Iteration 185000, loss = 0.0116786
I0503 17:29:49.392881 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00402414 (* 1 = 0.00402414 loss)
I0503 17:29:49.392980 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00657967 (* 1 = 0.00657967 loss)
I0503 17:29:49.393055 10699 sgd_solver.cpp:106] Iteration 185000, lr = 3.8147e-08
I0503 17:29:52.761090 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:29:59.883204 10699 solver.cpp:228] Iteration 186000, loss = 0.0120994
I0503 17:29:59.883235 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0068036 (* 1 = 0.0068036 loss)
I0503 17:29:59.883241 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0159129 (* 1 = 0.0159129 loss)
I0503 17:29:59.883247 10699 sgd_solver.cpp:106] Iteration 186000, lr = 3.8147e-08
I0503 17:30:12.243088 10699 solver.cpp:228] Iteration 187000, loss = 0.0107664
I0503 17:30:12.243129 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00493555 (* 1 = 0.00493555 loss)
I0503 17:30:12.243139 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00654442 (* 1 = 0.00654442 loss)
I0503 17:30:12.243145 10699 sgd_solver.cpp:106] Iteration 187000, lr = 3.8147e-08
I0503 17:30:19.150240 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:30:25.374475 10699 solver.cpp:228] Iteration 188000, loss = 0.0111253
I0503 17:30:25.374510 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00366626 (* 1 = 0.00366626 loss)
I0503 17:30:25.374516 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00529973 (* 1 = 0.00529973 loss)
I0503 17:30:25.374522 10699 sgd_solver.cpp:106] Iteration 188000, lr = 3.8147e-08
I0503 17:30:38.258138 10699 solver.cpp:228] Iteration 189000, loss = 0.0111989
I0503 17:30:38.258234 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00255972 (* 1 = 0.00255972 loss)
I0503 17:30:38.258265 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00384882 (* 1 = 0.00384882 loss)
I0503 17:30:38.258289 10699 sgd_solver.cpp:106] Iteration 189000, lr = 3.8147e-08
I0503 17:30:50.412560 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:30:50.890657 10699 solver.cpp:337] Iteration 190000, Testing net (#0)
I0503 17:30:50.890681 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:30:50.890686 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:30:51.430155 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:30:51.430181 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:30:51.448643 10699 solver.cpp:228] Iteration 190000, loss = 0.0106814
I0503 17:30:51.448670 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00793217 (* 1 = 0.00793217 loss)
I0503 17:30:51.448675 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0179424 (* 1 = 0.0179424 loss)
I0503 17:30:51.448683 10699 sgd_solver.cpp:106] Iteration 190000, lr = 1.90735e-08
I0503 17:31:03.985682 10699 solver.cpp:228] Iteration 191000, loss = 0.0101375
I0503 17:31:03.985713 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00578612 (* 1 = 0.00578612 loss)
I0503 17:31:03.985718 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00787435 (* 1 = 0.00787435 loss)
I0503 17:31:03.985724 10699 sgd_solver.cpp:106] Iteration 191000, lr = 1.90735e-08
I0503 17:31:17.423483 10699 solver.cpp:228] Iteration 192000, loss = 0.0113204
I0503 17:31:17.423512 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00369539 (* 1 = 0.00369539 loss)
I0503 17:31:17.423518 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00454973 (* 1 = 0.00454973 loss)
I0503 17:31:17.423524 10699 sgd_solver.cpp:106] Iteration 192000, lr = 1.90735e-08
I0503 17:31:21.507102 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:31:30.391193 10699 solver.cpp:228] Iteration 193000, loss = 0.0103864
I0503 17:31:30.391234 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00427833 (* 1 = 0.00427833 loss)
I0503 17:31:30.391243 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00530219 (* 1 = 0.00530219 loss)
I0503 17:31:30.391252 10699 sgd_solver.cpp:106] Iteration 193000, lr = 1.90735e-08
I0503 17:31:43.226718 10699 solver.cpp:228] Iteration 194000, loss = 0.0102639
I0503 17:31:43.226749 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00354392 (* 1 = 0.00354392 loss)
I0503 17:31:43.226755 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00508363 (* 1 = 0.00508363 loss)
I0503 17:31:43.226761 10699 sgd_solver.cpp:106] Iteration 194000, lr = 1.90735e-08
I0503 17:31:52.806241 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:31:55.847681 10699 solver.cpp:337] Iteration 195000, Testing net (#0)
I0503 17:31:55.847707 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:31:55.847714 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:31:56.390754 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:31:56.390790 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:31:56.393348 10699 solver.cpp:228] Iteration 195000, loss = 0.0113973
I0503 17:31:56.393373 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00611746 (* 1 = 0.00611746 loss)
I0503 17:31:56.393381 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00889277 (* 1 = 0.00889277 loss)
I0503 17:31:56.393390 10699 sgd_solver.cpp:106] Iteration 195000, lr = 1.90735e-08
I0503 17:32:09.418138 10699 solver.cpp:228] Iteration 196000, loss = 0.0114183
I0503 17:32:09.418174 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00296982 (* 1 = 0.00296982 loss)
I0503 17:32:09.418182 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00450621 (* 1 = 0.00450621 loss)
I0503 17:32:09.418189 10699 sgd_solver.cpp:106] Iteration 196000, lr = 1.90735e-08
I0503 17:32:22.490169 10699 solver.cpp:228] Iteration 197000, loss = 0.010966
I0503 17:32:22.490263 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00319429 (* 1 = 0.00319429 loss)
I0503 17:32:22.490294 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00420012 (* 1 = 0.00420012 loss)
I0503 17:32:22.490317 10699 sgd_solver.cpp:106] Iteration 197000, lr = 1.90735e-08
I0503 17:32:23.900846 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:32:35.288372 10699 solver.cpp:228] Iteration 198000, loss = 0.0107892
I0503 17:32:35.288413 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00315881 (* 1 = 0.00315881 loss)
I0503 17:32:35.288424 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00402309 (* 1 = 0.00402309 loss)
I0503 17:32:35.288431 10699 sgd_solver.cpp:106] Iteration 198000, lr = 1.90735e-08
I0503 17:32:48.137193 10699 solver.cpp:228] Iteration 199000, loss = 0.0109968
I0503 17:32:48.137243 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00441745 (* 1 = 0.00441745 loss)
I0503 17:32:48.137253 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00704121 (* 1 = 0.00704121 loss)
I0503 17:32:48.137260 10699 sgd_solver.cpp:106] Iteration 199000, lr = 1.90735e-08
I0503 17:32:55.606336 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:33:01.299257 10699 solver.cpp:454] Snapshotting to binary proto file mnist_iter_200000.caffemodel
I0503 17:33:01.303659 10699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mnist_iter_200000.solverstate
I0503 17:33:01.304090 10699 solver.cpp:337] Iteration 200000, Testing net (#0)
I0503 17:33:01.304108 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:33:01.304116 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:33:01.870466 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:33:01.870499 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:33:01.873091 10699 solver.cpp:228] Iteration 200000, loss = 0.0105676
I0503 17:33:01.873116 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00493926 (* 1 = 0.00493926 loss)
I0503 17:33:01.873126 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00558999 (* 1 = 0.00558999 loss)
I0503 17:33:01.873136 10699 sgd_solver.cpp:106] Iteration 200000, lr = 9.53674e-09
I0503 17:33:14.666640 10699 solver.cpp:228] Iteration 201000, loss = 0.0098927
I0503 17:33:14.666682 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00369512 (* 1 = 0.00369512 loss)
I0503 17:33:14.666692 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00478675 (* 1 = 0.00478675 loss)
I0503 17:33:14.666700 10699 sgd_solver.cpp:106] Iteration 201000, lr = 9.53674e-09
I0503 17:33:26.259181 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:33:27.714898 10699 solver.cpp:228] Iteration 202000, loss = 0.0120175
I0503 17:33:27.714994 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00843928 (* 1 = 0.00843928 loss)
I0503 17:33:27.715025 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0125291 (* 1 = 0.0125291 loss)
I0503 17:33:27.715049 10699 sgd_solver.cpp:106] Iteration 202000, lr = 9.53674e-09
I0503 17:33:40.332844 10699 solver.cpp:228] Iteration 203000, loss = 0.0105609
I0503 17:33:40.332875 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00409979 (* 1 = 0.00409979 loss)
I0503 17:33:40.332881 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00678616 (* 1 = 0.00678616 loss)
I0503 17:33:40.332887 10699 sgd_solver.cpp:106] Iteration 203000, lr = 9.53674e-09
I0503 17:33:53.312971 10699 solver.cpp:228] Iteration 204000, loss = 0.0105044
I0503 17:33:53.313002 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00267294 (* 1 = 0.00267294 loss)
I0503 17:33:53.313007 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00243661 (* 1 = 0.00243661 loss)
I0503 17:33:53.313012 10699 sgd_solver.cpp:106] Iteration 204000, lr = 9.53674e-09
I0503 17:33:58.303033 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:34:05.981207 10699 solver.cpp:337] Iteration 205000, Testing net (#0)
I0503 17:34:05.981231 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:34:05.981236 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:34:06.678315 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:34:06.678349 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:34:06.700091 10699 solver.cpp:228] Iteration 205000, loss = 0.010228
I0503 17:34:06.700127 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00212827 (* 1 = 0.00212827 loss)
I0503 17:34:06.700137 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00328253 (* 1 = 0.00328253 loss)
I0503 17:34:06.700145 10699 sgd_solver.cpp:106] Iteration 205000, lr = 9.53674e-09
I0503 17:34:19.717566 10699 solver.cpp:228] Iteration 206000, loss = 0.0108059
I0503 17:34:19.717597 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00564116 (* 1 = 0.00564116 loss)
I0503 17:34:19.717603 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00625488 (* 1 = 0.00625488 loss)
I0503 17:34:19.717608 10699 sgd_solver.cpp:106] Iteration 206000, lr = 9.53674e-09
I0503 17:34:28.910634 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:34:32.580016 10699 solver.cpp:228] Iteration 207000, loss = 0.0114223
I0503 17:34:32.580061 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00454773 (* 1 = 0.00454773 loss)
I0503 17:34:32.580071 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00746127 (* 1 = 0.00746127 loss)
I0503 17:34:32.580078 10699 sgd_solver.cpp:106] Iteration 207000, lr = 9.53674e-09
I0503 17:34:45.933153 10699 solver.cpp:228] Iteration 208000, loss = 0.0112548
I0503 17:34:45.933185 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00478892 (* 1 = 0.00478892 loss)
I0503 17:34:45.933192 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00409615 (* 1 = 0.00409615 loss)
I0503 17:34:45.933197 10699 sgd_solver.cpp:106] Iteration 208000, lr = 9.53674e-09
I0503 17:34:58.643688 10699 solver.cpp:228] Iteration 209000, loss = 0.0105113
I0503 17:34:58.643782 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00381066 (* 1 = 0.00381066 loss)
I0503 17:34:58.643829 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0052445 (* 1 = 0.0052445 loss)
I0503 17:34:58.643856 10699 sgd_solver.cpp:106] Iteration 209000, lr = 9.53674e-09
I0503 17:35:00.954839 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:35:11.805060 10699 solver.cpp:337] Iteration 210000, Testing net (#0)
I0503 17:35:11.805090 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:35:11.805097 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:35:12.325623 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:35:12.325649 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:35:12.327908 10699 solver.cpp:228] Iteration 210000, loss = 0.0107636
I0503 17:35:12.327934 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00186128 (* 1 = 0.00186128 loss)
I0503 17:35:12.327939 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00276103 (* 1 = 0.00276103 loss)
I0503 17:35:12.327946 10699 sgd_solver.cpp:106] Iteration 210000, lr = 4.76837e-09
I0503 17:35:25.586339 10699 solver.cpp:228] Iteration 211000, loss = 0.0102452
I0503 17:35:25.586437 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00463678 (* 1 = 0.00463678 loss)
I0503 17:35:25.586468 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00469861 (* 1 = 0.00469861 loss)
I0503 17:35:25.586495 10699 sgd_solver.cpp:106] Iteration 211000, lr = 4.76837e-09
I0503 17:35:32.762637 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:35:38.314736 10699 solver.cpp:228] Iteration 212000, loss = 0.0101527
I0503 17:35:38.314767 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00347842 (* 1 = 0.00347842 loss)
I0503 17:35:38.314774 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00475173 (* 1 = 0.00475173 loss)
I0503 17:35:38.314777 10699 sgd_solver.cpp:106] Iteration 212000, lr = 4.76837e-09
I0503 17:35:51.446818 10699 solver.cpp:228] Iteration 213000, loss = 0.00970289
I0503 17:35:51.446910 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00469703 (* 1 = 0.00469703 loss)
I0503 17:35:51.446938 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00490056 (* 1 = 0.00490056 loss)
I0503 17:35:51.446959 10699 sgd_solver.cpp:106] Iteration 213000, lr = 4.76837e-09
I0503 17:36:04.422207 10699 solver.cpp:228] Iteration 214000, loss = 0.0106984
I0503 17:36:04.422297 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00269658 (* 1 = 0.00269658 loss)
I0503 17:36:04.422304 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0030199 (* 1 = 0.0030199 loss)
I0503 17:36:04.422312 10699 sgd_solver.cpp:106] Iteration 214000, lr = 4.76837e-09
I0503 17:36:05.136286 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:36:17.291712 10699 solver.cpp:337] Iteration 215000, Testing net (#0)
I0503 17:36:17.291791 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:36:17.291815 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:36:17.827757 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:36:17.827780 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:36:17.842983 10699 solver.cpp:228] Iteration 215000, loss = 0.010689
I0503 17:36:17.843003 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00556395 (* 1 = 0.00556395 loss)
I0503 17:36:17.843009 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00818651 (* 1 = 0.00818651 loss)
I0503 17:36:17.843015 10699 sgd_solver.cpp:106] Iteration 215000, lr = 4.76837e-09
I0503 17:36:30.951093 10699 solver.cpp:228] Iteration 216000, loss = 0.0101057
I0503 17:36:30.951125 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00311018 (* 1 = 0.00311018 loss)
I0503 17:36:30.951131 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00361672 (* 1 = 0.00361672 loss)
I0503 17:36:30.951135 10699 sgd_solver.cpp:106] Iteration 216000, lr = 4.76837e-09
I0503 17:36:36.939218 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:36:44.031954 10699 solver.cpp:228] Iteration 217000, loss = 0.0107779
I0503 17:36:44.031987 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00314044 (* 1 = 0.00314044 loss)
I0503 17:36:44.031993 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00432232 (* 1 = 0.00432232 loss)
I0503 17:36:44.031999 10699 sgd_solver.cpp:106] Iteration 217000, lr = 4.76837e-09
I0503 17:36:57.099131 10699 solver.cpp:228] Iteration 218000, loss = 0.0121226
I0503 17:36:57.099160 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00365538 (* 1 = 0.00365538 loss)
I0503 17:36:57.099166 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00561512 (* 1 = 0.00561512 loss)
I0503 17:36:57.099169 10699 sgd_solver.cpp:106] Iteration 218000, lr = 4.76837e-09
I0503 17:37:08.326671 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:37:10.012457 10699 solver.cpp:228] Iteration 219000, loss = 0.0111148
I0503 17:37:10.012488 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00423763 (* 1 = 0.00423763 loss)
I0503 17:37:10.012495 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00537712 (* 1 = 0.00537712 loss)
I0503 17:37:10.012500 10699 sgd_solver.cpp:106] Iteration 219000, lr = 4.76837e-09
I0503 17:37:22.973546 10699 solver.cpp:337] Iteration 220000, Testing net (#0)
I0503 17:37:22.973572 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:37:22.973579 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:37:23.580165 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:37:23.580199 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:37:23.582836 10699 solver.cpp:228] Iteration 220000, loss = 0.0113654
I0503 17:37:23.582903 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00677354 (* 1 = 0.00677354 loss)
I0503 17:37:23.582937 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0094097 (* 1 = 0.0094097 loss)
I0503 17:37:23.582968 10699 sgd_solver.cpp:106] Iteration 220000, lr = 2.38419e-09
I0503 17:37:36.536218 10699 solver.cpp:228] Iteration 221000, loss = 0.0108646
I0503 17:37:36.536253 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00338368 (* 1 = 0.00338368 loss)
I0503 17:37:36.536262 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00531778 (* 1 = 0.00531778 loss)
I0503 17:37:36.536269 10699 sgd_solver.cpp:106] Iteration 221000, lr = 2.38419e-09
I0503 17:37:39.964095 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:37:49.415730 10699 solver.cpp:228] Iteration 222000, loss = 0.0106115
I0503 17:37:49.415772 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0036055 (* 1 = 0.0036055 loss)
I0503 17:37:49.415781 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00482936 (* 1 = 0.00482936 loss)
I0503 17:37:49.415792 10699 sgd_solver.cpp:106] Iteration 222000, lr = 2.38419e-09
I0503 17:38:02.201486 10699 solver.cpp:228] Iteration 223000, loss = 0.010803
I0503 17:38:02.201586 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00525325 (* 1 = 0.00525325 loss)
I0503 17:38:02.201617 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00863653 (* 1 = 0.00863653 loss)
I0503 17:38:02.201642 10699 sgd_solver.cpp:106] Iteration 223000, lr = 2.38419e-09
I0503 17:38:11.156802 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:38:15.165129 10699 solver.cpp:228] Iteration 224000, loss = 0.0106257
I0503 17:38:15.165164 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00228057 (* 1 = 0.00228057 loss)
I0503 17:38:15.165170 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0031813 (* 1 = 0.0031813 loss)
I0503 17:38:15.165175 10699 sgd_solver.cpp:106] Iteration 224000, lr = 2.38419e-09
I0503 17:38:28.119036 10699 solver.cpp:337] Iteration 225000, Testing net (#0)
I0503 17:38:28.119123 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:38:28.119153 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:38:28.616917 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:38:28.616950 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:38:28.638262 10699 solver.cpp:228] Iteration 225000, loss = 0.0113579
I0503 17:38:28.638288 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0038184 (* 1 = 0.0038184 loss)
I0503 17:38:28.638293 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00539748 (* 1 = 0.00539748 loss)
I0503 17:38:28.638299 10699 sgd_solver.cpp:106] Iteration 225000, lr = 2.38419e-09
I0503 17:38:41.767830 10699 solver.cpp:228] Iteration 226000, loss = 0.0111417
I0503 17:38:41.767937 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00434409 (* 1 = 0.00434409 loss)
I0503 17:38:41.767943 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00635301 (* 1 = 0.00635301 loss)
I0503 17:38:41.767949 10699 sgd_solver.cpp:106] Iteration 226000, lr = 2.38419e-09
I0503 17:38:42.024199 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:38:54.917022 10699 solver.cpp:228] Iteration 227000, loss = 0.0104145
I0503 17:38:54.917109 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00299668 (* 1 = 0.00299668 loss)
I0503 17:38:54.917136 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00353023 (* 1 = 0.00353023 loss)
I0503 17:38:54.917160 10699 sgd_solver.cpp:106] Iteration 227000, lr = 2.38419e-09
I0503 17:39:07.977620 10699 solver.cpp:228] Iteration 228000, loss = 0.0114003
I0503 17:39:07.977651 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0065834 (* 1 = 0.0065834 loss)
I0503 17:39:07.977658 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00877625 (* 1 = 0.00877625 loss)
I0503 17:39:07.977663 10699 sgd_solver.cpp:106] Iteration 228000, lr = 2.38419e-09
I0503 17:39:14.707880 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:39:21.148066 10699 solver.cpp:228] Iteration 229000, loss = 0.0110817
I0503 17:39:21.148097 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00544551 (* 1 = 0.00544551 loss)
I0503 17:39:21.148103 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00824545 (* 1 = 0.00824545 loss)
I0503 17:39:21.148109 10699 sgd_solver.cpp:106] Iteration 229000, lr = 2.38419e-09
I0503 17:39:33.995409 10699 solver.cpp:337] Iteration 230000, Testing net (#0)
I0503 17:39:33.995514 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:39:33.995550 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:39:34.515189 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:39:34.515214 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:39:34.532166 10699 solver.cpp:228] Iteration 230000, loss = 0.0116096
I0503 17:39:34.532187 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00309595 (* 1 = 0.00309595 loss)
I0503 17:39:34.532192 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00417571 (* 1 = 0.00417571 loss)
I0503 17:39:34.532198 10699 sgd_solver.cpp:106] Iteration 230000, lr = 1.19209e-09
I0503 17:39:44.445825 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:39:47.304983 10699 solver.cpp:228] Iteration 231000, loss = 0.0107707
I0503 17:39:47.305058 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00436973 (* 1 = 0.00436973 loss)
I0503 17:39:47.305065 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0055435 (* 1 = 0.0055435 loss)
I0503 17:39:47.305070 10699 sgd_solver.cpp:106] Iteration 231000, lr = 1.19209e-09
I0503 17:40:00.457412 10699 solver.cpp:228] Iteration 232000, loss = 0.0100957
I0503 17:40:00.457451 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00270018 (* 1 = 0.00270018 loss)
I0503 17:40:00.457461 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00342421 (* 1 = 0.00342421 loss)
I0503 17:40:00.457468 10699 sgd_solver.cpp:106] Iteration 232000, lr = 1.19209e-09
I0503 17:40:13.163995 10699 solver.cpp:228] Iteration 233000, loss = 0.010401
I0503 17:40:13.164024 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00442195 (* 1 = 0.00442195 loss)
I0503 17:40:13.164031 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00831664 (* 1 = 0.00831664 loss)
I0503 17:40:13.164036 10699 sgd_solver.cpp:106] Iteration 233000, lr = 1.19209e-09
I0503 17:40:15.989675 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:40:25.805883 10699 solver.cpp:228] Iteration 234000, loss = 0.0113313
I0503 17:40:25.806010 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00379994 (* 1 = 0.00379994 loss)
I0503 17:40:25.806018 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00469956 (* 1 = 0.00469956 loss)
I0503 17:40:25.806025 10699 sgd_solver.cpp:106] Iteration 234000, lr = 1.19209e-09
I0503 17:40:38.607741 10699 solver.cpp:337] Iteration 235000, Testing net (#0)
I0503 17:40:38.607770 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:40:38.607777 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:40:39.080050 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:40:39.080085 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:40:39.097707 10699 solver.cpp:228] Iteration 235000, loss = 0.0110266
I0503 17:40:39.097730 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00246948 (* 1 = 0.00246948 loss)
I0503 17:40:39.097741 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00406543 (* 1 = 0.00406543 loss)
I0503 17:40:39.097748 10699 sgd_solver.cpp:106] Iteration 235000, lr = 1.19209e-09
I0503 17:40:45.609158 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:40:51.879783 10699 solver.cpp:228] Iteration 236000, loss = 0.0100959
I0503 17:40:51.879817 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0053732 (* 1 = 0.0053732 loss)
I0503 17:40:51.879822 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00592254 (* 1 = 0.00592254 loss)
I0503 17:40:51.879829 10699 sgd_solver.cpp:106] Iteration 236000, lr = 1.19209e-09
I0503 17:41:05.274294 10699 solver.cpp:228] Iteration 237000, loss = 0.0120041
I0503 17:41:05.274402 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00683006 (* 1 = 0.00683006 loss)
I0503 17:41:05.274416 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00983389 (* 1 = 0.00983389 loss)
I0503 17:41:05.274425 10699 sgd_solver.cpp:106] Iteration 237000, lr = 1.19209e-09
I0503 17:41:18.370148 10699 solver.cpp:228] Iteration 238000, loss = 0.0106695
I0503 17:41:18.370185 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00464769 (* 1 = 0.00464769 loss)
I0503 17:41:18.370193 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00611971 (* 1 = 0.00611971 loss)
I0503 17:41:18.370203 10699 sgd_solver.cpp:106] Iteration 238000, lr = 1.19209e-09
I0503 17:41:18.633522 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:41:31.495699 10699 solver.cpp:228] Iteration 239000, loss = 0.0105568
I0503 17:41:31.495734 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00460961 (* 1 = 0.00460961 loss)
I0503 17:41:31.495740 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00642095 (* 1 = 0.00642095 loss)
I0503 17:41:31.495748 10699 sgd_solver.cpp:106] Iteration 239000, lr = 1.19209e-09
I0503 17:41:44.330482 10699 solver.cpp:337] Iteration 240000, Testing net (#0)
I0503 17:41:44.330560 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:41:44.330566 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:41:44.901903 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:41:44.901929 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:41:44.921180 10699 solver.cpp:228] Iteration 240000, loss = 0.0102184
I0503 17:41:44.921206 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00383262 (* 1 = 0.00383262 loss)
I0503 17:41:44.921216 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00473085 (* 1 = 0.00473085 loss)
I0503 17:41:44.921224 10699 sgd_solver.cpp:106] Iteration 240000, lr = 5.96046e-10
I0503 17:41:50.123337 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:41:58.021625 10699 solver.cpp:228] Iteration 241000, loss = 0.0108401
I0503 17:41:58.021667 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00420032 (* 1 = 0.00420032 loss)
I0503 17:41:58.021677 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00518917 (* 1 = 0.00518917 loss)
I0503 17:41:58.021685 10699 sgd_solver.cpp:106] Iteration 241000, lr = 5.96046e-10
I0503 17:42:11.178110 10699 solver.cpp:228] Iteration 242000, loss = 0.0111035
I0503 17:42:11.178145 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00514834 (* 1 = 0.00514834 loss)
I0503 17:42:11.178153 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00788463 (* 1 = 0.00788463 loss)
I0503 17:42:11.178158 10699 sgd_solver.cpp:106] Iteration 242000, lr = 5.96046e-10
I0503 17:42:22.691182 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:42:24.052906 10699 solver.cpp:228] Iteration 243000, loss = 0.00994743
I0503 17:42:24.052943 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00285209 (* 1 = 0.00285209 loss)
I0503 17:42:24.052952 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00445812 (* 1 = 0.00445812 loss)
I0503 17:42:24.052959 10699 sgd_solver.cpp:106] Iteration 243000, lr = 5.96046e-10
I0503 17:42:37.060686 10699 solver.cpp:228] Iteration 244000, loss = 0.011492
I0503 17:42:37.060724 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00386647 (* 1 = 0.00386647 loss)
I0503 17:42:37.060734 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00447691 (* 1 = 0.00447691 loss)
I0503 17:42:37.060742 10699 sgd_solver.cpp:106] Iteration 244000, lr = 5.96046e-10
I0503 17:42:47.707059 10699 solver.cpp:337] Iteration 245000, Testing net (#0)
I0503 17:42:47.707142 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:42:47.707165 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:42:48.114425 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:42:48.143606 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:42:48.143631 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:42:48.162721 10699 solver.cpp:228] Iteration 245000, loss = 0.00979152
I0503 17:42:48.162746 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00419403 (* 1 = 0.00419403 loss)
I0503 17:42:48.162752 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00526929 (* 1 = 0.00526929 loss)
I0503 17:42:48.162758 10699 sgd_solver.cpp:106] Iteration 245000, lr = 5.96046e-10
I0503 17:42:58.644482 10699 solver.cpp:228] Iteration 246000, loss = 0.0116142
I0503 17:42:58.644582 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00191929 (* 1 = 0.00191929 loss)
I0503 17:42:58.644588 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00335297 (* 1 = 0.00335297 loss)
I0503 17:42:58.644594 10699 sgd_solver.cpp:106] Iteration 246000, lr = 5.96046e-10
I0503 17:43:08.812523 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:43:09.125959 10699 solver.cpp:228] Iteration 247000, loss = 0.0117496
I0503 17:43:09.125993 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0055708 (* 1 = 0.0055708 loss)
I0503 17:43:09.125998 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00616056 (* 1 = 0.00616056 loss)
I0503 17:43:09.126004 10699 sgd_solver.cpp:106] Iteration 247000, lr = 5.96046e-10
I0503 17:43:19.948460 10699 solver.cpp:228] Iteration 248000, loss = 0.0112728
I0503 17:43:19.948494 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00243688 (* 1 = 0.00243688 loss)
I0503 17:43:19.948500 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00266083 (* 1 = 0.00266083 loss)
I0503 17:43:19.948503 10699 sgd_solver.cpp:106] Iteration 248000, lr = 5.96046e-10
I0503 17:43:29.908442 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:43:30.423530 10699 solver.cpp:228] Iteration 249000, loss = 0.0100324
I0503 17:43:30.423568 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00297645 (* 1 = 0.00297645 loss)
I0503 17:43:30.423578 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00415101 (* 1 = 0.00415101 loss)
I0503 17:43:30.423588 10699 sgd_solver.cpp:106] Iteration 249000, lr = 5.96046e-10
I0503 17:43:41.072460 10699 solver.cpp:337] Iteration 250000, Testing net (#0)
I0503 17:43:41.072484 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:43:41.072490 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:43:41.456254 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:43:41.456291 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:43:41.458870 10699 solver.cpp:228] Iteration 250000, loss = 0.0111634
I0503 17:43:41.458896 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00507877 (* 1 = 0.00507877 loss)
I0503 17:43:41.458904 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00770633 (* 1 = 0.00770633 loss)
I0503 17:43:41.458912 10699 sgd_solver.cpp:106] Iteration 250000, lr = 2.98023e-10
I0503 17:43:49.709944 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:43:51.932415 10699 solver.cpp:228] Iteration 251000, loss = 0.0100361
I0503 17:43:51.932459 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00274681 (* 1 = 0.00274681 loss)
I0503 17:43:51.932472 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00384127 (* 1 = 0.00384127 loss)
I0503 17:43:51.932482 10699 sgd_solver.cpp:106] Iteration 251000, lr = 2.98023e-10
I0503 17:44:02.658807 10699 solver.cpp:228] Iteration 252000, loss = 0.0107776
I0503 17:44:02.658959 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0034989 (* 1 = 0.0034989 loss)
I0503 17:44:02.658989 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00541328 (* 1 = 0.00541328 loss)
I0503 17:44:02.659014 10699 sgd_solver.cpp:106] Iteration 252000, lr = 2.98023e-10
I0503 17:44:10.165171 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:44:13.043642 10699 solver.cpp:228] Iteration 253000, loss = 0.0107442
I0503 17:44:13.043673 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00336561 (* 1 = 0.00336561 loss)
I0503 17:44:13.043678 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00312599 (* 1 = 0.00312599 loss)
I0503 17:44:13.043686 10699 sgd_solver.cpp:106] Iteration 253000, lr = 2.98023e-10
I0503 17:44:23.529549 10699 solver.cpp:228] Iteration 254000, loss = 0.0110246
I0503 17:44:23.529644 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00827957 (* 1 = 0.00827957 loss)
I0503 17:44:23.529654 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00759063 (* 1 = 0.00759063 loss)
I0503 17:44:23.529662 10699 sgd_solver.cpp:106] Iteration 254000, lr = 2.98023e-10
I0503 17:44:32.470046 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:44:35.330227 10699 solver.cpp:337] Iteration 255000, Testing net (#0)
I0503 17:44:35.330328 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:44:35.330337 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:44:35.886766 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:44:35.886801 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:44:35.889477 10699 solver.cpp:228] Iteration 255000, loss = 0.0111477
I0503 17:44:35.889502 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00258212 (* 1 = 0.00258212 loss)
I0503 17:44:35.889511 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00315528 (* 1 = 0.00315528 loss)
I0503 17:44:35.889521 10699 sgd_solver.cpp:106] Iteration 255000, lr = 2.98023e-10
I0503 17:44:48.966491 10699 solver.cpp:228] Iteration 256000, loss = 0.0114681
I0503 17:44:48.966521 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00358651 (* 1 = 0.00358651 loss)
I0503 17:44:48.966527 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00603412 (* 1 = 0.00603412 loss)
I0503 17:44:48.966532 10699 sgd_solver.cpp:106] Iteration 256000, lr = 2.98023e-10
I0503 17:45:01.771919 10699 solver.cpp:228] Iteration 257000, loss = 0.0114444
I0503 17:45:01.772014 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00356936 (* 1 = 0.00356936 loss)
I0503 17:45:01.772050 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00472017 (* 1 = 0.00472017 loss)
I0503 17:45:01.772080 10699 sgd_solver.cpp:106] Iteration 257000, lr = 2.98023e-10
I0503 17:45:03.572533 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:45:14.414757 10699 solver.cpp:228] Iteration 258000, loss = 0.0111003
I0503 17:45:14.414885 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00396508 (* 1 = 0.00396508 loss)
I0503 17:45:14.414896 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00546009 (* 1 = 0.00546009 loss)
I0503 17:45:14.414904 10699 sgd_solver.cpp:106] Iteration 258000, lr = 2.98023e-10
I0503 17:45:27.378082 10699 solver.cpp:228] Iteration 259000, loss = 0.0108103
I0503 17:45:27.378130 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00416217 (* 1 = 0.00416217 loss)
I0503 17:45:27.378142 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00577873 (* 1 = 0.00577873 loss)
I0503 17:45:27.378151 10699 sgd_solver.cpp:106] Iteration 259000, lr = 2.98023e-10
I0503 17:45:35.173228 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:45:40.486980 10699 solver.cpp:337] Iteration 260000, Testing net (#0)
I0503 17:45:40.487004 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:45:40.487010 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:45:41.076872 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:45:41.076902 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:45:41.079679 10699 solver.cpp:228] Iteration 260000, loss = 0.0122251
I0503 17:45:41.079707 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00368065 (* 1 = 0.00368065 loss)
I0503 17:45:41.079718 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00628156 (* 1 = 0.00628156 loss)
I0503 17:45:41.079728 10699 sgd_solver.cpp:106] Iteration 260000, lr = 1.49012e-10
I0503 17:45:54.158519 10699 solver.cpp:228] Iteration 261000, loss = 0.0106748
I0503 17:45:54.158617 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00344318 (* 1 = 0.00344318 loss)
I0503 17:45:54.158625 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00434713 (* 1 = 0.00434713 loss)
I0503 17:45:54.158632 10699 sgd_solver.cpp:106] Iteration 261000, lr = 1.49012e-10
I0503 17:46:06.586902 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:46:07.156985 10699 solver.cpp:228] Iteration 262000, loss = 0.0102407
I0503 17:46:07.157078 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00278219 (* 1 = 0.00278219 loss)
I0503 17:46:07.157101 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00418923 (* 1 = 0.00418923 loss)
I0503 17:46:07.157122 10699 sgd_solver.cpp:106] Iteration 262000, lr = 1.49012e-10
I0503 17:46:20.164757 10699 solver.cpp:228] Iteration 263000, loss = 0.0108308
I0503 17:46:20.164794 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.005666 (* 1 = 0.005666 loss)
I0503 17:46:20.164803 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00635877 (* 1 = 0.00635877 loss)
I0503 17:46:20.164813 10699 sgd_solver.cpp:106] Iteration 263000, lr = 1.49012e-10
I0503 17:46:32.755223 10699 solver.cpp:228] Iteration 264000, loss = 0.0110763
I0503 17:46:32.755306 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00648705 (* 1 = 0.00648705 loss)
I0503 17:46:32.755324 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00834502 (* 1 = 0.00834502 loss)
I0503 17:46:32.755331 10699 sgd_solver.cpp:106] Iteration 264000, lr = 1.49012e-10
I0503 17:46:38.147469 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:46:45.912106 10699 solver.cpp:337] Iteration 265000, Testing net (#0)
I0503 17:46:45.912128 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:46:45.912133 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:46:46.413029 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:46:46.413060 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:46:46.415349 10699 solver.cpp:228] Iteration 265000, loss = 0.0101292
I0503 17:46:46.415374 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00275491 (* 1 = 0.00275491 loss)
I0503 17:46:46.415380 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0033232 (* 1 = 0.0033232 loss)
I0503 17:46:46.415388 10699 sgd_solver.cpp:106] Iteration 265000, lr = 1.49012e-10
I0503 17:46:59.521143 10699 solver.cpp:228] Iteration 266000, loss = 0.00959725
I0503 17:46:59.521173 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00391974 (* 1 = 0.00391974 loss)
I0503 17:46:59.521180 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00353037 (* 1 = 0.00353037 loss)
I0503 17:46:59.521186 10699 sgd_solver.cpp:106] Iteration 266000, lr = 1.49012e-10
I0503 17:47:08.950711 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:47:12.668676 10699 solver.cpp:228] Iteration 267000, loss = 0.0105866
I0503 17:47:12.668773 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00390234 (* 1 = 0.00390234 loss)
I0503 17:47:12.668807 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00569314 (* 1 = 0.00569314 loss)
I0503 17:47:12.668836 10699 sgd_solver.cpp:106] Iteration 267000, lr = 1.49012e-10
I0503 17:47:25.685549 10699 solver.cpp:228] Iteration 268000, loss = 0.0100126
I0503 17:47:25.685650 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00298176 (* 1 = 0.00298176 loss)
I0503 17:47:25.685681 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00461418 (* 1 = 0.00461418 loss)
I0503 17:47:25.685706 10699 sgd_solver.cpp:106] Iteration 268000, lr = 1.49012e-10
I0503 17:47:38.735205 10699 solver.cpp:228] Iteration 269000, loss = 0.0109434
I0503 17:47:38.735246 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00604974 (* 1 = 0.00604974 loss)
I0503 17:47:38.735258 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0089106 (* 1 = 0.0089106 loss)
I0503 17:47:38.735268 10699 sgd_solver.cpp:106] Iteration 269000, lr = 1.49012e-10
I0503 17:47:41.864631 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:47:51.831310 10699 solver.cpp:337] Iteration 270000, Testing net (#0)
I0503 17:47:51.831393 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:47:51.831414 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:47:52.338543 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:47:52.338568 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:47:52.355815 10699 solver.cpp:228] Iteration 270000, loss = 0.0101707
I0503 17:47:52.355842 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00167884 (* 1 = 0.00167884 loss)
I0503 17:47:52.355851 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00332839 (* 1 = 0.00332839 loss)
I0503 17:47:52.355859 10699 sgd_solver.cpp:106] Iteration 270000, lr = 7.45058e-11
I0503 17:48:05.049387 10699 solver.cpp:228] Iteration 271000, loss = 0.0106843
I0503 17:48:05.049418 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00271387 (* 1 = 0.00271387 loss)
I0503 17:48:05.049424 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00399783 (* 1 = 0.00399783 loss)
I0503 17:48:05.049430 10699 sgd_solver.cpp:106] Iteration 271000, lr = 7.45058e-11
I0503 17:48:13.545759 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:48:18.359580 10699 solver.cpp:228] Iteration 272000, loss = 0.00975071
I0503 17:48:18.359671 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0021051 (* 1 = 0.0021051 loss)
I0503 17:48:18.359697 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00236213 (* 1 = 0.00236213 loss)
I0503 17:48:18.359719 10699 sgd_solver.cpp:106] Iteration 272000, lr = 7.45058e-11
I0503 17:48:31.266211 10699 solver.cpp:228] Iteration 273000, loss = 0.0101918
I0503 17:48:31.266242 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00455113 (* 1 = 0.00455113 loss)
I0503 17:48:31.266249 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00665914 (* 1 = 0.00665914 loss)
I0503 17:48:31.266254 10699 sgd_solver.cpp:106] Iteration 273000, lr = 7.45058e-11
I0503 17:48:44.021543 10699 solver.cpp:228] Iteration 274000, loss = 0.0101657
I0503 17:48:44.021670 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00781137 (* 1 = 0.00781137 loss)
I0503 17:48:44.021677 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0138039 (* 1 = 0.0138039 loss)
I0503 17:48:44.021684 10699 sgd_solver.cpp:106] Iteration 274000, lr = 7.45058e-11
I0503 17:48:45.228821 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:48:57.467725 10699 solver.cpp:337] Iteration 275000, Testing net (#0)
I0503 17:48:57.467749 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:48:57.467754 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:48:58.012059 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:48:58.012089 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:48:58.014459 10699 solver.cpp:228] Iteration 275000, loss = 0.010603
I0503 17:48:58.014482 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00434713 (* 1 = 0.00434713 loss)
I0503 17:48:58.014488 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00378308 (* 1 = 0.00378308 loss)
I0503 17:48:58.014494 10699 sgd_solver.cpp:106] Iteration 275000, lr = 7.45058e-11
I0503 17:49:10.626546 10699 solver.cpp:228] Iteration 276000, loss = 0.00993274
I0503 17:49:10.626639 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00446485 (* 1 = 0.00446485 loss)
I0503 17:49:10.626668 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0059462 (* 1 = 0.0059462 loss)
I0503 17:49:10.626690 10699 sgd_solver.cpp:106] Iteration 276000, lr = 7.45058e-11
I0503 17:49:17.360173 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:49:23.543735 10699 solver.cpp:228] Iteration 277000, loss = 0.0103958
I0503 17:49:23.543771 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00533762 (* 1 = 0.00533762 loss)
I0503 17:49:23.543778 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0061683 (* 1 = 0.0061683 loss)
I0503 17:49:23.543784 10699 sgd_solver.cpp:106] Iteration 277000, lr = 7.45058e-11
I0503 17:49:36.269079 10699 solver.cpp:228] Iteration 278000, loss = 0.0108593
I0503 17:49:36.269173 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00161267 (* 1 = 0.00161267 loss)
I0503 17:49:36.269201 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00300129 (* 1 = 0.00300129 loss)
I0503 17:49:36.269227 10699 sgd_solver.cpp:106] Iteration 278000, lr = 7.45058e-11
I0503 17:49:49.232707 10699 solver.cpp:228] Iteration 279000, loss = 0.0109916
I0503 17:49:49.234467 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00496109 (* 1 = 0.00496109 loss)
I0503 17:49:49.234479 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00795006 (* 1 = 0.00795006 loss)
I0503 17:49:49.234488 10699 sgd_solver.cpp:106] Iteration 279000, lr = 7.45058e-11
I0503 17:49:49.521185 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:50:02.298807 10699 solver.cpp:337] Iteration 280000, Testing net (#0)
I0503 17:50:02.298843 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:50:02.298849 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:50:02.826270 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:50:02.826357 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:50:02.828969 10699 solver.cpp:228] Iteration 280000, loss = 0.011903
I0503 17:50:02.829030 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00522647 (* 1 = 0.00522647 loss)
I0503 17:50:02.829064 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00790483 (* 1 = 0.00790483 loss)
I0503 17:50:02.829116 10699 sgd_solver.cpp:106] Iteration 280000, lr = 3.72529e-11
I0503 17:50:15.612267 10699 solver.cpp:228] Iteration 281000, loss = 0.0107745
I0503 17:50:15.612306 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00559306 (* 1 = 0.00559306 loss)
I0503 17:50:15.612314 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0058516 (* 1 = 0.0058516 loss)
I0503 17:50:15.612323 10699 sgd_solver.cpp:106] Iteration 281000, lr = 3.72529e-11
I0503 17:50:20.638906 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:50:28.779232 10699 solver.cpp:228] Iteration 282000, loss = 0.0106648
I0503 17:50:28.779263 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00282535 (* 1 = 0.00282535 loss)
I0503 17:50:28.779269 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00421808 (* 1 = 0.00421808 loss)
I0503 17:50:28.779274 10699 sgd_solver.cpp:106] Iteration 282000, lr = 3.72529e-11
I0503 17:50:41.784910 10699 solver.cpp:228] Iteration 283000, loss = 0.0106283
I0503 17:50:41.784960 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00141913 (* 1 = 0.00141913 loss)
I0503 17:50:41.784978 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00134506 (* 1 = 0.00134506 loss)
I0503 17:50:41.784994 10699 sgd_solver.cpp:106] Iteration 283000, lr = 3.72529e-11
I0503 17:50:53.429076 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:50:54.765923 10699 solver.cpp:228] Iteration 284000, loss = 0.0107376
I0503 17:50:54.765952 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00711206 (* 1 = 0.00711206 loss)
I0503 17:50:54.765959 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0100549 (* 1 = 0.0100549 loss)
I0503 17:50:54.765964 10699 sgd_solver.cpp:106] Iteration 284000, lr = 3.72529e-11
I0503 17:51:07.870405 10699 solver.cpp:337] Iteration 285000, Testing net (#0)
I0503 17:51:07.870427 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:51:07.870432 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:51:08.429926 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:51:08.429958 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:51:08.432575 10699 solver.cpp:228] Iteration 285000, loss = 0.0114232
I0503 17:51:08.432600 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00310189 (* 1 = 0.00310189 loss)
I0503 17:51:08.432610 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00464533 (* 1 = 0.00464533 loss)
I0503 17:51:08.432620 10699 sgd_solver.cpp:106] Iteration 285000, lr = 3.72529e-11
I0503 17:51:21.740021 10699 solver.cpp:228] Iteration 286000, loss = 0.0110195
I0503 17:51:21.740057 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00567511 (* 1 = 0.00567511 loss)
I0503 17:51:21.740067 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00772516 (* 1 = 0.00772516 loss)
I0503 17:51:21.740075 10699 sgd_solver.cpp:106] Iteration 286000, lr = 3.72529e-11
I0503 17:51:26.055495 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:51:34.685300 10699 solver.cpp:228] Iteration 287000, loss = 0.0104426
I0503 17:51:34.685349 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0065725 (* 1 = 0.0065725 loss)
I0503 17:51:34.685370 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00816058 (* 1 = 0.00816058 loss)
I0503 17:51:34.685385 10699 sgd_solver.cpp:106] Iteration 287000, lr = 3.72529e-11
I0503 17:51:47.672332 10699 solver.cpp:228] Iteration 288000, loss = 0.0110643
I0503 17:51:47.672361 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00581874 (* 1 = 0.00581874 loss)
I0503 17:51:47.672368 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00818832 (* 1 = 0.00818832 loss)
I0503 17:51:47.672374 10699 sgd_solver.cpp:106] Iteration 288000, lr = 3.72529e-11
I0503 17:51:58.476495 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:52:00.842478 10699 solver.cpp:228] Iteration 289000, loss = 0.0111877
I0503 17:52:00.842510 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00505673 (* 1 = 0.00505673 loss)
I0503 17:52:00.842516 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00610743 (* 1 = 0.00610743 loss)
I0503 17:52:00.842521 10699 sgd_solver.cpp:106] Iteration 289000, lr = 3.72529e-11
I0503 17:52:13.641602 10699 solver.cpp:337] Iteration 290000, Testing net (#0)
I0503 17:52:13.641626 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:52:13.641633 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:52:14.145256 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:52:14.145279 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:52:14.161728 10699 solver.cpp:228] Iteration 290000, loss = 0.0101889
I0503 17:52:14.161767 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00405607 (* 1 = 0.00405607 loss)
I0503 17:52:14.161773 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00628333 (* 1 = 0.00628333 loss)
I0503 17:52:14.161780 10699 sgd_solver.cpp:106] Iteration 290000, lr = 1.86265e-11
I0503 17:52:27.239279 10699 solver.cpp:228] Iteration 291000, loss = 0.00968567
I0503 17:52:27.239316 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00365623 (* 1 = 0.00365623 loss)
I0503 17:52:27.239328 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00368192 (* 1 = 0.00368192 loss)
I0503 17:52:27.239337 10699 sgd_solver.cpp:106] Iteration 291000, lr = 1.86265e-11
I0503 17:52:28.801132 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:52:40.281412 10699 solver.cpp:228] Iteration 292000, loss = 0.0105143
I0503 17:52:40.281450 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00286622 (* 1 = 0.00286622 loss)
I0503 17:52:40.281461 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00517825 (* 1 = 0.00517825 loss)
I0503 17:52:40.281469 10699 sgd_solver.cpp:106] Iteration 292000, lr = 1.86265e-11
I0503 17:52:53.419376 10699 solver.cpp:228] Iteration 293000, loss = 0.0108551
I0503 17:52:53.419421 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00363535 (* 1 = 0.00363535 loss)
I0503 17:52:53.419432 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00450039 (* 1 = 0.00450039 loss)
I0503 17:52:53.419440 10699 sgd_solver.cpp:106] Iteration 293000, lr = 1.86265e-11
I0503 17:53:01.948734 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:53:06.345813 10699 solver.cpp:228] Iteration 294000, loss = 0.0103082
I0503 17:53:06.345909 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0057656 (* 1 = 0.0057656 loss)
I0503 17:53:06.345937 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00789166 (* 1 = 0.00789166 loss)
I0503 17:53:06.345959 10699 sgd_solver.cpp:106] Iteration 294000, lr = 1.86265e-11
I0503 17:53:19.408118 10699 solver.cpp:337] Iteration 295000, Testing net (#0)
I0503 17:53:19.408211 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:53:19.408242 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:53:19.873646 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:53:19.873672 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.985701
I0503 17:53:19.875921 10699 solver.cpp:228] Iteration 295000, loss = 0.0104688
I0503 17:53:19.875941 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00410672 (* 1 = 0.00410672 loss)
I0503 17:53:19.875946 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00593231 (* 1 = 0.00593231 loss)
I0503 17:53:19.875952 10699 sgd_solver.cpp:106] Iteration 295000, lr = 1.86265e-11
I0503 17:53:32.852282 10699 solver.cpp:228] Iteration 296000, loss = 0.0105158
I0503 17:53:32.852380 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0032646 (* 1 = 0.0032646 loss)
I0503 17:53:32.852387 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00448584 (* 1 = 0.00448584 loss)
I0503 17:53:32.852393 10699 sgd_solver.cpp:106] Iteration 296000, lr = 1.86265e-11
I0503 17:53:33.293900 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:53:46.093613 10699 solver.cpp:228] Iteration 297000, loss = 0.0107657
I0503 17:53:46.093653 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00542786 (* 1 = 0.00542786 loss)
I0503 17:53:46.093662 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00770506 (* 1 = 0.00770506 loss)
I0503 17:53:46.093668 10699 sgd_solver.cpp:106] Iteration 297000, lr = 1.86265e-11
I0503 17:53:59.206890 10699 solver.cpp:228] Iteration 298000, loss = 0.0107456
I0503 17:53:59.206918 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00639245 (* 1 = 0.00639245 loss)
I0503 17:53:59.206924 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0126258 (* 1 = 0.0126258 loss)
I0503 17:53:59.206930 10699 sgd_solver.cpp:106] Iteration 298000, lr = 1.86265e-11
I0503 17:54:05.947505 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:54:12.309787 10699 solver.cpp:228] Iteration 299000, loss = 0.010859
I0503 17:54:12.309818 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00353136 (* 1 = 0.00353136 loss)
I0503 17:54:12.309823 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0053904 (* 1 = 0.0053904 loss)
I0503 17:54:12.309829 10699 sgd_solver.cpp:106] Iteration 299000, lr = 1.86265e-11
I0503 17:54:25.020867 10699 solver.cpp:454] Snapshotting to binary proto file mnist_iter_300000.caffemodel
I0503 17:54:25.026839 10699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mnist_iter_300000.solverstate
I0503 17:54:25.027287 10699 solver.cpp:337] Iteration 300000, Testing net (#0)
I0503 17:54:25.027300 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:54:25.027308 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:54:25.558066 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:54:25.558143 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:54:25.560771 10699 solver.cpp:228] Iteration 300000, loss = 0.0109758
I0503 17:54:25.560827 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00555438 (* 1 = 0.00555438 loss)
I0503 17:54:25.560856 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0115762 (* 1 = 0.0115762 loss)
I0503 17:54:25.560881 10699 sgd_solver.cpp:106] Iteration 300000, lr = 9.31323e-12
I0503 17:54:37.091187 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:54:38.576318 10699 solver.cpp:228] Iteration 301000, loss = 0.0104478
I0503 17:54:38.576350 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00433228 (* 1 = 0.00433228 loss)
I0503 17:54:38.576356 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0061872 (* 1 = 0.0061872 loss)
I0503 17:54:38.576361 10699 sgd_solver.cpp:106] Iteration 301000, lr = 9.31323e-12
I0503 17:54:51.747110 10699 solver.cpp:228] Iteration 302000, loss = 0.0111509
I0503 17:54:51.747150 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00510546 (* 1 = 0.00510546 loss)
I0503 17:54:51.747161 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00825156 (* 1 = 0.00825156 loss)
I0503 17:54:51.747170 10699 sgd_solver.cpp:106] Iteration 302000, lr = 9.31323e-12
I0503 17:55:04.669595 10699 solver.cpp:228] Iteration 303000, loss = 0.0107935
I0503 17:55:04.669641 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00584064 (* 1 = 0.00584064 loss)
I0503 17:55:04.669653 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00798554 (* 1 = 0.00798554 loss)
I0503 17:55:04.669661 10699 sgd_solver.cpp:106] Iteration 303000, lr = 9.31323e-12
I0503 17:55:09.323122 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:55:17.978871 10699 solver.cpp:228] Iteration 304000, loss = 0.0108058
I0503 17:55:17.978960 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00270384 (* 1 = 0.00270384 loss)
I0503 17:55:17.978987 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00354278 (* 1 = 0.00354278 loss)
I0503 17:55:17.979009 10699 sgd_solver.cpp:106] Iteration 304000, lr = 9.31323e-12
I0503 17:55:30.738245 10699 solver.cpp:337] Iteration 305000, Testing net (#0)
I0503 17:55:30.738268 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:55:30.738275 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:55:31.289887 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:55:31.289914 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:55:31.292126 10699 solver.cpp:228] Iteration 305000, loss = 0.00985394
I0503 17:55:31.292143 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00557727 (* 1 = 0.00557727 loss)
I0503 17:55:31.292152 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00619006 (* 1 = 0.00619006 loss)
I0503 17:55:31.292158 10699 sgd_solver.cpp:106] Iteration 305000, lr = 9.31323e-12
I0503 17:55:40.448616 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:55:43.868474 10699 solver.cpp:228] Iteration 306000, loss = 0.0109146
I0503 17:55:43.868508 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00255247 (* 1 = 0.00255247 loss)
I0503 17:55:43.868517 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00330151 (* 1 = 0.00330151 loss)
I0503 17:55:43.868525 10699 sgd_solver.cpp:106] Iteration 306000, lr = 9.31323e-12
I0503 17:55:56.837059 10699 solver.cpp:228] Iteration 307000, loss = 0.0117553
I0503 17:55:56.837088 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0071755 (* 1 = 0.0071755 loss)
I0503 17:55:56.837095 10699 solver.cpp:244]     Train net output #1: loss_single = 0.010393 (* 1 = 0.010393 loss)
I0503 17:55:56.837100 10699 sgd_solver.cpp:106] Iteration 307000, lr = 9.31323e-12
I0503 17:56:09.646591 10699 solver.cpp:228] Iteration 308000, loss = 0.0113278
I0503 17:56:09.646626 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00205664 (* 1 = 0.00205664 loss)
I0503 17:56:09.646632 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00291091 (* 1 = 0.00291091 loss)
I0503 17:56:09.646639 10699 sgd_solver.cpp:106] Iteration 308000, lr = 9.31323e-12
I0503 17:56:12.520535 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:56:22.588651 10699 solver.cpp:228] Iteration 309000, loss = 0.0103638
I0503 17:56:22.588755 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00538168 (* 1 = 0.00538168 loss)
I0503 17:56:22.588783 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00591491 (* 1 = 0.00591491 loss)
I0503 17:56:22.588807 10699 sgd_solver.cpp:106] Iteration 309000, lr = 9.31323e-12
I0503 17:56:35.705482 10699 solver.cpp:337] Iteration 310000, Testing net (#0)
I0503 17:56:35.705566 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:56:35.705605 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:56:36.241616 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:56:36.241646 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:56:36.255956 10699 solver.cpp:228] Iteration 310000, loss = 0.0103192
I0503 17:56:36.255981 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00361952 (* 1 = 0.00361952 loss)
I0503 17:56:36.255990 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00566493 (* 1 = 0.00566493 loss)
I0503 17:56:36.255997 10699 sgd_solver.cpp:106] Iteration 310000, lr = 4.65661e-12
I0503 17:56:43.941555 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:56:49.301169 10699 solver.cpp:228] Iteration 311000, loss = 0.011281
I0503 17:56:49.301329 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00389769 (* 1 = 0.00389769 loss)
I0503 17:56:49.301388 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00495017 (* 1 = 0.00495017 loss)
I0503 17:56:49.301439 10699 sgd_solver.cpp:106] Iteration 311000, lr = 4.65661e-12
I0503 17:57:02.441545 10699 solver.cpp:228] Iteration 312000, loss = 0.0115047
I0503 17:57:02.441583 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00393497 (* 1 = 0.00393497 loss)
I0503 17:57:02.441593 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00405865 (* 1 = 0.00405865 loss)
I0503 17:57:02.441601 10699 sgd_solver.cpp:106] Iteration 312000, lr = 4.65661e-12
I0503 17:57:11.487064 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:57:13.377380 10699 solver.cpp:228] Iteration 313000, loss = 0.0107905
I0503 17:57:13.377475 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00603855 (* 1 = 0.00603855 loss)
I0503 17:57:13.377509 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0105065 (* 1 = 0.0105065 loss)
I0503 17:57:13.377537 10699 sgd_solver.cpp:106] Iteration 313000, lr = 4.65661e-12
I0503 17:57:24.079783 10699 solver.cpp:228] Iteration 314000, loss = 0.0115466
I0503 17:57:24.079891 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00260853 (* 1 = 0.00260853 loss)
I0503 17:57:24.079900 10699 solver.cpp:244]     Train net output #1: loss_single = 0.003816 (* 1 = 0.003816 loss)
I0503 17:57:24.079905 10699 sgd_solver.cpp:106] Iteration 314000, lr = 4.65661e-12
I0503 17:57:31.939061 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:57:34.427456 10699 solver.cpp:337] Iteration 315000, Testing net (#0)
I0503 17:57:34.427482 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:57:34.427487 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:57:34.838989 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:57:34.839126 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:57:34.841727 10699 solver.cpp:228] Iteration 315000, loss = 0.0109481
I0503 17:57:34.841825 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00289414 (* 1 = 0.00289414 loss)
I0503 17:57:34.841873 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00501397 (* 1 = 0.00501397 loss)
I0503 17:57:34.841917 10699 sgd_solver.cpp:106] Iteration 315000, lr = 4.65661e-12
I0503 17:57:45.462379 10699 solver.cpp:228] Iteration 316000, loss = 0.0114908
I0503 17:57:45.462421 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00457849 (* 1 = 0.00457849 loss)
I0503 17:57:45.462759 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00814682 (* 1 = 0.00814682 loss)
I0503 17:57:45.462779 10699 sgd_solver.cpp:106] Iteration 316000, lr = 4.65661e-12
I0503 17:57:52.065101 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:57:56.044868 10699 solver.cpp:228] Iteration 317000, loss = 0.0112657
I0503 17:57:56.044939 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00501011 (* 1 = 0.00501011 loss)
I0503 17:57:56.044950 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00787903 (* 1 = 0.00787903 loss)
I0503 17:57:56.044958 10699 sgd_solver.cpp:106] Iteration 317000, lr = 4.65661e-12
I0503 17:58:06.533196 10699 solver.cpp:228] Iteration 318000, loss = 0.0109841
I0503 17:58:06.533298 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00466373 (* 1 = 0.00466373 loss)
I0503 17:58:06.533329 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0053431 (* 1 = 0.0053431 loss)
I0503 17:58:06.533355 10699 sgd_solver.cpp:106] Iteration 318000, lr = 4.65661e-12
I0503 17:58:13.233100 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:58:17.105538 10699 solver.cpp:228] Iteration 319000, loss = 0.0117213
I0503 17:58:17.105577 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00373936 (* 1 = 0.00373936 loss)
I0503 17:58:17.105587 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00642694 (* 1 = 0.00642694 loss)
I0503 17:58:17.105595 10699 sgd_solver.cpp:106] Iteration 319000, lr = 4.65661e-12
I0503 17:58:27.358964 10699 solver.cpp:337] Iteration 320000, Testing net (#0)
I0503 17:58:27.359041 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:58:27.359050 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:58:27.774652 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:58:27.774732 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:58:27.780194 10699 solver.cpp:228] Iteration 320000, loss = 0.0102423
I0503 17:58:27.780407 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00205573 (* 1 = 0.00205573 loss)
I0503 17:58:27.780606 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00285833 (* 1 = 0.00285833 loss)
I0503 17:58:27.780640 10699 sgd_solver.cpp:106] Iteration 320000, lr = 2.32831e-12
I0503 17:58:32.934226 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:58:38.172411 10699 solver.cpp:228] Iteration 321000, loss = 0.0108197
I0503 17:58:38.172446 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00310195 (* 1 = 0.00310195 loss)
I0503 17:58:38.172456 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0045608 (* 1 = 0.0045608 loss)
I0503 17:58:38.172462 10699 sgd_solver.cpp:106] Iteration 321000, lr = 2.32831e-12
I0503 17:58:48.469780 10699 solver.cpp:228] Iteration 322000, loss = 0.011455
I0503 17:58:48.469815 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00404169 (* 1 = 0.00404169 loss)
I0503 17:58:48.469823 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00463986 (* 1 = 0.00463986 loss)
I0503 17:58:48.469832 10699 sgd_solver.cpp:106] Iteration 322000, lr = 2.32831e-12
I0503 17:58:53.346679 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:58:59.668511 10699 solver.cpp:228] Iteration 323000, loss = 0.0105656
I0503 17:58:59.668627 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00560406 (* 1 = 0.00560406 loss)
I0503 17:58:59.668634 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00698077 (* 1 = 0.00698077 loss)
I0503 17:58:59.668638 10699 sgd_solver.cpp:106] Iteration 323000, lr = 2.32831e-12
I0503 17:59:12.564254 10699 solver.cpp:228] Iteration 324000, loss = 0.0126803
I0503 17:59:12.564285 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00729817 (* 1 = 0.00729817 loss)
I0503 17:59:12.564293 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0113231 (* 1 = 0.0113231 loss)
I0503 17:59:12.564301 10699 sgd_solver.cpp:106] Iteration 324000, lr = 2.32831e-12
I0503 17:59:25.247433 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 17:59:25.741286 10699 solver.cpp:337] Iteration 325000, Testing net (#0)
I0503 17:59:25.741312 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 17:59:25.741319 10699 net.cpp:709] Ignoring source layer loss_single
I0503 17:59:26.351007 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 17:59:26.351042 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 17:59:26.353569 10699 solver.cpp:228] Iteration 325000, loss = 0.011178
I0503 17:59:26.353596 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00425437 (* 1 = 0.00425437 loss)
I0503 17:59:26.353623 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00526171 (* 1 = 0.00526171 loss)
I0503 17:59:26.353631 10699 sgd_solver.cpp:106] Iteration 325000, lr = 2.32831e-12
I0503 17:59:39.246608 10699 solver.cpp:228] Iteration 326000, loss = 0.0105437
I0503 17:59:39.246739 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00342642 (* 1 = 0.00342642 loss)
I0503 17:59:39.246767 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00575196 (* 1 = 0.00575196 loss)
I0503 17:59:39.246788 10699 sgd_solver.cpp:106] Iteration 326000, lr = 2.32831e-12
I0503 17:59:51.969800 10699 solver.cpp:228] Iteration 327000, loss = 0.0111369
I0503 17:59:51.969830 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00622711 (* 1 = 0.00622711 loss)
I0503 17:59:51.969835 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0109957 (* 1 = 0.0109957 loss)
I0503 17:59:51.969840 10699 sgd_solver.cpp:106] Iteration 327000, lr = 2.32831e-12
I0503 17:59:55.178043 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:00:05.041019 10699 solver.cpp:228] Iteration 328000, loss = 0.0116469
I0503 18:00:05.041112 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00674883 (* 1 = 0.00674883 loss)
I0503 18:00:05.041158 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0101525 (* 1 = 0.0101525 loss)
I0503 18:00:05.041184 10699 sgd_solver.cpp:106] Iteration 328000, lr = 2.32831e-12
I0503 18:00:17.795035 10699 solver.cpp:228] Iteration 329000, loss = 0.0100571
I0503 18:00:17.795142 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00461595 (* 1 = 0.00461595 loss)
I0503 18:00:17.795153 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00537737 (* 1 = 0.00537737 loss)
I0503 18:00:17.795161 10699 sgd_solver.cpp:106] Iteration 329000, lr = 2.32831e-12
I0503 18:00:26.128551 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:00:30.566824 10699 solver.cpp:337] Iteration 330000, Testing net (#0)
I0503 18:00:30.566849 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:00:30.566855 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:00:31.176319 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:00:31.176345 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:00:31.185642 10699 solver.cpp:228] Iteration 330000, loss = 0.0121354
I0503 18:00:31.185708 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00412847 (* 1 = 0.00412847 loss)
I0503 18:00:31.185741 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00488454 (* 1 = 0.00488454 loss)
I0503 18:00:31.185770 10699 sgd_solver.cpp:106] Iteration 330000, lr = 1.16415e-12
I0503 18:00:44.196130 10699 solver.cpp:228] Iteration 331000, loss = 0.0108123
I0503 18:00:44.196218 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0048624 (* 1 = 0.0048624 loss)
I0503 18:00:44.196249 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00647708 (* 1 = 0.00647708 loss)
I0503 18:00:44.196276 10699 sgd_solver.cpp:106] Iteration 331000, lr = 1.16415e-12
I0503 18:00:56.710080 10699 solver.cpp:228] Iteration 332000, loss = 0.0111359
I0503 18:00:56.710170 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00427815 (* 1 = 0.00427815 loss)
I0503 18:00:56.710180 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00635144 (* 1 = 0.00635144 loss)
I0503 18:00:56.710186 10699 sgd_solver.cpp:106] Iteration 332000, lr = 1.16415e-12
I0503 18:00:57.051450 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:01:09.414494 10699 solver.cpp:228] Iteration 333000, loss = 0.0101554
I0503 18:01:09.414525 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00368538 (* 1 = 0.00368538 loss)
I0503 18:01:09.414530 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00404252 (* 1 = 0.00404252 loss)
I0503 18:01:09.414535 10699 sgd_solver.cpp:106] Iteration 333000, lr = 1.16415e-12
I0503 18:01:22.215189 10699 solver.cpp:228] Iteration 334000, loss = 0.0110794
I0503 18:01:22.219357 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00322022 (* 1 = 0.00322022 loss)
I0503 18:01:22.219426 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00392128 (* 1 = 0.00392128 loss)
I0503 18:01:22.219455 10699 sgd_solver.cpp:106] Iteration 334000, lr = 1.16415e-12
I0503 18:01:28.476027 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:01:35.237784 10699 solver.cpp:337] Iteration 335000, Testing net (#0)
I0503 18:01:35.237807 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:01:35.237812 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:01:35.851493 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:01:35.851527 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:01:35.854243 10699 solver.cpp:228] Iteration 335000, loss = 0.0106205
I0503 18:01:35.854272 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00473101 (* 1 = 0.00473101 loss)
I0503 18:01:35.854284 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00914773 (* 1 = 0.00914773 loss)
I0503 18:01:35.854292 10699 sgd_solver.cpp:106] Iteration 335000, lr = 1.16415e-12
I0503 18:01:48.925971 10699 solver.cpp:228] Iteration 336000, loss = 0.00964133
I0503 18:01:48.926008 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00232613 (* 1 = 0.00232613 loss)
I0503 18:01:48.926017 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00288401 (* 1 = 0.00288401 loss)
I0503 18:01:48.926023 10699 sgd_solver.cpp:106] Iteration 336000, lr = 1.16415e-12
I0503 18:01:59.660076 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:02:01.512926 10699 solver.cpp:228] Iteration 337000, loss = 0.0115818
I0503 18:02:01.512959 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00390084 (* 1 = 0.00390084 loss)
I0503 18:02:01.512965 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00423788 (* 1 = 0.00423788 loss)
I0503 18:02:01.512970 10699 sgd_solver.cpp:106] Iteration 337000, lr = 1.16415e-12
I0503 18:02:14.370054 10699 solver.cpp:228] Iteration 338000, loss = 0.0100276
I0503 18:02:14.370084 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00315211 (* 1 = 0.00315211 loss)
I0503 18:02:14.370090 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00491674 (* 1 = 0.00491674 loss)
I0503 18:02:14.370095 10699 sgd_solver.cpp:106] Iteration 338000, lr = 1.16415e-12
I0503 18:02:27.478426 10699 solver.cpp:228] Iteration 339000, loss = 0.0110883
I0503 18:02:27.478466 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00325648 (* 1 = 0.00325648 loss)
I0503 18:02:27.478476 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00626783 (* 1 = 0.00626783 loss)
I0503 18:02:27.478482 10699 sgd_solver.cpp:106] Iteration 339000, lr = 1.16415e-12
I0503 18:02:31.446377 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:02:40.329406 10699 solver.cpp:337] Iteration 340000, Testing net (#0)
I0503 18:02:40.329430 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:02:40.329435 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:02:40.891105 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:02:40.891139 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:02:40.893718 10699 solver.cpp:228] Iteration 340000, loss = 0.0118506
I0503 18:02:40.893749 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00328231 (* 1 = 0.00328231 loss)
I0503 18:02:40.893757 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00468944 (* 1 = 0.00468944 loss)
I0503 18:02:40.893766 10699 sgd_solver.cpp:106] Iteration 340000, lr = 5.82077e-13
I0503 18:02:53.838855 10699 solver.cpp:228] Iteration 341000, loss = 0.00953739
I0503 18:02:53.838896 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00394514 (* 1 = 0.00394514 loss)
I0503 18:02:53.838904 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00587158 (* 1 = 0.00587158 loss)
I0503 18:02:53.838913 10699 sgd_solver.cpp:106] Iteration 341000, lr = 5.82077e-13
I0503 18:03:02.223165 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:03:06.569519 10699 solver.cpp:228] Iteration 342000, loss = 0.0106208
I0503 18:03:06.569557 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00431793 (* 1 = 0.00431793 loss)
I0503 18:03:06.569567 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00535247 (* 1 = 0.00535247 loss)
I0503 18:03:06.569576 10699 sgd_solver.cpp:106] Iteration 342000, lr = 5.82077e-13
I0503 18:03:19.742548 10699 solver.cpp:228] Iteration 343000, loss = 0.010548
I0503 18:03:19.742580 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00694012 (* 1 = 0.00694012 loss)
I0503 18:03:19.742585 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00865841 (* 1 = 0.00865841 loss)
I0503 18:03:19.742591 10699 sgd_solver.cpp:106] Iteration 343000, lr = 5.82077e-13
I0503 18:03:32.780108 10699 solver.cpp:228] Iteration 344000, loss = 0.0101785
I0503 18:03:32.780206 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00367651 (* 1 = 0.00367651 loss)
I0503 18:03:32.780220 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00290124 (* 1 = 0.00290124 loss)
I0503 18:03:32.780228 10699 sgd_solver.cpp:106] Iteration 344000, lr = 5.82077e-13
I0503 18:03:34.286945 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:03:45.608085 10699 solver.cpp:337] Iteration 345000, Testing net (#0)
I0503 18:03:45.608114 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:03:45.608120 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:03:46.111075 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:03:46.111099 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:03:46.130192 10699 solver.cpp:228] Iteration 345000, loss = 0.0100169
I0503 18:03:46.130216 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00230465 (* 1 = 0.00230465 loss)
I0503 18:03:46.130223 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00302868 (* 1 = 0.00302868 loss)
I0503 18:03:46.130228 10699 sgd_solver.cpp:106] Iteration 345000, lr = 5.82077e-13
I0503 18:03:58.768872 10699 solver.cpp:228] Iteration 346000, loss = 0.0102567
I0503 18:03:58.768909 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0041355 (* 1 = 0.0041355 loss)
I0503 18:03:58.768921 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00749265 (* 1 = 0.00749265 loss)
I0503 18:03:58.768930 10699 sgd_solver.cpp:106] Iteration 346000, lr = 5.82077e-13
I0503 18:04:03.756288 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:04:11.582398 10699 solver.cpp:228] Iteration 347000, loss = 0.0110753
I0503 18:04:11.582438 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00360152 (* 1 = 0.00360152 loss)
I0503 18:04:11.582448 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00433873 (* 1 = 0.00433873 loss)
I0503 18:04:11.582453 10699 sgd_solver.cpp:106] Iteration 347000, lr = 5.82077e-13
I0503 18:04:24.650250 10699 solver.cpp:228] Iteration 348000, loss = 0.0107741
I0503 18:04:24.650291 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0032651 (* 1 = 0.0032651 loss)
I0503 18:04:24.650300 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00561461 (* 1 = 0.00561461 loss)
I0503 18:04:24.650307 10699 sgd_solver.cpp:106] Iteration 348000, lr = 5.82077e-13
I0503 18:04:35.190706 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:04:37.560171 10699 solver.cpp:228] Iteration 349000, loss = 0.0111586
I0503 18:04:37.560207 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00170444 (* 1 = 0.00170444 loss)
I0503 18:04:37.560217 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00224051 (* 1 = 0.00224051 loss)
I0503 18:04:37.560225 10699 sgd_solver.cpp:106] Iteration 349000, lr = 5.82077e-13
I0503 18:04:50.423884 10699 solver.cpp:337] Iteration 350000, Testing net (#0)
I0503 18:04:50.423915 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:04:50.423921 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:04:50.986029 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:04:50.986063 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:04:50.988596 10699 solver.cpp:228] Iteration 350000, loss = 0.0107752
I0503 18:04:50.988664 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00497959 (* 1 = 0.00497959 loss)
I0503 18:04:50.988698 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00564011 (* 1 = 0.00564011 loss)
I0503 18:04:50.988725 10699 sgd_solver.cpp:106] Iteration 350000, lr = 2.91038e-13
I0503 18:05:03.921725 10699 solver.cpp:228] Iteration 351000, loss = 0.0110034
I0503 18:05:03.921757 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00307596 (* 1 = 0.00307596 loss)
I0503 18:05:03.921763 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0047042 (* 1 = 0.0047042 loss)
I0503 18:05:03.921767 10699 sgd_solver.cpp:106] Iteration 351000, lr = 2.91038e-13
I0503 18:05:07.537289 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:05:16.897256 10699 solver.cpp:228] Iteration 352000, loss = 0.0105226
I0503 18:05:16.897344 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00508403 (* 1 = 0.00508403 loss)
I0503 18:05:16.897390 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00768864 (* 1 = 0.00768864 loss)
I0503 18:05:16.897413 10699 sgd_solver.cpp:106] Iteration 352000, lr = 2.91038e-13
I0503 18:05:29.973104 10699 solver.cpp:228] Iteration 353000, loss = 0.0114214
I0503 18:05:29.973143 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0058512 (* 1 = 0.0058512 loss)
I0503 18:05:29.973155 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00529497 (* 1 = 0.00529497 loss)
I0503 18:05:29.973165 10699 sgd_solver.cpp:106] Iteration 353000, lr = 2.91038e-13
I0503 18:05:40.289317 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:05:42.909894 10699 solver.cpp:228] Iteration 354000, loss = 0.00986084
I0503 18:05:42.909930 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00247136 (* 1 = 0.00247136 loss)
I0503 18:05:42.909940 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00367373 (* 1 = 0.00367373 loss)
I0503 18:05:42.909948 10699 sgd_solver.cpp:106] Iteration 354000, lr = 2.91038e-13
I0503 18:05:55.739624 10699 solver.cpp:337] Iteration 355000, Testing net (#0)
I0503 18:05:55.739655 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:05:55.739662 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:05:56.242913 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:05:56.242939 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:05:56.262147 10699 solver.cpp:228] Iteration 355000, loss = 0.0111246
I0503 18:05:56.262176 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00303949 (* 1 = 0.00303949 loss)
I0503 18:05:56.262181 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00403425 (* 1 = 0.00403425 loss)
I0503 18:05:56.262187 10699 sgd_solver.cpp:106] Iteration 355000, lr = 2.91038e-13
I0503 18:06:08.873775 10699 solver.cpp:228] Iteration 356000, loss = 0.0103781
I0503 18:06:08.873875 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0030738 (* 1 = 0.0030738 loss)
I0503 18:06:08.873903 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00429483 (* 1 = 0.00429483 loss)
I0503 18:06:08.873926 10699 sgd_solver.cpp:106] Iteration 356000, lr = 2.91038e-13
I0503 18:06:10.275885 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:06:21.861815 10699 solver.cpp:228] Iteration 357000, loss = 0.0108811
I0503 18:06:21.861958 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00225337 (* 1 = 0.00225337 loss)
I0503 18:06:21.861987 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00366678 (* 1 = 0.00366678 loss)
I0503 18:06:21.862012 10699 sgd_solver.cpp:106] Iteration 357000, lr = 2.91038e-13
I0503 18:06:34.889983 10699 solver.cpp:228] Iteration 358000, loss = 0.0106
I0503 18:06:34.890024 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00340819 (* 1 = 0.00340819 loss)
I0503 18:06:34.890034 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0057993 (* 1 = 0.0057993 loss)
I0503 18:06:34.890041 10699 sgd_solver.cpp:106] Iteration 358000, lr = 2.91038e-13
I0503 18:06:42.829848 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:06:47.895642 10699 solver.cpp:228] Iteration 359000, loss = 0.0107333
I0503 18:06:47.895675 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00689404 (* 1 = 0.00689404 loss)
I0503 18:06:47.895683 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00727633 (* 1 = 0.00727633 loss)
I0503 18:06:47.895686 10699 sgd_solver.cpp:106] Iteration 359000, lr = 2.91038e-13
I0503 18:07:01.130594 10699 solver.cpp:337] Iteration 360000, Testing net (#0)
I0503 18:07:01.130691 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:07:01.130697 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:07:01.721604 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:07:01.721631 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:07:01.724139 10699 solver.cpp:228] Iteration 360000, loss = 0.0112487
I0503 18:07:01.724170 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00604708 (* 1 = 0.00604708 loss)
I0503 18:07:01.724367 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00616321 (* 1 = 0.00616321 loss)
I0503 18:07:01.724504 10699 sgd_solver.cpp:106] Iteration 360000, lr = 1.45519e-13
I0503 18:07:14.354365 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:07:14.948297 10699 solver.cpp:228] Iteration 361000, loss = 0.0106782
I0503 18:07:14.948457 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00398222 (* 1 = 0.00398222 loss)
I0503 18:07:14.948508 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00658145 (* 1 = 0.00658145 loss)
I0503 18:07:14.948552 10699 sgd_solver.cpp:106] Iteration 361000, lr = 1.45519e-13
I0503 18:07:28.187367 10699 solver.cpp:228] Iteration 362000, loss = 0.0113594
I0503 18:07:28.187467 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00426952 (* 1 = 0.00426952 loss)
I0503 18:07:28.187500 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00685769 (* 1 = 0.00685769 loss)
I0503 18:07:28.187526 10699 sgd_solver.cpp:106] Iteration 362000, lr = 1.45519e-13
I0503 18:07:41.374248 10699 solver.cpp:228] Iteration 363000, loss = 0.010169
I0503 18:07:41.374359 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00428325 (* 1 = 0.00428325 loss)
I0503 18:07:41.374369 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00646565 (* 1 = 0.00646565 loss)
I0503 18:07:41.374379 10699 sgd_solver.cpp:106] Iteration 363000, lr = 1.45519e-13
I0503 18:07:47.924513 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:07:54.359249 10699 solver.cpp:228] Iteration 364000, loss = 0.0113406
I0503 18:07:54.359288 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00556369 (* 1 = 0.00556369 loss)
I0503 18:07:54.359299 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00629002 (* 1 = 0.00629002 loss)
I0503 18:07:54.359307 10699 sgd_solver.cpp:106] Iteration 364000, lr = 1.45519e-13
I0503 18:08:07.288614 10699 solver.cpp:337] Iteration 365000, Testing net (#0)
I0503 18:08:07.288640 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:08:07.288648 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:08:07.849311 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:08:07.849396 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:08:07.851708 10699 solver.cpp:228] Iteration 365000, loss = 0.0110184
I0503 18:08:07.851730 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00281305 (* 1 = 0.00281305 loss)
I0503 18:08:07.851740 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00593559 (* 1 = 0.00593559 loss)
I0503 18:08:07.851749 10699 sgd_solver.cpp:106] Iteration 365000, lr = 1.45519e-13
I0503 18:08:18.187080 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:08:20.858422 10699 solver.cpp:228] Iteration 366000, loss = 0.0107595
I0503 18:08:20.858460 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00356563 (* 1 = 0.00356563 loss)
I0503 18:08:20.858471 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0040642 (* 1 = 0.0040642 loss)
I0503 18:08:20.858479 10699 sgd_solver.cpp:106] Iteration 366000, lr = 1.45519e-13
I0503 18:08:33.649662 10699 solver.cpp:228] Iteration 367000, loss = 0.011598
I0503 18:08:33.649771 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0040626 (* 1 = 0.0040626 loss)
I0503 18:08:33.649806 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00599658 (* 1 = 0.00599658 loss)
I0503 18:08:33.649829 10699 sgd_solver.cpp:106] Iteration 367000, lr = 1.45519e-13
I0503 18:08:46.682889 10699 solver.cpp:228] Iteration 368000, loss = 0.0100097
I0503 18:08:46.682929 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.006471 (* 1 = 0.006471 loss)
I0503 18:08:46.682936 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00844114 (* 1 = 0.00844114 loss)
I0503 18:08:46.682946 10699 sgd_solver.cpp:106] Iteration 368000, lr = 1.45519e-13
I0503 18:08:48.781078 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:08:59.379185 10699 solver.cpp:228] Iteration 369000, loss = 0.0121029
I0503 18:08:59.379217 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00444719 (* 1 = 0.00444719 loss)
I0503 18:08:59.379223 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0081425 (* 1 = 0.0081425 loss)
I0503 18:08:59.379230 10699 sgd_solver.cpp:106] Iteration 369000, lr = 1.45519e-13
I0503 18:09:12.202765 10699 solver.cpp:337] Iteration 370000, Testing net (#0)
I0503 18:09:12.202795 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:09:12.202802 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:09:12.728132 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:09:12.728402 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:09:12.731036 10699 solver.cpp:228] Iteration 370000, loss = 0.0117988
I0503 18:09:12.731215 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0057153 (* 1 = 0.0057153 loss)
I0503 18:09:12.731343 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00832046 (* 1 = 0.00832046 loss)
I0503 18:09:12.731472 10699 sgd_solver.cpp:106] Iteration 370000, lr = 7.27596e-14
I0503 18:09:19.133726 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:09:25.415845 10699 solver.cpp:228] Iteration 371000, loss = 0.0103309
I0503 18:09:25.415880 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00406569 (* 1 = 0.00406569 loss)
I0503 18:09:25.415889 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00525762 (* 1 = 0.00525762 loss)
I0503 18:09:25.415897 10699 sgd_solver.cpp:106] Iteration 371000, lr = 7.27596e-14
I0503 18:09:38.078925 10699 solver.cpp:228] Iteration 372000, loss = 0.0110566
I0503 18:09:38.079021 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0052629 (* 1 = 0.0052629 loss)
I0503 18:09:38.079051 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00767888 (* 1 = 0.00767888 loss)
I0503 18:09:38.079077 10699 sgd_solver.cpp:106] Iteration 372000, lr = 7.27596e-14
I0503 18:09:49.856349 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:09:51.293195 10699 solver.cpp:228] Iteration 373000, loss = 0.0112063
I0503 18:09:51.293228 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00413283 (* 1 = 0.00413283 loss)
I0503 18:09:51.293234 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00611255 (* 1 = 0.00611255 loss)
I0503 18:09:51.293241 10699 sgd_solver.cpp:106] Iteration 373000, lr = 7.27596e-14
I0503 18:10:04.349784 10699 solver.cpp:228] Iteration 374000, loss = 0.0115777
I0503 18:10:04.349879 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00327681 (* 1 = 0.00327681 loss)
I0503 18:10:04.349903 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00288102 (* 1 = 0.00288102 loss)
I0503 18:10:04.349925 10699 sgd_solver.cpp:106] Iteration 374000, lr = 7.27596e-14
I0503 18:10:17.523924 10699 solver.cpp:337] Iteration 375000, Testing net (#0)
I0503 18:10:17.523949 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:10:17.523955 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:10:18.051913 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:10:18.052181 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:10:18.054594 10699 solver.cpp:228] Iteration 375000, loss = 0.0104894
I0503 18:10:18.054618 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00596302 (* 1 = 0.00596302 loss)
I0503 18:10:18.054808 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0073321 (* 1 = 0.0073321 loss)
I0503 18:10:18.054924 10699 sgd_solver.cpp:106] Iteration 375000, lr = 7.27596e-14
I0503 18:10:21.723218 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:10:31.047577 10699 solver.cpp:228] Iteration 376000, loss = 0.0125491
I0503 18:10:31.047619 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00527139 (* 1 = 0.00527139 loss)
I0503 18:10:31.047629 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00732373 (* 1 = 0.00732373 loss)
I0503 18:10:31.047638 10699 sgd_solver.cpp:106] Iteration 376000, lr = 7.27596e-14
I0503 18:10:44.191289 10699 solver.cpp:228] Iteration 377000, loss = 0.0111273
I0503 18:10:44.191335 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00424298 (* 1 = 0.00424298 loss)
I0503 18:10:44.191346 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00522707 (* 1 = 0.00522707 loss)
I0503 18:10:44.191354 10699 sgd_solver.cpp:106] Iteration 377000, lr = 7.27596e-14
I0503 18:10:54.494143 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:10:57.024519 10699 solver.cpp:228] Iteration 378000, loss = 0.0105962
I0503 18:10:57.024607 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00360501 (* 1 = 0.00360501 loss)
I0503 18:10:57.024641 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00373422 (* 1 = 0.00373422 loss)
I0503 18:10:57.024669 10699 sgd_solver.cpp:106] Iteration 378000, lr = 7.27596e-14
I0503 18:11:09.999286 10699 solver.cpp:228] Iteration 379000, loss = 0.010491
I0503 18:11:09.999327 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00397575 (* 1 = 0.00397575 loss)
I0503 18:11:09.999336 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00704717 (* 1 = 0.00704717 loss)
I0503 18:11:09.999343 10699 sgd_solver.cpp:106] Iteration 379000, lr = 7.27596e-14
I0503 18:11:22.793514 10699 solver.cpp:337] Iteration 380000, Testing net (#0)
I0503 18:11:22.793543 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:11:22.793550 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:11:23.333576 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:11:23.340131 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:11:23.343755 10699 solver.cpp:228] Iteration 380000, loss = 0.00951111
I0503 18:11:23.343879 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00364871 (* 1 = 0.00364871 loss)
I0503 18:11:23.343937 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00580851 (* 1 = 0.00580851 loss)
I0503 18:11:23.343993 10699 sgd_solver.cpp:106] Iteration 380000, lr = 3.63798e-14
I0503 18:11:25.038271 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:11:34.596356 10699 solver.cpp:228] Iteration 381000, loss = 0.0109433
I0503 18:11:34.596388 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00411436 (* 1 = 0.00411436 loss)
I0503 18:11:34.596395 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00439123 (* 1 = 0.00439123 loss)
I0503 18:11:34.596400 10699 sgd_solver.cpp:106] Iteration 381000, lr = 3.63798e-14
I0503 18:11:44.835538 10699 solver.cpp:228] Iteration 382000, loss = 0.0116349
I0503 18:11:44.835575 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00371485 (* 1 = 0.00371485 loss)
I0503 18:11:44.835584 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00436375 (* 1 = 0.00436375 loss)
I0503 18:11:44.835593 10699 sgd_solver.cpp:106] Iteration 382000, lr = 3.63798e-14
I0503 18:11:47.078083 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:11:55.690888 10699 solver.cpp:228] Iteration 383000, loss = 0.0124064
I0503 18:11:55.691424 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00341827 (* 1 = 0.00341827 loss)
I0503 18:11:55.691642 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00696029 (* 1 = 0.00696029 loss)
I0503 18:11:55.691843 10699 sgd_solver.cpp:106] Iteration 383000, lr = 3.63798e-14
I0503 18:12:06.168706 10699 solver.cpp:228] Iteration 384000, loss = 0.0103269
I0503 18:12:06.168741 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00281925 (* 1 = 0.00281925 loss)
I0503 18:12:06.168751 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00377597 (* 1 = 0.00377597 loss)
I0503 18:12:06.168757 10699 sgd_solver.cpp:106] Iteration 384000, lr = 3.63798e-14
I0503 18:12:07.943846 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:12:16.891141 10699 solver.cpp:337] Iteration 385000, Testing net (#0)
I0503 18:12:16.891222 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:12:16.891244 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:12:17.335605 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:12:17.335638 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:12:17.338052 10699 solver.cpp:228] Iteration 385000, loss = 0.0113101
I0503 18:12:17.338074 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0073761 (* 1 = 0.0073761 loss)
I0503 18:12:17.338083 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00963253 (* 1 = 0.00963253 loss)
I0503 18:12:17.338093 10699 sgd_solver.cpp:106] Iteration 385000, lr = 3.63798e-14
I0503 18:12:27.009166 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:12:28.211047 10699 solver.cpp:228] Iteration 386000, loss = 0.0116424
I0503 18:12:28.211083 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0060696 (* 1 = 0.0060696 loss)
I0503 18:12:28.211089 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00691185 (* 1 = 0.00691185 loss)
I0503 18:12:28.211094 10699 sgd_solver.cpp:106] Iteration 386000, lr = 3.63798e-14
I0503 18:12:38.735206 10699 solver.cpp:228] Iteration 387000, loss = 0.0109315
I0503 18:12:38.735296 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00652384 (* 1 = 0.00652384 loss)
I0503 18:12:38.735321 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0156234 (* 1 = 0.0156234 loss)
I0503 18:12:38.735340 10699 sgd_solver.cpp:106] Iteration 387000, lr = 3.63798e-14
I0503 18:12:46.763484 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:12:49.144747 10699 solver.cpp:228] Iteration 388000, loss = 0.0109855
I0503 18:12:49.144778 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00361608 (* 1 = 0.00361608 loss)
I0503 18:12:49.144784 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00415641 (* 1 = 0.00415641 loss)
I0503 18:12:49.144791 10699 sgd_solver.cpp:106] Iteration 388000, lr = 3.63798e-14
I0503 18:12:59.764520 10699 solver.cpp:228] Iteration 389000, loss = 0.0106396
I0503 18:12:59.764737 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00314664 (* 1 = 0.00314664 loss)
I0503 18:12:59.764789 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00448905 (* 1 = 0.00448905 loss)
I0503 18:12:59.764832 10699 sgd_solver.cpp:106] Iteration 389000, lr = 3.63798e-14
I0503 18:13:07.828331 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:13:10.589056 10699 solver.cpp:337] Iteration 390000, Testing net (#0)
I0503 18:13:10.589131 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:13:10.589153 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:13:10.978840 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:13:10.978874 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:13:10.981426 10699 solver.cpp:228] Iteration 390000, loss = 0.0112251
I0503 18:13:10.981449 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00509177 (* 1 = 0.00509177 loss)
I0503 18:13:10.981461 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00764941 (* 1 = 0.00764941 loss)
I0503 18:13:10.981469 10699 sgd_solver.cpp:106] Iteration 390000, lr = 1.81899e-14
I0503 18:13:21.330552 10699 solver.cpp:228] Iteration 391000, loss = 0.0107006
I0503 18:13:21.330585 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00567442 (* 1 = 0.00567442 loss)
I0503 18:13:21.330591 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0070644 (* 1 = 0.0070644 loss)
I0503 18:13:21.330597 10699 sgd_solver.cpp:106] Iteration 391000, lr = 1.81899e-14
I0503 18:13:30.556483 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:13:33.993892 10699 solver.cpp:228] Iteration 392000, loss = 0.0106728
I0503 18:13:33.993981 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00187637 (* 1 = 0.00187637 loss)
I0503 18:13:33.994009 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0011156 (* 1 = 0.0011156 loss)
I0503 18:13:33.994032 10699 sgd_solver.cpp:106] Iteration 392000, lr = 1.81899e-14
I0503 18:13:46.807512 10699 solver.cpp:228] Iteration 393000, loss = 0.0107223
I0503 18:13:46.807541 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00199909 (* 1 = 0.00199909 loss)
I0503 18:13:46.807548 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0030815 (* 1 = 0.0030815 loss)
I0503 18:13:46.807551 10699 sgd_solver.cpp:106] Iteration 393000, lr = 1.81899e-14
I0503 18:13:59.600992 10699 solver.cpp:228] Iteration 394000, loss = 0.00940565
I0503 18:13:59.601029 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00369836 (* 1 = 0.00369836 loss)
I0503 18:13:59.601037 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00477408 (* 1 = 0.00477408 loss)
I0503 18:13:59.601044 10699 sgd_solver.cpp:106] Iteration 394000, lr = 1.81899e-14
I0503 18:14:02.213795 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:14:12.842517 10699 solver.cpp:337] Iteration 395000, Testing net (#0)
I0503 18:14:12.842604 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:14:12.842628 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:14:13.468811 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:14:13.468837 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:14:13.487113 10699 solver.cpp:228] Iteration 395000, loss = 0.0104235
I0503 18:14:13.487140 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00548688 (* 1 = 0.00548688 loss)
I0503 18:14:13.487146 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00747726 (* 1 = 0.00747726 loss)
I0503 18:14:13.487152 10699 sgd_solver.cpp:106] Iteration 395000, lr = 1.81899e-14
I0503 18:14:26.564505 10699 solver.cpp:228] Iteration 396000, loss = 0.0115244
I0503 18:14:26.564534 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00424427 (* 1 = 0.00424427 loss)
I0503 18:14:26.564540 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00699478 (* 1 = 0.00699478 loss)
I0503 18:14:26.564546 10699 sgd_solver.cpp:106] Iteration 396000, lr = 1.81899e-14
I0503 18:14:33.297200 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:14:39.436069 10699 solver.cpp:228] Iteration 397000, loss = 0.0105264
I0503 18:14:39.436106 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00152598 (* 1 = 0.00152598 loss)
I0503 18:14:39.436115 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00229396 (* 1 = 0.00229396 loss)
I0503 18:14:39.436122 10699 sgd_solver.cpp:106] Iteration 397000, lr = 1.81899e-14
I0503 18:14:52.244195 10699 solver.cpp:228] Iteration 398000, loss = 0.0110241
I0503 18:14:52.244237 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00590574 (* 1 = 0.00590574 loss)
I0503 18:14:52.244247 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00812747 (* 1 = 0.00812747 loss)
I0503 18:14:52.244256 10699 sgd_solver.cpp:106] Iteration 398000, lr = 1.81899e-14
I0503 18:15:04.972144 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:15:05.133826 10699 solver.cpp:228] Iteration 399000, loss = 0.0114189
I0503 18:15:05.133857 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00404073 (* 1 = 0.00404073 loss)
I0503 18:15:05.133864 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00463644 (* 1 = 0.00463644 loss)
I0503 18:15:05.133870 10699 sgd_solver.cpp:106] Iteration 399000, lr = 1.81899e-14
I0503 18:15:17.876440 10699 solver.cpp:454] Snapshotting to binary proto file mnist_iter_400000.caffemodel
I0503 18:15:17.885556 10699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mnist_iter_400000.solverstate
I0503 18:15:17.886001 10699 solver.cpp:337] Iteration 400000, Testing net (#0)
I0503 18:15:17.886015 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:15:17.886024 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:15:18.427733 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:15:18.427767 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:15:18.444953 10699 solver.cpp:228] Iteration 400000, loss = 0.0103126
I0503 18:15:18.444983 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00349602 (* 1 = 0.00349602 loss)
I0503 18:15:18.444989 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00638179 (* 1 = 0.00638179 loss)
I0503 18:15:18.444995 10699 sgd_solver.cpp:106] Iteration 400000, lr = 9.09495e-15
I0503 18:15:31.414863 10699 solver.cpp:228] Iteration 401000, loss = 0.010016
I0503 18:15:31.414958 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00761893 (* 1 = 0.00761893 loss)
I0503 18:15:31.414985 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00836499 (* 1 = 0.00836499 loss)
I0503 18:15:31.415005 10699 sgd_solver.cpp:106] Iteration 401000, lr = 9.09495e-15
I0503 18:15:35.350550 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:15:44.336136 10699 solver.cpp:228] Iteration 402000, loss = 0.0111531
I0503 18:15:44.336170 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00405905 (* 1 = 0.00405905 loss)
I0503 18:15:44.336175 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00577995 (* 1 = 0.00577995 loss)
I0503 18:15:44.336181 10699 sgd_solver.cpp:106] Iteration 402000, lr = 9.09495e-15
I0503 18:15:57.499843 10699 solver.cpp:228] Iteration 403000, loss = 0.00972397
I0503 18:15:57.499874 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00314135 (* 1 = 0.00314135 loss)
I0503 18:15:57.499883 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00333961 (* 1 = 0.00333961 loss)
I0503 18:15:57.499889 10699 sgd_solver.cpp:106] Iteration 403000, lr = 9.09495e-15
I0503 18:16:07.768546 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:16:10.343189 10699 solver.cpp:228] Iteration 404000, loss = 0.0102277
I0503 18:16:10.343230 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00289885 (* 1 = 0.00289885 loss)
I0503 18:16:10.343240 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00532949 (* 1 = 0.00532949 loss)
I0503 18:16:10.343250 10699 sgd_solver.cpp:106] Iteration 404000, lr = 9.09495e-15
I0503 18:16:23.507258 10699 solver.cpp:337] Iteration 405000, Testing net (#0)
I0503 18:16:23.507292 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:16:23.507300 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:16:24.001570 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:16:24.001601 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:16:24.003859 10699 solver.cpp:228] Iteration 405000, loss = 0.0105907
I0503 18:16:24.003878 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00359776 (* 1 = 0.00359776 loss)
I0503 18:16:24.003883 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00580021 (* 1 = 0.00580021 loss)
I0503 18:16:24.003892 10699 sgd_solver.cpp:106] Iteration 405000, lr = 9.09495e-15
I0503 18:16:36.763015 10699 solver.cpp:228] Iteration 406000, loss = 0.0106468
I0503 18:16:36.763047 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0206648 (* 1 = 0.0206648 loss)
I0503 18:16:36.763054 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0230912 (* 1 = 0.0230912 loss)
I0503 18:16:36.763059 10699 sgd_solver.cpp:106] Iteration 406000, lr = 9.09495e-15
I0503 18:16:38.490010 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:16:49.726147 10699 solver.cpp:228] Iteration 407000, loss = 0.0104453
I0503 18:16:49.726244 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00625927 (* 1 = 0.00625927 loss)
I0503 18:16:49.726276 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00806011 (* 1 = 0.00806011 loss)
I0503 18:16:49.726321 10699 sgd_solver.cpp:106] Iteration 407000, lr = 9.09495e-15
I0503 18:17:02.472090 10699 solver.cpp:228] Iteration 408000, loss = 0.010688
I0503 18:17:02.472129 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00297355 (* 1 = 0.00297355 loss)
I0503 18:17:02.472138 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00373566 (* 1 = 0.00373566 loss)
I0503 18:17:02.472146 10699 sgd_solver.cpp:106] Iteration 408000, lr = 9.09495e-15
I0503 18:17:09.668948 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:17:15.289683 10699 solver.cpp:228] Iteration 409000, loss = 0.010863
I0503 18:17:15.289727 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0038824 (* 1 = 0.0038824 loss)
I0503 18:17:15.289747 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00529823 (* 1 = 0.00529823 loss)
I0503 18:17:15.289755 10699 sgd_solver.cpp:106] Iteration 409000, lr = 9.09495e-15
I0503 18:17:28.549499 10699 solver.cpp:337] Iteration 410000, Testing net (#0)
I0503 18:17:28.549571 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:17:28.549592 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:17:29.086518 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:17:29.086606 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:17:29.089223 10699 solver.cpp:228] Iteration 410000, loss = 0.0107553
I0503 18:17:29.089284 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00606905 (* 1 = 0.00606905 loss)
I0503 18:17:29.089315 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00840458 (* 1 = 0.00840458 loss)
I0503 18:17:29.089344 10699 sgd_solver.cpp:106] Iteration 410000, lr = 4.54747e-15
I0503 18:17:41.108885 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:17:41.994479 10699 solver.cpp:228] Iteration 411000, loss = 0.010164
I0503 18:17:41.994518 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00321571 (* 1 = 0.00321571 loss)
I0503 18:17:41.994529 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00440928 (* 1 = 0.00440928 loss)
I0503 18:17:41.994539 10699 sgd_solver.cpp:106] Iteration 411000, lr = 4.54747e-15
I0503 18:17:54.705744 10699 solver.cpp:228] Iteration 412000, loss = 0.0102552
I0503 18:17:54.705839 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00435037 (* 1 = 0.00435037 loss)
I0503 18:17:54.705874 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00573732 (* 1 = 0.00573732 loss)
I0503 18:17:54.705901 10699 sgd_solver.cpp:106] Iteration 412000, lr = 4.54747e-15
I0503 18:18:07.746860 10699 solver.cpp:228] Iteration 413000, loss = 0.0103423
I0503 18:18:07.746891 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00415734 (* 1 = 0.00415734 loss)
I0503 18:18:07.746896 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00423282 (* 1 = 0.00423282 loss)
I0503 18:18:07.746902 10699 sgd_solver.cpp:106] Iteration 413000, lr = 4.54747e-15
I0503 18:18:12.751097 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:18:21.107859 10699 solver.cpp:228] Iteration 414000, loss = 0.0124442
I0503 18:18:21.107895 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00251999 (* 1 = 0.00251999 loss)
I0503 18:18:21.107904 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00242903 (* 1 = 0.00242903 loss)
I0503 18:18:21.107913 10699 sgd_solver.cpp:106] Iteration 414000, lr = 4.54747e-15
I0503 18:18:33.964021 10699 solver.cpp:337] Iteration 415000, Testing net (#0)
I0503 18:18:33.964048 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:18:33.964056 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:18:34.580334 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:18:34.580371 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:18:34.599602 10699 solver.cpp:228] Iteration 415000, loss = 0.0115491
I0503 18:18:34.599632 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00328488 (* 1 = 0.00328488 loss)
I0503 18:18:34.599639 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00514799 (* 1 = 0.00514799 loss)
I0503 18:18:34.599647 10699 sgd_solver.cpp:106] Iteration 415000, lr = 4.54747e-15
I0503 18:18:44.997623 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:18:47.635192 10699 solver.cpp:228] Iteration 416000, loss = 0.0113579
I0503 18:18:47.635231 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00377553 (* 1 = 0.00377553 loss)
I0503 18:18:47.635241 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00351236 (* 1 = 0.00351236 loss)
I0503 18:18:47.635247 10699 sgd_solver.cpp:106] Iteration 416000, lr = 4.54747e-15
I0503 18:19:00.552764 10699 solver.cpp:228] Iteration 417000, loss = 0.0104667
I0503 18:19:00.552808 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00515689 (* 1 = 0.00515689 loss)
I0503 18:19:00.552816 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00521662 (* 1 = 0.00521662 loss)
I0503 18:19:00.552825 10699 sgd_solver.cpp:106] Iteration 417000, lr = 4.54747e-15
I0503 18:19:13.447304 10699 solver.cpp:228] Iteration 418000, loss = 0.0102775
I0503 18:19:13.447342 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00309678 (* 1 = 0.00309678 loss)
I0503 18:19:13.447352 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00501582 (* 1 = 0.00501582 loss)
I0503 18:19:13.447360 10699 sgd_solver.cpp:106] Iteration 418000, lr = 4.54747e-15
I0503 18:19:16.137454 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:19:26.391465 10699 solver.cpp:228] Iteration 419000, loss = 0.0105642
I0503 18:19:26.391510 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00791783 (* 1 = 0.00791783 loss)
I0503 18:19:26.391520 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0165096 (* 1 = 0.0165096 loss)
I0503 18:19:26.391528 10699 sgd_solver.cpp:106] Iteration 419000, lr = 4.54747e-15
I0503 18:19:39.545411 10699 solver.cpp:337] Iteration 420000, Testing net (#0)
I0503 18:19:39.545439 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:19:39.545444 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:19:40.096040 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:19:40.096063 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:19:40.114009 10699 solver.cpp:228] Iteration 420000, loss = 0.0103605
I0503 18:19:40.114027 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00471451 (* 1 = 0.00471451 loss)
I0503 18:19:40.114032 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00753727 (* 1 = 0.00753727 loss)
I0503 18:19:40.114037 10699 sgd_solver.cpp:106] Iteration 420000, lr = 2.27374e-15
I0503 18:19:47.531642 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:19:53.044709 10699 solver.cpp:228] Iteration 421000, loss = 0.0115207
I0503 18:19:53.044751 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00382238 (* 1 = 0.00382238 loss)
I0503 18:19:53.044760 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00453768 (* 1 = 0.00453768 loss)
I0503 18:19:53.044767 10699 sgd_solver.cpp:106] Iteration 421000, lr = 2.27374e-15
I0503 18:20:05.901214 10699 solver.cpp:228] Iteration 422000, loss = 0.0095799
I0503 18:20:05.901242 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00360243 (* 1 = 0.00360243 loss)
I0503 18:20:05.901247 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00540449 (* 1 = 0.00540449 loss)
I0503 18:20:05.901252 10699 sgd_solver.cpp:106] Iteration 422000, lr = 2.27374e-15
I0503 18:20:18.736824 10699 solver.cpp:228] Iteration 423000, loss = 0.010784
I0503 18:20:18.737011 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00573806 (* 1 = 0.00573806 loss)
I0503 18:20:18.737062 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00809298 (* 1 = 0.00809298 loss)
I0503 18:20:18.737105 10699 sgd_solver.cpp:106] Iteration 423000, lr = 2.27374e-15
I0503 18:20:19.388998 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:20:31.664736 10699 solver.cpp:228] Iteration 424000, loss = 0.0110214
I0503 18:20:31.664772 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00375992 (* 1 = 0.00375992 loss)
I0503 18:20:31.664782 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00465392 (* 1 = 0.00465392 loss)
I0503 18:20:31.664790 10699 sgd_solver.cpp:106] Iteration 424000, lr = 2.27374e-15
I0503 18:20:44.739897 10699 solver.cpp:337] Iteration 425000, Testing net (#0)
I0503 18:20:44.739979 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:20:44.740000 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:20:45.296383 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:20:45.296417 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:20:45.299159 10699 solver.cpp:228] Iteration 425000, loss = 0.00961943
I0503 18:20:45.299230 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00730637 (* 1 = 0.00730637 loss)
I0503 18:20:45.299264 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0123826 (* 1 = 0.0123826 loss)
I0503 18:20:45.299300 10699 sgd_solver.cpp:106] Iteration 425000, lr = 2.27374e-15
I0503 18:20:50.161895 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:20:58.605913 10699 solver.cpp:228] Iteration 426000, loss = 0.0117316
I0503 18:20:58.605948 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00645417 (* 1 = 0.00645417 loss)
I0503 18:20:58.605958 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00882511 (* 1 = 0.00882511 loss)
I0503 18:20:58.605967 10699 sgd_solver.cpp:106] Iteration 426000, lr = 2.27374e-15
I0503 18:21:11.462815 10699 solver.cpp:228] Iteration 427000, loss = 0.00994477
I0503 18:21:11.462846 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00375117 (* 1 = 0.00375117 loss)
I0503 18:21:11.462852 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00383784 (* 1 = 0.00383784 loss)
I0503 18:21:11.462857 10699 sgd_solver.cpp:106] Iteration 427000, lr = 2.27374e-15
I0503 18:21:22.044870 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:21:24.252055 10699 solver.cpp:228] Iteration 428000, loss = 0.0125334
I0503 18:21:24.252085 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00362124 (* 1 = 0.00362124 loss)
I0503 18:21:24.252091 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00473649 (* 1 = 0.00473649 loss)
I0503 18:21:24.252097 10699 sgd_solver.cpp:106] Iteration 428000, lr = 2.27374e-15
I0503 18:21:37.233280 10699 solver.cpp:228] Iteration 429000, loss = 0.010642
I0503 18:21:37.233311 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00455235 (* 1 = 0.00455235 loss)
I0503 18:21:37.233317 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00516056 (* 1 = 0.00516056 loss)
I0503 18:21:37.233322 10699 sgd_solver.cpp:106] Iteration 429000, lr = 2.27374e-15
I0503 18:21:50.027132 10699 solver.cpp:337] Iteration 430000, Testing net (#0)
I0503 18:21:50.027158 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:21:50.027163 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:21:50.660339 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:21:50.660365 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:21:50.677795 10699 solver.cpp:228] Iteration 430000, loss = 0.0123345
I0503 18:21:50.677819 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00405455 (* 1 = 0.00405455 loss)
I0503 18:21:50.677829 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00589907 (* 1 = 0.00589907 loss)
I0503 18:21:50.677837 10699 sgd_solver.cpp:106] Iteration 430000, lr = 1.13687e-15
I0503 18:21:53.261224 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:22:03.344570 10699 solver.cpp:228] Iteration 431000, loss = 0.0109523
I0503 18:22:03.344601 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0059198 (* 1 = 0.0059198 loss)
I0503 18:22:03.344607 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00855093 (* 1 = 0.00855093 loss)
I0503 18:22:03.344614 10699 sgd_solver.cpp:106] Iteration 431000, lr = 1.13687e-15
I0503 18:22:16.494493 10699 solver.cpp:228] Iteration 432000, loss = 0.0107746
I0503 18:22:16.494530 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00323097 (* 1 = 0.00323097 loss)
I0503 18:22:16.494539 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00482166 (* 1 = 0.00482166 loss)
I0503 18:22:16.494546 10699 sgd_solver.cpp:106] Iteration 432000, lr = 1.13687e-15
I0503 18:22:25.474797 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:22:29.566769 10699 solver.cpp:228] Iteration 433000, loss = 0.00955834
I0503 18:22:29.566865 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00235754 (* 1 = 0.00235754 loss)
I0503 18:22:29.566900 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00279336 (* 1 = 0.00279336 loss)
I0503 18:22:29.566931 10699 sgd_solver.cpp:106] Iteration 433000, lr = 1.13687e-15
I0503 18:22:42.656132 10699 solver.cpp:228] Iteration 434000, loss = 0.0112938
I0503 18:22:42.656172 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00787138 (* 1 = 0.00787138 loss)
I0503 18:22:42.656182 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00926026 (* 1 = 0.00926026 loss)
I0503 18:22:42.656189 10699 sgd_solver.cpp:106] Iteration 434000, lr = 1.13687e-15
I0503 18:22:55.620116 10699 solver.cpp:337] Iteration 435000, Testing net (#0)
I0503 18:22:55.620194 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:22:55.620203 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:22:56.166815 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:22:56.166837 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:22:56.183472 10699 solver.cpp:228] Iteration 435000, loss = 0.0109981
I0503 18:22:56.183492 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00291713 (* 1 = 0.00291713 loss)
I0503 18:22:56.183500 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00316324 (* 1 = 0.00316324 loss)
I0503 18:22:56.183504 10699 sgd_solver.cpp:106] Iteration 435000, lr = 1.13687e-15
I0503 18:22:56.369629 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:23:09.293437 10699 solver.cpp:228] Iteration 436000, loss = 0.0103912
I0503 18:23:09.293470 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00223626 (* 1 = 0.00223626 loss)
I0503 18:23:09.293476 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00336502 (* 1 = 0.00336502 loss)
I0503 18:23:09.293483 10699 sgd_solver.cpp:106] Iteration 436000, lr = 1.13687e-15
I0503 18:23:22.364040 10699 solver.cpp:228] Iteration 437000, loss = 0.0104366
I0503 18:23:22.364132 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00284037 (* 1 = 0.00284037 loss)
I0503 18:23:22.364166 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00348167 (* 1 = 0.00348167 loss)
I0503 18:23:22.364193 10699 sgd_solver.cpp:106] Iteration 437000, lr = 1.13687e-15
I0503 18:23:29.448837 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:23:35.388901 10699 solver.cpp:228] Iteration 438000, loss = 0.0110434
I0503 18:23:35.389004 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00479522 (* 1 = 0.00479522 loss)
I0503 18:23:35.389035 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00620507 (* 1 = 0.00620507 loss)
I0503 18:23:35.389062 10699 sgd_solver.cpp:106] Iteration 438000, lr = 1.13687e-15
I0503 18:23:48.439801 10699 solver.cpp:228] Iteration 439000, loss = 0.0104723
I0503 18:23:48.439901 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00239386 (* 1 = 0.00239386 loss)
I0503 18:23:48.439931 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00366822 (* 1 = 0.00366822 loss)
I0503 18:23:48.439954 10699 sgd_solver.cpp:106] Iteration 439000, lr = 1.13687e-15
I0503 18:24:01.484726 10699 solver.cpp:337] Iteration 440000, Testing net (#0)
I0503 18:24:01.484884 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:24:01.484907 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:24:01.531795 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:24:02.047478 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:24:02.047508 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:24:02.049774 10699 solver.cpp:228] Iteration 440000, loss = 0.0112571
I0503 18:24:02.049796 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00456297 (* 1 = 0.00456297 loss)
I0503 18:24:02.049805 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00488017 (* 1 = 0.00488017 loss)
I0503 18:24:02.049815 10699 sgd_solver.cpp:106] Iteration 440000, lr = 5.68434e-16
I0503 18:24:14.796373 10699 solver.cpp:228] Iteration 441000, loss = 0.0099964
I0503 18:24:14.796412 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0028973 (* 1 = 0.0028973 loss)
I0503 18:24:14.796421 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00448153 (* 1 = 0.00448153 loss)
I0503 18:24:14.796428 10699 sgd_solver.cpp:106] Iteration 441000, lr = 5.68434e-16
I0503 18:24:27.593626 10699 solver.cpp:228] Iteration 442000, loss = 0.0112993
I0503 18:24:27.593724 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00449818 (* 1 = 0.00449818 loss)
I0503 18:24:27.593760 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00704169 (* 1 = 0.00704169 loss)
I0503 18:24:27.593785 10699 sgd_solver.cpp:106] Iteration 442000, lr = 5.68434e-16
I0503 18:24:32.532627 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:24:40.723806 10699 solver.cpp:228] Iteration 443000, loss = 0.0116359
I0503 18:24:40.723845 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00224322 (* 1 = 0.00224322 loss)
I0503 18:24:40.723853 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00285821 (* 1 = 0.00285821 loss)
I0503 18:24:40.723860 10699 sgd_solver.cpp:106] Iteration 443000, lr = 5.68434e-16
I0503 18:24:53.603652 10699 solver.cpp:228] Iteration 444000, loss = 0.0115837
I0503 18:24:53.603682 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00327733 (* 1 = 0.00327733 loss)
I0503 18:24:53.603688 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0067086 (* 1 = 0.0067086 loss)
I0503 18:24:53.603693 10699 sgd_solver.cpp:106] Iteration 444000, lr = 5.68434e-16
I0503 18:25:05.322075 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:25:06.693230 10699 solver.cpp:337] Iteration 445000, Testing net (#0)
I0503 18:25:06.693258 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:25:06.693264 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:25:07.252959 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:25:07.252993 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:25:07.271646 10699 solver.cpp:228] Iteration 445000, loss = 0.0113074
I0503 18:25:07.271673 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00480368 (* 1 = 0.00480368 loss)
I0503 18:25:07.271679 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00611783 (* 1 = 0.00611783 loss)
I0503 18:25:07.271685 10699 sgd_solver.cpp:106] Iteration 445000, lr = 5.68434e-16
I0503 18:25:20.448148 10699 solver.cpp:228] Iteration 446000, loss = 0.0113079
I0503 18:25:20.448187 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00466259 (* 1 = 0.00466259 loss)
I0503 18:25:20.448199 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00874228 (* 1 = 0.00874228 loss)
I0503 18:25:20.448207 10699 sgd_solver.cpp:106] Iteration 446000, lr = 5.68434e-16
I0503 18:25:33.540438 10699 solver.cpp:228] Iteration 447000, loss = 0.0116006
I0503 18:25:33.540472 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00407505 (* 1 = 0.00407505 loss)
I0503 18:25:33.540479 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00643059 (* 1 = 0.00643059 loss)
I0503 18:25:33.540488 10699 sgd_solver.cpp:106] Iteration 447000, lr = 5.68434e-16
I0503 18:25:36.940384 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:25:46.357028 10699 solver.cpp:228] Iteration 448000, loss = 0.0104442
I0503 18:25:46.357131 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00543663 (* 1 = 0.00543663 loss)
I0503 18:25:46.357163 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00741066 (* 1 = 0.00741066 loss)
I0503 18:25:46.357192 10699 sgd_solver.cpp:106] Iteration 448000, lr = 5.68434e-16
I0503 18:25:58.842041 10699 solver.cpp:228] Iteration 449000, loss = 0.0114973
I0503 18:25:58.842080 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00426141 (* 1 = 0.00426141 loss)
I0503 18:25:58.842089 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00685936 (* 1 = 0.00685936 loss)
I0503 18:25:58.842099 10699 sgd_solver.cpp:106] Iteration 449000, lr = 5.68434e-16
I0503 18:26:05.431452 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:26:09.246894 10699 solver.cpp:337] Iteration 450000, Testing net (#0)
I0503 18:26:09.246979 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:26:09.246989 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:26:09.672325 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:26:09.672351 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:26:09.676214 10699 solver.cpp:228] Iteration 450000, loss = 0.0116271
I0503 18:26:09.676234 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00391633 (* 1 = 0.00391633 loss)
I0503 18:26:09.676244 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00399131 (* 1 = 0.00399131 loss)
I0503 18:26:09.676254 10699 sgd_solver.cpp:106] Iteration 450000, lr = 2.84217e-16
I0503 18:26:20.228652 10699 solver.cpp:228] Iteration 451000, loss = 0.0102456
I0503 18:26:20.228690 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00458052 (* 1 = 0.00458052 loss)
I0503 18:26:20.228699 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00389742 (* 1 = 0.00389742 loss)
I0503 18:26:20.228708 10699 sgd_solver.cpp:106] Iteration 451000, lr = 2.84217e-16
I0503 18:26:25.492429 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:26:30.833174 10699 solver.cpp:228] Iteration 452000, loss = 0.0115776
I0503 18:26:30.833271 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00271084 (* 1 = 0.00271084 loss)
I0503 18:26:30.833298 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00408795 (* 1 = 0.00408795 loss)
I0503 18:26:30.833319 10699 sgd_solver.cpp:106] Iteration 452000, lr = 2.84217e-16
I0503 18:26:41.292271 10699 solver.cpp:228] Iteration 453000, loss = 0.0103093
I0503 18:26:41.292354 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00357716 (* 1 = 0.00357716 loss)
I0503 18:26:41.292361 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00485986 (* 1 = 0.00485986 loss)
I0503 18:26:41.292367 10699 sgd_solver.cpp:106] Iteration 453000, lr = 2.84217e-16
I0503 18:26:45.895114 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:26:51.487216 10699 solver.cpp:228] Iteration 454000, loss = 0.0107403
I0503 18:26:51.487246 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00260093 (* 1 = 0.00260093 loss)
I0503 18:26:51.487252 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00379797 (* 1 = 0.00379797 loss)
I0503 18:26:51.487257 10699 sgd_solver.cpp:106] Iteration 454000, lr = 2.84217e-16
I0503 18:27:02.295608 10699 solver.cpp:337] Iteration 455000, Testing net (#0)
I0503 18:27:02.295630 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:27:02.295636 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:27:02.731628 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:27:02.731716 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:27:02.734278 10699 solver.cpp:228] Iteration 455000, loss = 0.0106526
I0503 18:27:02.734334 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00443227 (* 1 = 0.00443227 loss)
I0503 18:27:02.734387 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0079759 (* 1 = 0.0079759 loss)
I0503 18:27:02.734416 10699 sgd_solver.cpp:106] Iteration 455000, lr = 2.84217e-16
I0503 18:27:06.151578 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:27:12.823648 10699 solver.cpp:228] Iteration 456000, loss = 0.0117122
I0503 18:27:12.823748 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00598365 (* 1 = 0.00598365 loss)
I0503 18:27:12.823756 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00784306 (* 1 = 0.00784306 loss)
I0503 18:27:12.823761 10699 sgd_solver.cpp:106] Iteration 456000, lr = 2.84217e-16
I0503 18:27:23.708632 10699 solver.cpp:228] Iteration 457000, loss = 0.0109248
I0503 18:27:23.708735 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00381377 (* 1 = 0.00381377 loss)
I0503 18:27:23.708772 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00427357 (* 1 = 0.00427357 loss)
I0503 18:27:23.708806 10699 sgd_solver.cpp:106] Iteration 457000, lr = 2.84217e-16
I0503 18:27:27.436956 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:27:34.086309 10699 solver.cpp:228] Iteration 458000, loss = 0.00984352
I0503 18:27:34.086345 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00343656 (* 1 = 0.00343656 loss)
I0503 18:27:34.086356 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00477922 (* 1 = 0.00477922 loss)
I0503 18:27:34.086365 10699 sgd_solver.cpp:106] Iteration 458000, lr = 2.84217e-16
I0503 18:27:44.468000 10699 solver.cpp:228] Iteration 459000, loss = 0.00957516
I0503 18:27:44.468076 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0022747 (* 1 = 0.0022747 loss)
I0503 18:27:44.468085 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00283442 (* 1 = 0.00283442 loss)
I0503 18:27:44.468089 10699 sgd_solver.cpp:106] Iteration 459000, lr = 2.84217e-16
I0503 18:27:49.044646 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:27:56.601225 10699 solver.cpp:337] Iteration 460000, Testing net (#0)
I0503 18:27:56.601251 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:27:56.601258 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:27:57.138808 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:27:57.138833 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:27:57.141468 10699 solver.cpp:228] Iteration 460000, loss = 0.0112853
I0503 18:27:57.141489 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00285981 (* 1 = 0.00285981 loss)
I0503 18:27:57.141499 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00441224 (* 1 = 0.00441224 loss)
I0503 18:27:57.141507 10699 sgd_solver.cpp:106] Iteration 460000, lr = 1.42109e-16
I0503 18:28:09.894152 10699 solver.cpp:228] Iteration 461000, loss = 0.0118791
I0503 18:28:09.894194 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00456416 (* 1 = 0.00456416 loss)
I0503 18:28:09.894204 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00452819 (* 1 = 0.00452819 loss)
I0503 18:28:09.894212 10699 sgd_solver.cpp:106] Iteration 461000, lr = 1.42109e-16
I0503 18:28:20.139827 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:28:22.893045 10699 solver.cpp:228] Iteration 462000, loss = 0.00994575
I0503 18:28:22.893075 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00654712 (* 1 = 0.00654712 loss)
I0503 18:28:22.893081 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00579591 (* 1 = 0.00579591 loss)
I0503 18:28:22.893086 10699 sgd_solver.cpp:106] Iteration 462000, lr = 1.42109e-16
I0503 18:28:35.754066 10699 solver.cpp:228] Iteration 463000, loss = 0.0109067
I0503 18:28:35.754111 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00706366 (* 1 = 0.00706366 loss)
I0503 18:28:35.754122 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00899618 (* 1 = 0.00899618 loss)
I0503 18:28:35.754133 10699 sgd_solver.cpp:106] Iteration 463000, lr = 1.42109e-16
I0503 18:28:48.644748 10699 solver.cpp:228] Iteration 464000, loss = 0.0124594
I0503 18:28:48.644780 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00692704 (* 1 = 0.00692704 loss)
I0503 18:28:48.644788 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00845943 (* 1 = 0.00845943 loss)
I0503 18:28:48.644793 10699 sgd_solver.cpp:106] Iteration 464000, lr = 1.42109e-16
I0503 18:28:51.972704 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:29:01.371701 10699 solver.cpp:337] Iteration 465000, Testing net (#0)
I0503 18:29:01.371731 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:29:01.371737 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:29:01.896363 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:29:01.896394 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:29:01.912468 10699 solver.cpp:228] Iteration 465000, loss = 0.0106262
I0503 18:29:01.912497 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00368618 (* 1 = 0.00368618 loss)
I0503 18:29:01.912506 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00432828 (* 1 = 0.00432828 loss)
I0503 18:29:01.912514 10699 sgd_solver.cpp:106] Iteration 465000, lr = 1.42109e-16
I0503 18:29:14.980767 10699 solver.cpp:228] Iteration 466000, loss = 0.0101464
I0503 18:29:14.980806 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00407444 (* 1 = 0.00407444 loss)
I0503 18:29:14.980815 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00666218 (* 1 = 0.00666218 loss)
I0503 18:29:14.980823 10699 sgd_solver.cpp:106] Iteration 466000, lr = 1.42109e-16
I0503 18:29:22.708950 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:29:28.083781 10699 solver.cpp:228] Iteration 467000, loss = 0.0106676
I0503 18:29:28.083822 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00407868 (* 1 = 0.00407868 loss)
I0503 18:29:28.083832 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00537918 (* 1 = 0.00537918 loss)
I0503 18:29:28.083838 10699 sgd_solver.cpp:106] Iteration 467000, lr = 1.42109e-16
I0503 18:29:41.182783 10699 solver.cpp:228] Iteration 468000, loss = 0.0104137
I0503 18:29:41.182879 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00306759 (* 1 = 0.00306759 loss)
I0503 18:29:41.182907 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00278743 (* 1 = 0.00278743 loss)
I0503 18:29:41.182932 10699 sgd_solver.cpp:106] Iteration 468000, lr = 1.42109e-16
I0503 18:29:54.255158 10699 solver.cpp:228] Iteration 469000, loss = 0.0106046
I0503 18:29:54.255285 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00538064 (* 1 = 0.00538064 loss)
I0503 18:29:54.255311 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00612465 (* 1 = 0.00612465 loss)
I0503 18:29:54.255332 10699 sgd_solver.cpp:106] Iteration 469000, lr = 1.42109e-16
I0503 18:29:55.321585 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:30:06.871632 10699 solver.cpp:337] Iteration 470000, Testing net (#0)
I0503 18:30:06.871726 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:30:06.871752 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:30:07.519731 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:30:07.519815 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:30:07.522420 10699 solver.cpp:228] Iteration 470000, loss = 0.0108461
I0503 18:30:07.522445 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0038716 (* 1 = 0.0038716 loss)
I0503 18:30:07.522455 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00597312 (* 1 = 0.00597312 loss)
I0503 18:30:07.522464 10699 sgd_solver.cpp:106] Iteration 470000, lr = 7.10543e-17
I0503 18:30:20.398304 10699 solver.cpp:228] Iteration 471000, loss = 0.009542
I0503 18:30:20.398345 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00420937 (* 1 = 0.00420937 loss)
I0503 18:30:20.398356 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00611621 (* 1 = 0.00611621 loss)
I0503 18:30:20.398365 10699 sgd_solver.cpp:106] Iteration 471000, lr = 7.10543e-17
I0503 18:30:25.768483 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:30:33.253221 10699 solver.cpp:228] Iteration 472000, loss = 0.0117501
I0503 18:30:33.253255 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00463242 (* 1 = 0.00463242 loss)
I0503 18:30:33.253264 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0056476 (* 1 = 0.0056476 loss)
I0503 18:30:33.253274 10699 sgd_solver.cpp:106] Iteration 472000, lr = 7.10543e-17
I0503 18:30:46.064070 10699 solver.cpp:228] Iteration 473000, loss = 0.011288
I0503 18:30:46.064112 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00309419 (* 1 = 0.00309419 loss)
I0503 18:30:46.064122 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00523183 (* 1 = 0.00523183 loss)
I0503 18:30:46.064131 10699 sgd_solver.cpp:106] Iteration 473000, lr = 7.10543e-17
I0503 18:30:58.194258 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:30:59.222470 10699 solver.cpp:228] Iteration 474000, loss = 0.0105682
I0503 18:30:59.222508 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00305707 (* 1 = 0.00305707 loss)
I0503 18:30:59.222518 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00314168 (* 1 = 0.00314168 loss)
I0503 18:30:59.222528 10699 sgd_solver.cpp:106] Iteration 474000, lr = 7.10543e-17
I0503 18:31:12.357873 10699 solver.cpp:337] Iteration 475000, Testing net (#0)
I0503 18:31:12.357962 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:31:12.357990 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:31:12.934696 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:31:12.934729 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:31:12.937350 10699 solver.cpp:228] Iteration 475000, loss = 0.0100395
I0503 18:31:12.937374 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00220006 (* 1 = 0.00220006 loss)
I0503 18:31:12.937382 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00361709 (* 1 = 0.00361709 loss)
I0503 18:31:12.937391 10699 sgd_solver.cpp:106] Iteration 475000, lr = 7.10543e-17
I0503 18:31:26.022209 10699 solver.cpp:228] Iteration 476000, loss = 0.0108991
I0503 18:31:26.022251 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00558434 (* 1 = 0.00558434 loss)
I0503 18:31:26.022263 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0135057 (* 1 = 0.0135057 loss)
I0503 18:31:26.022270 10699 sgd_solver.cpp:106] Iteration 476000, lr = 7.10543e-17
I0503 18:31:29.740726 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:31:38.572835 10699 solver.cpp:228] Iteration 477000, loss = 0.0104632
I0503 18:31:38.573001 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00286023 (* 1 = 0.00286023 loss)
I0503 18:31:38.573057 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00453833 (* 1 = 0.00453833 loss)
I0503 18:31:38.573103 10699 sgd_solver.cpp:106] Iteration 477000, lr = 7.10543e-17
I0503 18:31:51.677315 10699 solver.cpp:228] Iteration 478000, loss = 0.0105924
I0503 18:31:51.677347 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00393012 (* 1 = 0.00393012 loss)
I0503 18:31:51.677353 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00498532 (* 1 = 0.00498532 loss)
I0503 18:31:51.677361 10699 sgd_solver.cpp:106] Iteration 478000, lr = 7.10543e-17
I0503 18:32:00.794093 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:32:04.504567 10699 solver.cpp:228] Iteration 479000, loss = 0.0116147
I0503 18:32:04.504603 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00475529 (* 1 = 0.00475529 loss)
I0503 18:32:04.504611 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0063013 (* 1 = 0.0063013 loss)
I0503 18:32:04.504619 10699 sgd_solver.cpp:106] Iteration 479000, lr = 7.10543e-17
I0503 18:32:17.306991 10699 solver.cpp:337] Iteration 480000, Testing net (#0)
I0503 18:32:17.307013 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:32:17.307018 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:32:17.853675 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:32:17.853698 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:32:17.872231 10699 solver.cpp:228] Iteration 480000, loss = 0.0118506
I0503 18:32:17.872257 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00414436 (* 1 = 0.00414436 loss)
I0503 18:32:17.872263 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00655647 (* 1 = 0.00655647 loss)
I0503 18:32:17.872269 10699 sgd_solver.cpp:106] Iteration 480000, lr = 3.55271e-17
I0503 18:32:31.083663 10699 solver.cpp:228] Iteration 481000, loss = 0.0114277
I0503 18:32:31.083806 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00603389 (* 1 = 0.00603389 loss)
I0503 18:32:31.083818 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00623366 (* 1 = 0.00623366 loss)
I0503 18:32:31.083825 10699 sgd_solver.cpp:106] Iteration 481000, lr = 3.55271e-17
I0503 18:32:31.914927 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:32:44.361558 10699 solver.cpp:228] Iteration 482000, loss = 0.0107618
I0503 18:32:44.361598 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.004158 (* 1 = 0.004158 loss)
I0503 18:32:44.361608 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00447743 (* 1 = 0.00447743 loss)
I0503 18:32:44.361616 10699 sgd_solver.cpp:106] Iteration 482000, lr = 3.55271e-17
I0503 18:32:57.198765 10699 solver.cpp:228] Iteration 483000, loss = 0.0104542
I0503 18:32:57.198804 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00780448 (* 1 = 0.00780448 loss)
I0503 18:32:57.198813 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0119554 (* 1 = 0.0119554 loss)
I0503 18:32:57.198820 10699 sgd_solver.cpp:106] Iteration 483000, lr = 3.55271e-17
I0503 18:33:05.336751 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:33:10.018348 10699 solver.cpp:228] Iteration 484000, loss = 0.0105501
I0503 18:33:10.018381 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00432058 (* 1 = 0.00432058 loss)
I0503 18:33:10.018388 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00557718 (* 1 = 0.00557718 loss)
I0503 18:33:10.018394 10699 sgd_solver.cpp:106] Iteration 484000, lr = 3.55271e-17
I0503 18:33:23.059123 10699 solver.cpp:337] Iteration 485000, Testing net (#0)
I0503 18:33:23.059154 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:33:23.059162 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:33:23.662950 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:33:23.662981 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:33:23.682248 10699 solver.cpp:228] Iteration 485000, loss = 0.0121598
I0503 18:33:23.682284 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00479573 (* 1 = 0.00479573 loss)
I0503 18:33:23.682293 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00791731 (* 1 = 0.00791731 loss)
I0503 18:33:23.682302 10699 sgd_solver.cpp:106] Iteration 485000, lr = 3.55271e-17
I0503 18:33:36.312626 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:33:36.352092 10699 solver.cpp:228] Iteration 486000, loss = 0.0108187
I0503 18:33:36.352141 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00472894 (* 1 = 0.00472894 loss)
I0503 18:33:36.352154 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00532148 (* 1 = 0.00532148 loss)
I0503 18:33:36.352164 10699 sgd_solver.cpp:106] Iteration 486000, lr = 3.55271e-17
I0503 18:33:49.307881 10699 solver.cpp:228] Iteration 487000, loss = 0.010636
I0503 18:33:49.307917 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00537949 (* 1 = 0.00537949 loss)
I0503 18:33:49.307924 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00982708 (* 1 = 0.00982708 loss)
I0503 18:33:49.307930 10699 sgd_solver.cpp:106] Iteration 487000, lr = 3.55271e-17
I0503 18:34:02.279377 10699 solver.cpp:228] Iteration 488000, loss = 0.0104305
I0503 18:34:02.279409 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00430548 (* 1 = 0.00430548 loss)
I0503 18:34:02.279415 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00395474 (* 1 = 0.00395474 loss)
I0503 18:34:02.279420 10699 sgd_solver.cpp:106] Iteration 488000, lr = 3.55271e-17
I0503 18:34:08.353437 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:34:15.260700 10699 solver.cpp:228] Iteration 489000, loss = 0.0106594
I0503 18:34:15.260733 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00222561 (* 1 = 0.00222561 loss)
I0503 18:34:15.260743 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00369731 (* 1 = 0.00369731 loss)
I0503 18:34:15.260752 10699 sgd_solver.cpp:106] Iteration 489000, lr = 3.55271e-17
I0503 18:34:28.318384 10699 solver.cpp:337] Iteration 490000, Testing net (#0)
I0503 18:34:28.318413 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:34:28.318420 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:34:28.934204 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:34:28.934238 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:34:28.936885 10699 solver.cpp:228] Iteration 490000, loss = 0.0101583
I0503 18:34:28.936913 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00635292 (* 1 = 0.00635292 loss)
I0503 18:34:28.936923 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0112757 (* 1 = 0.0112757 loss)
I0503 18:34:28.936931 10699 sgd_solver.cpp:106] Iteration 490000, lr = 1.77636e-17
I0503 18:34:39.229367 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:34:41.603662 10699 solver.cpp:228] Iteration 491000, loss = 0.0122199
I0503 18:34:41.603703 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0083387 (* 1 = 0.0083387 loss)
I0503 18:34:41.603713 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0121739 (* 1 = 0.0121739 loss)
I0503 18:34:41.603720 10699 sgd_solver.cpp:106] Iteration 491000, lr = 1.77636e-17
I0503 18:34:54.599130 10699 solver.cpp:228] Iteration 492000, loss = 0.0100937
I0503 18:34:54.599169 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0051918 (* 1 = 0.0051918 loss)
I0503 18:34:54.599177 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0058432 (* 1 = 0.0058432 loss)
I0503 18:34:54.599184 10699 sgd_solver.cpp:106] Iteration 492000, lr = 1.77636e-17
I0503 18:35:07.462044 10699 solver.cpp:228] Iteration 493000, loss = 0.0112942
I0503 18:35:07.462080 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00271919 (* 1 = 0.00271919 loss)
I0503 18:35:07.462086 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00471694 (* 1 = 0.00471694 loss)
I0503 18:35:07.462093 10699 sgd_solver.cpp:106] Iteration 493000, lr = 1.77636e-17
I0503 18:35:10.629479 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:35:20.704012 10699 solver.cpp:228] Iteration 494000, loss = 0.011025
I0503 18:35:20.704100 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00322502 (* 1 = 0.00322502 loss)
I0503 18:35:20.704125 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00632337 (* 1 = 0.00632337 loss)
I0503 18:35:20.704145 10699 sgd_solver.cpp:106] Iteration 494000, lr = 1.77636e-17
I0503 18:35:33.286784 10699 solver.cpp:337] Iteration 495000, Testing net (#0)
I0503 18:35:33.286813 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:35:33.286820 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:35:33.811666 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:35:33.811700 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:35:33.814234 10699 solver.cpp:228] Iteration 495000, loss = 0.0114259
I0503 18:35:33.814268 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00886377 (* 1 = 0.00886377 loss)
I0503 18:35:33.814280 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0154356 (* 1 = 0.0154356 loss)
I0503 18:35:33.814290 10699 sgd_solver.cpp:106] Iteration 495000, lr = 1.77636e-17
I0503 18:35:40.368098 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:35:46.354310 10699 solver.cpp:228] Iteration 496000, loss = 0.0106159
I0503 18:35:46.354470 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00228046 (* 1 = 0.00228046 loss)
I0503 18:35:46.354497 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00254977 (* 1 = 0.00254977 loss)
I0503 18:35:46.354518 10699 sgd_solver.cpp:106] Iteration 496000, lr = 1.77636e-17
I0503 18:35:58.968384 10699 solver.cpp:228] Iteration 497000, loss = 0.0122789
I0503 18:35:58.968411 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00311888 (* 1 = 0.00311888 loss)
I0503 18:35:58.968420 10699 solver.cpp:244]     Train net output #1: loss_single = 0.00608612 (* 1 = 0.00608612 loss)
I0503 18:35:58.968425 10699 sgd_solver.cpp:106] Iteration 497000, lr = 1.77636e-17
I0503 18:36:11.373626 10699 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 18:36:11.843849 10699 solver.cpp:228] Iteration 498000, loss = 0.01088
I0503 18:36:11.843894 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.0078078 (* 1 = 0.0078078 loss)
I0503 18:36:11.843906 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0098436 (* 1 = 0.0098436 loss)
I0503 18:36:11.843916 10699 sgd_solver.cpp:106] Iteration 498000, lr = 1.77636e-17
I0503 18:36:25.199831 10699 solver.cpp:228] Iteration 499000, loss = 0.011903
I0503 18:36:25.199915 10699 solver.cpp:244]     Train net output #0: loss_dual = 0.00624811 (* 1 = 0.00624811 loss)
I0503 18:36:25.199923 10699 solver.cpp:244]     Train net output #1: loss_single = 0.0136473 (* 1 = 0.0136473 loss)
I0503 18:36:25.199928 10699 sgd_solver.cpp:106] Iteration 499000, lr = 1.77636e-17
I0503 18:36:38.189465 10699 solver.cpp:454] Snapshotting to binary proto file mnist_iter_500000.caffemodel
I0503 18:36:38.200283 10699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mnist_iter_500000.solverstate
I0503 18:36:38.218940 10699 solver.cpp:317] Iteration 500000, loss = 0.011118
I0503 18:36:38.218957 10699 solver.cpp:337] Iteration 500000, Testing net (#0)
I0503 18:36:38.218964 10699 net.cpp:709] Ignoring source layer loss_dual
I0503 18:36:38.218968 10699 net.cpp:709] Ignoring source layer loss_single
I0503 18:36:38.745301 10699 solver.cpp:404]     Test net output #0: accuracy_dual = 0.986
I0503 18:36:38.745331 10699 solver.cpp:404]     Test net output #1: accuracy_single = 0.9857
I0503 18:36:38.745335 10699 solver.cpp:322] Optimization Done.
I0503 18:36:38.745338 10699 caffe.cpp:254] Optimization Done.
